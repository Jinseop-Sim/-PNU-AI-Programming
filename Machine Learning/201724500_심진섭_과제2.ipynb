{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 201724500 심진섭 Machine learning assignment #2\n",
        "## 1. Get dataset\n",
        "\n",
        ">가장 먼저, pdf에서 제공받은 iris(붓꽃) dataset을 가져와 읽어온다.\n",
        "\n",
        "이전 과제와는 다르게 iris data로 데이터가 고정되었다.\n",
        "기계 학습에서 가장 유명한 데이터로, 아래와 같은 Attribute를 가진다.\n",
        "- Sepal length (cm) : 꽃받침의 길이\n",
        "- Sepal width (cm) : 꽃받침의 너비\n",
        "- Petal length (cm) : 꽃잎의 길이\n",
        "- Petal width (cm) : 꽃잎의 너비\n",
        "\n",
        "위의 4가지 Attribute를 통해 총 150개의 Example을 아래 3가지 class에 대해 학습한다.\n",
        "- Setosa : 부채 붓꽃\n",
        "- Versicolour : 버시칼라 붓꽃\n",
        "- Virginica : 버지니카 붓꽃\n",
        "\n",
        "## 1-1. 왜 Pytorch를 사용했는가?\n",
        "이번 과제에서는 Keras, tensorflow 등 여러 프레임워크를 사용할 수 있지만 나는 Pytorch를 사용해보기로 했다.  \n",
        "아래와 같은 이유로 Pytorch를 선택하게 되었다.  \n",
        "- 이전에 학습한 적이 있어 다른 프레임워크들에 비해 익숙하다.\n",
        "- 문법의 형태가 기존 파이썬에서 크게 벗어나지 않아 학습이 쉽다.\n"
      ],
      "metadata": {
        "id": "Pu6a3S77MzT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WUzBSFI3NXPR",
        "outputId": "057945c0-854d-4e9a-ede2-25723178fad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3472414-fcba-4144-b22c-2926ae7f1653\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3472414-fcba-4144-b22c-2926ae7f1653')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3472414-fcba-4144-b22c-2926ae7f1653 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3472414-fcba-4144-b22c-2926ae7f1653');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sklearn.metrics as met\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "col_names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
        "df = pd.read_csv('iris.data', names=col_names)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data preprocessing\n",
        "먼저, 아래와 같이 데이터 전처리를 진행한다.\n",
        "- Categorical data로는 학습 및 분류가 불가능하다.\n",
        "  - 따라서 Numerical data로 factorize() 함수를 통해 변환한다.\n",
        "- Pytorch를 통해 기계 학습을 진행하려면 array가 아닌 Tensor의 형태여야한다.\n",
        "  - torch.from_numpy() 함수를 이용해 변환한다.\n",
        "- Train 60%, Test 20%, Valid 20%로 dataset을 분할해야 한다.\n",
        "  - Scikit learn 패키지의 train_test_split을 이용해서 random하게 분할한다.\n",
        "    - 먼저 Train : Test를 60 : 40으로 분할한다.\n",
        "    - 이후 Test : valid를 50 : 50으로 다시 분할한다.\n",
        "\n",
        "아래와 같은 shape의 가공된 학습 데이터가 만들어진다.\n",
        "- Train set : [90, 4]\n",
        "- Test set : [30, 4]\n",
        "- Valid set : [30, 4]"
      ],
      "metadata": {
        "id": "ZD8WM6NaOxR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 우선 학습을 위해 Dataset을 입력과 결과로 자른다.\n",
        "# 이 때, 학습을 위해 Categorical data로 되어있는 y를 Numerical 하게 변환해준다.\n",
        "df['species'], _ = df['species'].factorize() # Categorical -> Numerical\n",
        "\n",
        "x = df.iloc[:,0:4].values # 입력\n",
        "y = df.iloc[:,4].values # 출력\n",
        "\n",
        "# Pytorch를 통한 기계학습을 위해 Array를 Tensor로 바꾸어 준다.\n",
        "x = torch.from_numpy(x).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.long)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
        "x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "print(x_valid.shape, y_valid.shape)"
      ],
      "metadata": {
        "id": "MA_1kWyaO04q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808db9aa-9495-4d52-f7b7-582131f55c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([90, 4]) torch.Size([90])\n",
            "torch.Size([30, 4]) torch.Size([30])\n",
            "torch.Size([30, 4]) torch.Size([30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Neural Network Learning\n",
        "이제 실제로 Feedforward Neural Netwrok를 구성하여 실제로 데이터를 학습시켜 볼 차례이다.  \n",
        "\n",
        "### Network architecture\n",
        "Layer를 쌓는 방식은 자유이므로, 나는 아래와 같이 간단한 network를 구성하였다.\n",
        "- Fully connected layer (90 * 4 -> 90 * 256)\n",
        "- ReLU (Activation function)\n",
        "- Fully connected layer (90 * 256 -> 90 * 128)\n",
        "- ReLU (Activation function)\n",
        "- Fully connected layer (90 * 128 -> 90 * 3)  \n",
        "\n",
        "최초에는 Layer의 크기를 16, 32와 같이 적게 시도했다.  \n",
        "이후 64, 128, 256과 같이 점차 늘려갈 수록 더 높은 정확도를 보였다.  \n",
        "하지만 512, 1024와 같이 너무 많은 neuron의 수는 오히려 정확도를 떨어트림을 확인할 수 있었다.  \n",
        "\n",
        "### Optimizer\n",
        "Optimizer은, weight를 어떤 방식으로 최적화 시켜나갈 것인지에 대한 설정이다.  \n",
        "Stochastic Gradient Descent를 기본적으로 채택하며, hyperparameter에 대한 설정은 자유이므로, 아래와 같이 설정했다.\n",
        "- learning rate(alpha) : 0.01[링크 텍스트](https://)\n",
        "\n",
        "### Loss function\n",
        "Loss function은 Categorical cross entropy 방식으로 고정인데,  \n",
        "Keras의 Categorical cross entropy와 Pytorch의 nn.CrossEntropy는 동일한 기능을 제공한다.  \n",
        "\n",
        "Epoch가 진행될 수록 낮아지는 loss를 확인할 수 있다."
      ],
      "metadata": {
        "id": "yBMJ36bno5RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 3)\n",
        ")\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "## Training 과정\n",
        "\n",
        "for epoch in range(1000):\n",
        "  optimizer.zero_grad() # 이전 epoch에서 쌓인 정보 초기화\n",
        "\n",
        "  train_output = model(x_train) # Feedforward\n",
        "  train_loss = cross_entropy(train_output, y_train) # Calculate loss\n",
        "  train_loss.backward() # Backpropagation, gradient를 계산하는 것\n",
        "  optimizer.step() # 위에서 얻은 정보를 통해 weight를 update한다.\n",
        "\n",
        "  test_output = model(x_test) # Test set에 대한 feedforward\n",
        "  test_loss = cross_entropy(test_output, y_test) # Test set의 loss\n",
        "\n",
        "  valid_output = model(x_valid) # Valid set에 대한 feedforward\n",
        "  valid_loss = cross_entropy(valid_output, y_valid) # Valid set의 loss\n",
        "\n",
        "  print(\"======== Epoch %d =========\" % (epoch + 1))\n",
        "  print(\"Train loss : %f, Test loss : %f, Validation loss : %f\" % (train_loss.item(), test_loss.item(), valid_loss.item()))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSbwma2NSl4b",
        "outputId": "ee17e3bf-ca2f-44dc-fff3-1c01fc38bb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 =========\n",
            "Train loss : 1.401608, Test loss : 1.082842, Validation loss : 1.054976\n",
            "\n",
            "======== Epoch 2 =========\n",
            "Train loss : 1.088606, Test loss : 1.017588, Validation loss : 1.027332\n",
            "\n",
            "======== Epoch 3 =========\n",
            "Train loss : 1.024620, Test loss : 0.983517, Validation loss : 1.012483\n",
            "\n",
            "======== Epoch 4 =========\n",
            "Train loss : 0.994837, Test loss : 0.958545, Validation loss : 0.997407\n",
            "\n",
            "======== Epoch 5 =========\n",
            "Train loss : 0.972710, Test loss : 0.934097, Validation loss : 0.976967\n",
            "\n",
            "======== Epoch 6 =========\n",
            "Train loss : 0.951309, Test loss : 0.913582, Validation loss : 0.959762\n",
            "\n",
            "======== Epoch 7 =========\n",
            "Train loss : 0.934203, Test loss : 0.894429, Validation loss : 0.944613\n",
            "\n",
            "======== Epoch 8 =========\n",
            "Train loss : 0.918484, Test loss : 0.875013, Validation loss : 0.929232\n",
            "\n",
            "======== Epoch 9 =========\n",
            "Train loss : 0.903805, Test loss : 0.859081, Validation loss : 0.913659\n",
            "\n",
            "======== Epoch 10 =========\n",
            "Train loss : 0.890083, Test loss : 0.842406, Validation loss : 0.899477\n",
            "\n",
            "======== Epoch 11 =========\n",
            "Train loss : 0.877346, Test loss : 0.827849, Validation loss : 0.885359\n",
            "\n",
            "======== Epoch 12 =========\n",
            "Train loss : 0.864913, Test loss : 0.811727, Validation loss : 0.872132\n",
            "\n",
            "======== Epoch 13 =========\n",
            "Train loss : 0.852954, Test loss : 0.798197, Validation loss : 0.858054\n",
            "\n",
            "======== Epoch 14 =========\n",
            "Train loss : 0.840771, Test loss : 0.783079, Validation loss : 0.845206\n",
            "\n",
            "======== Epoch 15 =========\n",
            "Train loss : 0.829251, Test loss : 0.770518, Validation loss : 0.832639\n",
            "\n",
            "======== Epoch 16 =========\n",
            "Train loss : 0.818102, Test loss : 0.755617, Validation loss : 0.820251\n",
            "\n",
            "======== Epoch 17 =========\n",
            "Train loss : 0.806924, Test loss : 0.743721, Validation loss : 0.807696\n",
            "\n",
            "======== Epoch 18 =========\n",
            "Train loss : 0.795979, Test loss : 0.729722, Validation loss : 0.795991\n",
            "\n",
            "======== Epoch 19 =========\n",
            "Train loss : 0.785441, Test loss : 0.718608, Validation loss : 0.784406\n",
            "\n",
            "======== Epoch 20 =========\n",
            "Train loss : 0.775106, Test loss : 0.705239, Validation loss : 0.772904\n",
            "\n",
            "======== Epoch 21 =========\n",
            "Train loss : 0.764885, Test loss : 0.694701, Validation loss : 0.761904\n",
            "\n",
            "======== Epoch 22 =========\n",
            "Train loss : 0.755049, Test loss : 0.682272, Validation loss : 0.751012\n",
            "\n",
            "======== Epoch 23 =========\n",
            "Train loss : 0.745298, Test loss : 0.672196, Validation loss : 0.740767\n",
            "\n",
            "======== Epoch 24 =========\n",
            "Train loss : 0.736029, Test loss : 0.660572, Validation loss : 0.730032\n",
            "\n",
            "======== Epoch 25 =========\n",
            "Train loss : 0.726631, Test loss : 0.651091, Validation loss : 0.720299\n",
            "\n",
            "======== Epoch 26 =========\n",
            "Train loss : 0.717853, Test loss : 0.640114, Validation loss : 0.710230\n",
            "\n",
            "======== Epoch 27 =========\n",
            "Train loss : 0.708877, Test loss : 0.631082, Validation loss : 0.700782\n",
            "\n",
            "======== Epoch 28 =========\n",
            "Train loss : 0.700434, Test loss : 0.620863, Validation loss : 0.691169\n",
            "\n",
            "======== Epoch 29 =========\n",
            "Train loss : 0.691970, Test loss : 0.612462, Validation loss : 0.681969\n",
            "\n",
            "======== Epoch 30 =========\n",
            "Train loss : 0.683874, Test loss : 0.602665, Validation loss : 0.673235\n",
            "\n",
            "======== Epoch 31 =========\n",
            "Train loss : 0.675826, Test loss : 0.594839, Validation loss : 0.664568\n",
            "\n",
            "======== Epoch 32 =========\n",
            "Train loss : 0.668216, Test loss : 0.585595, Validation loss : 0.656227\n",
            "\n",
            "======== Epoch 33 =========\n",
            "Train loss : 0.660534, Test loss : 0.578202, Validation loss : 0.648178\n",
            "\n",
            "======== Epoch 34 =========\n",
            "Train loss : 0.653410, Test loss : 0.569571, Validation loss : 0.640287\n",
            "\n",
            "======== Epoch 35 =========\n",
            "Train loss : 0.646127, Test loss : 0.562422, Validation loss : 0.632718\n",
            "\n",
            "======== Epoch 36 =========\n",
            "Train loss : 0.639319, Test loss : 0.554601, Validation loss : 0.625367\n",
            "\n",
            "======== Epoch 37 =========\n",
            "Train loss : 0.632547, Test loss : 0.547819, Validation loss : 0.618097\n",
            "\n",
            "======== Epoch 38 =========\n",
            "Train loss : 0.626089, Test loss : 0.540562, Validation loss : 0.611254\n",
            "\n",
            "======== Epoch 39 =========\n",
            "Train loss : 0.619739, Test loss : 0.534431, Validation loss : 0.604479\n",
            "\n",
            "======== Epoch 40 =========\n",
            "Train loss : 0.613680, Test loss : 0.527583, Validation loss : 0.598283\n",
            "\n",
            "======== Epoch 41 =========\n",
            "Train loss : 0.607690, Test loss : 0.520974, Validation loss : 0.592582\n",
            "\n",
            "======== Epoch 42 =========\n",
            "Train loss : 0.602019, Test loss : 0.514957, Validation loss : 0.586520\n",
            "\n",
            "======== Epoch 43 =========\n",
            "Train loss : 0.596492, Test loss : 0.509268, Validation loss : 0.580785\n",
            "\n",
            "======== Epoch 44 =========\n",
            "Train loss : 0.591121, Test loss : 0.503628, Validation loss : 0.574967\n",
            "\n",
            "======== Epoch 45 =========\n",
            "Train loss : 0.585883, Test loss : 0.498311, Validation loss : 0.569553\n",
            "\n",
            "======== Epoch 46 =========\n",
            "Train loss : 0.580790, Test loss : 0.492973, Validation loss : 0.564103\n",
            "\n",
            "======== Epoch 47 =========\n",
            "Train loss : 0.575834, Test loss : 0.487999, Validation loss : 0.558865\n",
            "\n",
            "======== Epoch 48 =========\n",
            "Train loss : 0.570989, Test loss : 0.483012, Validation loss : 0.553691\n",
            "\n",
            "======== Epoch 49 =========\n",
            "Train loss : 0.566268, Test loss : 0.478326, Validation loss : 0.548725\n",
            "\n",
            "======== Epoch 50 =========\n",
            "Train loss : 0.561685, Test loss : 0.473589, Validation loss : 0.543792\n",
            "\n",
            "======== Epoch 51 =========\n",
            "Train loss : 0.557203, Test loss : 0.469204, Validation loss : 0.539105\n",
            "\n",
            "======== Epoch 52 =========\n",
            "Train loss : 0.552841, Test loss : 0.464735, Validation loss : 0.534369\n",
            "\n",
            "======== Epoch 53 =========\n",
            "Train loss : 0.548565, Test loss : 0.460613, Validation loss : 0.529861\n",
            "\n",
            "======== Epoch 54 =========\n",
            "Train loss : 0.544406, Test loss : 0.456317, Validation loss : 0.525503\n",
            "\n",
            "======== Epoch 55 =========\n",
            "Train loss : 0.540328, Test loss : 0.452457, Validation loss : 0.521086\n",
            "\n",
            "======== Epoch 56 =========\n",
            "Train loss : 0.536352, Test loss : 0.448396, Validation loss : 0.516941\n",
            "\n",
            "======== Epoch 57 =========\n",
            "Train loss : 0.532470, Test loss : 0.444736, Validation loss : 0.512787\n",
            "\n",
            "======== Epoch 58 =========\n",
            "Train loss : 0.528675, Test loss : 0.440901, Validation loss : 0.508738\n",
            "\n",
            "======== Epoch 59 =========\n",
            "Train loss : 0.524943, Test loss : 0.437296, Validation loss : 0.504847\n",
            "\n",
            "======== Epoch 60 =========\n",
            "Train loss : 0.521313, Test loss : 0.433617, Validation loss : 0.501116\n",
            "\n",
            "======== Epoch 61 =========\n",
            "Train loss : 0.517766, Test loss : 0.430384, Validation loss : 0.497171\n",
            "\n",
            "======== Epoch 62 =========\n",
            "Train loss : 0.514289, Test loss : 0.426901, Validation loss : 0.493501\n",
            "\n",
            "======== Epoch 63 =========\n",
            "Train loss : 0.510849, Test loss : 0.423649, Validation loss : 0.489849\n",
            "\n",
            "======== Epoch 64 =========\n",
            "Train loss : 0.507503, Test loss : 0.420361, Validation loss : 0.486415\n",
            "\n",
            "======== Epoch 65 =========\n",
            "Train loss : 0.504223, Test loss : 0.417345, Validation loss : 0.482807\n",
            "\n",
            "======== Epoch 66 =========\n",
            "Train loss : 0.501005, Test loss : 0.414233, Validation loss : 0.479461\n",
            "\n",
            "======== Epoch 67 =========\n",
            "Train loss : 0.497849, Test loss : 0.411321, Validation loss : 0.475961\n",
            "\n",
            "======== Epoch 68 =========\n",
            "Train loss : 0.494755, Test loss : 0.408219, Validation loss : 0.472858\n",
            "\n",
            "======== Epoch 69 =========\n",
            "Train loss : 0.491714, Test loss : 0.405441, Validation loss : 0.469549\n",
            "\n",
            "======== Epoch 70 =========\n",
            "Train loss : 0.488723, Test loss : 0.402582, Validation loss : 0.466453\n",
            "\n",
            "======== Epoch 71 =========\n",
            "Train loss : 0.485786, Test loss : 0.399796, Validation loss : 0.463345\n",
            "\n",
            "======== Epoch 72 =========\n",
            "Train loss : 0.482897, Test loss : 0.397207, Validation loss : 0.460168\n",
            "\n",
            "======== Epoch 73 =========\n",
            "Train loss : 0.480054, Test loss : 0.394551, Validation loss : 0.457183\n",
            "\n",
            "======== Epoch 74 =========\n",
            "Train loss : 0.477269, Test loss : 0.391992, Validation loss : 0.454166\n",
            "\n",
            "======== Epoch 75 =========\n",
            "Train loss : 0.474516, Test loss : 0.389536, Validation loss : 0.451068\n",
            "\n",
            "======== Epoch 76 =========\n",
            "Train loss : 0.471817, Test loss : 0.386819, Validation loss : 0.448449\n",
            "\n",
            "======== Epoch 77 =========\n",
            "Train loss : 0.469149, Test loss : 0.384491, Validation loss : 0.445485\n",
            "\n",
            "======== Epoch 78 =========\n",
            "Train loss : 0.466519, Test loss : 0.382061, Validation loss : 0.442698\n",
            "\n",
            "======== Epoch 79 =========\n",
            "Train loss : 0.463936, Test loss : 0.379712, Validation loss : 0.439947\n",
            "\n",
            "======== Epoch 80 =========\n",
            "Train loss : 0.461388, Test loss : 0.377493, Validation loss : 0.437081\n",
            "\n",
            "======== Epoch 81 =========\n",
            "Train loss : 0.458876, Test loss : 0.375084, Validation loss : 0.434529\n",
            "\n",
            "======== Epoch 82 =========\n",
            "Train loss : 0.456393, Test loss : 0.372859, Validation loss : 0.431856\n",
            "\n",
            "======== Epoch 83 =========\n",
            "Train loss : 0.453947, Test loss : 0.370587, Validation loss : 0.429280\n",
            "\n",
            "======== Epoch 84 =========\n",
            "Train loss : 0.451534, Test loss : 0.368321, Validation loss : 0.426777\n",
            "\n",
            "======== Epoch 85 =========\n",
            "Train loss : 0.449149, Test loss : 0.366257, Validation loss : 0.424123\n",
            "\n",
            "======== Epoch 86 =========\n",
            "Train loss : 0.446793, Test loss : 0.364154, Validation loss : 0.421600\n",
            "\n",
            "======== Epoch 87 =========\n",
            "Train loss : 0.444463, Test loss : 0.361962, Validation loss : 0.419234\n",
            "\n",
            "======== Epoch 88 =========\n",
            "Train loss : 0.442161, Test loss : 0.359982, Validation loss : 0.416635\n",
            "\n",
            "======== Epoch 89 =========\n",
            "Train loss : 0.439885, Test loss : 0.357995, Validation loss : 0.414144\n",
            "\n",
            "======== Epoch 90 =========\n",
            "Train loss : 0.437631, Test loss : 0.355970, Validation loss : 0.411771\n",
            "\n",
            "======== Epoch 91 =========\n",
            "Train loss : 0.435402, Test loss : 0.353952, Validation loss : 0.409401\n",
            "\n",
            "======== Epoch 92 =========\n",
            "Train loss : 0.433195, Test loss : 0.352023, Validation loss : 0.407026\n",
            "\n",
            "======== Epoch 93 =========\n",
            "Train loss : 0.431008, Test loss : 0.350159, Validation loss : 0.404598\n",
            "\n",
            "======== Epoch 94 =========\n",
            "Train loss : 0.428843, Test loss : 0.348172, Validation loss : 0.402364\n",
            "\n",
            "======== Epoch 95 =========\n",
            "Train loss : 0.426700, Test loss : 0.346224, Validation loss : 0.400067\n",
            "\n",
            "======== Epoch 96 =========\n",
            "Train loss : 0.424574, Test loss : 0.344461, Validation loss : 0.397682\n",
            "\n",
            "======== Epoch 97 =========\n",
            "Train loss : 0.422468, Test loss : 0.342409, Validation loss : 0.395607\n",
            "\n",
            "======== Epoch 98 =========\n",
            "Train loss : 0.420380, Test loss : 0.340810, Validation loss : 0.393103\n",
            "\n",
            "======== Epoch 99 =========\n",
            "Train loss : 0.418303, Test loss : 0.338924, Validation loss : 0.390951\n",
            "\n",
            "======== Epoch 100 =========\n",
            "Train loss : 0.416251, Test loss : 0.336933, Validation loss : 0.388963\n",
            "\n",
            "======== Epoch 101 =========\n",
            "Train loss : 0.414214, Test loss : 0.335436, Validation loss : 0.386460\n",
            "\n",
            "======== Epoch 102 =========\n",
            "Train loss : 0.412194, Test loss : 0.333311, Validation loss : 0.384679\n",
            "\n",
            "======== Epoch 103 =========\n",
            "Train loss : 0.410191, Test loss : 0.331833, Validation loss : 0.382215\n",
            "\n",
            "======== Epoch 104 =========\n",
            "Train loss : 0.408199, Test loss : 0.329950, Validation loss : 0.380247\n",
            "\n",
            "======== Epoch 105 =========\n",
            "Train loss : 0.406227, Test loss : 0.328429, Validation loss : 0.377920\n",
            "\n",
            "======== Epoch 106 =========\n",
            "Train loss : 0.404270, Test loss : 0.326483, Validation loss : 0.376068\n",
            "\n",
            "======== Epoch 107 =========\n",
            "Train loss : 0.402328, Test loss : 0.324916, Validation loss : 0.373907\n",
            "\n",
            "======== Epoch 108 =========\n",
            "Train loss : 0.400395, Test loss : 0.323383, Validation loss : 0.371638\n",
            "\n",
            "======== Epoch 109 =========\n",
            "Train loss : 0.398479, Test loss : 0.321485, Validation loss : 0.369890\n",
            "\n",
            "======== Epoch 110 =========\n",
            "Train loss : 0.396576, Test loss : 0.320093, Validation loss : 0.367514\n",
            "\n",
            "======== Epoch 111 =========\n",
            "Train loss : 0.394681, Test loss : 0.318280, Validation loss : 0.365710\n",
            "\n",
            "======== Epoch 112 =========\n",
            "Train loss : 0.392798, Test loss : 0.316991, Validation loss : 0.363285\n",
            "\n",
            "======== Epoch 113 =========\n",
            "Train loss : 0.390930, Test loss : 0.314996, Validation loss : 0.361754\n",
            "\n",
            "======== Epoch 114 =========\n",
            "Train loss : 0.389064, Test loss : 0.313791, Validation loss : 0.359272\n",
            "\n",
            "======== Epoch 115 =========\n",
            "Train loss : 0.387212, Test loss : 0.311774, Validation loss : 0.357863\n",
            "\n",
            "======== Epoch 116 =========\n",
            "Train loss : 0.385381, Test loss : 0.310424, Validation loss : 0.355567\n",
            "\n",
            "======== Epoch 117 =========\n",
            "Train loss : 0.383559, Test loss : 0.308804, Validation loss : 0.353708\n",
            "\n",
            "======== Epoch 118 =========\n",
            "Train loss : 0.381739, Test loss : 0.307249, Validation loss : 0.351771\n",
            "\n",
            "======== Epoch 119 =========\n",
            "Train loss : 0.379937, Test loss : 0.305719, Validation loss : 0.349860\n",
            "\n",
            "======== Epoch 120 =========\n",
            "Train loss : 0.378147, Test loss : 0.304218, Validation loss : 0.347905\n",
            "\n",
            "======== Epoch 121 =========\n",
            "Train loss : 0.376367, Test loss : 0.302767, Validation loss : 0.345926\n",
            "\n",
            "======== Epoch 122 =========\n",
            "Train loss : 0.374596, Test loss : 0.301114, Validation loss : 0.344193\n",
            "\n",
            "======== Epoch 123 =========\n",
            "Train loss : 0.372834, Test loss : 0.299758, Validation loss : 0.342160\n",
            "\n",
            "======== Epoch 124 =========\n",
            "Train loss : 0.371084, Test loss : 0.298151, Validation loss : 0.340406\n",
            "\n",
            "======== Epoch 125 =========\n",
            "Train loss : 0.369345, Test loss : 0.296753, Validation loss : 0.338462\n",
            "\n",
            "======== Epoch 126 =========\n",
            "Train loss : 0.367616, Test loss : 0.295316, Validation loss : 0.336569\n",
            "\n",
            "======== Epoch 127 =========\n",
            "Train loss : 0.365896, Test loss : 0.293886, Validation loss : 0.334724\n",
            "\n",
            "======== Epoch 128 =========\n",
            "Train loss : 0.364186, Test loss : 0.292453, Validation loss : 0.332886\n",
            "\n",
            "======== Epoch 129 =========\n",
            "Train loss : 0.362488, Test loss : 0.290927, Validation loss : 0.331171\n",
            "\n",
            "======== Epoch 130 =========\n",
            "Train loss : 0.360798, Test loss : 0.289570, Validation loss : 0.329276\n",
            "\n",
            "======== Epoch 131 =========\n",
            "Train loss : 0.359116, Test loss : 0.288201, Validation loss : 0.327441\n",
            "\n",
            "======== Epoch 132 =========\n",
            "Train loss : 0.357445, Test loss : 0.286829, Validation loss : 0.325638\n",
            "\n",
            "======== Epoch 133 =========\n",
            "Train loss : 0.355786, Test loss : 0.285447, Validation loss : 0.323871\n",
            "\n",
            "======== Epoch 134 =========\n",
            "Train loss : 0.354135, Test loss : 0.283915, Validation loss : 0.322264\n",
            "\n",
            "======== Epoch 135 =========\n",
            "Train loss : 0.352495, Test loss : 0.282794, Validation loss : 0.320253\n",
            "\n",
            "======== Epoch 136 =========\n",
            "Train loss : 0.350864, Test loss : 0.281245, Validation loss : 0.318706\n",
            "\n",
            "======== Epoch 137 =========\n",
            "Train loss : 0.349240, Test loss : 0.279963, Validation loss : 0.316905\n",
            "\n",
            "======== Epoch 138 =========\n",
            "Train loss : 0.347623, Test loss : 0.278600, Validation loss : 0.315185\n",
            "\n",
            "======== Epoch 139 =========\n",
            "Train loss : 0.346018, Test loss : 0.277340, Validation loss : 0.313394\n",
            "\n",
            "======== Epoch 140 =========\n",
            "Train loss : 0.344419, Test loss : 0.276008, Validation loss : 0.311686\n",
            "\n",
            "======== Epoch 141 =========\n",
            "Train loss : 0.342829, Test loss : 0.274593, Validation loss : 0.310092\n",
            "\n",
            "======== Epoch 142 =========\n",
            "Train loss : 0.341245, Test loss : 0.273320, Validation loss : 0.308372\n",
            "\n",
            "======== Epoch 143 =========\n",
            "Train loss : 0.339671, Test loss : 0.272058, Validation loss : 0.306652\n",
            "\n",
            "======== Epoch 144 =========\n",
            "Train loss : 0.338104, Test loss : 0.270739, Validation loss : 0.305016\n",
            "\n",
            "======== Epoch 145 =========\n",
            "Train loss : 0.336550, Test loss : 0.269553, Validation loss : 0.303264\n",
            "\n",
            "======== Epoch 146 =========\n",
            "Train loss : 0.335005, Test loss : 0.268002, Validation loss : 0.301907\n",
            "\n",
            "======== Epoch 147 =========\n",
            "Train loss : 0.333469, Test loss : 0.267084, Validation loss : 0.299891\n",
            "\n",
            "======== Epoch 148 =========\n",
            "Train loss : 0.331938, Test loss : 0.265609, Validation loss : 0.298528\n",
            "\n",
            "======== Epoch 149 =========\n",
            "Train loss : 0.330417, Test loss : 0.264525, Validation loss : 0.296714\n",
            "\n",
            "======== Epoch 150 =========\n",
            "Train loss : 0.328905, Test loss : 0.263175, Validation loss : 0.295239\n",
            "\n",
            "======== Epoch 151 =========\n",
            "Train loss : 0.327403, Test loss : 0.262061, Validation loss : 0.293488\n",
            "\n",
            "======== Epoch 152 =========\n",
            "Train loss : 0.325908, Test loss : 0.260717, Validation loss : 0.292042\n",
            "\n",
            "======== Epoch 153 =========\n",
            "Train loss : 0.324422, Test loss : 0.259523, Validation loss : 0.290452\n",
            "\n",
            "======== Epoch 154 =========\n",
            "Train loss : 0.322944, Test loss : 0.258335, Validation loss : 0.288868\n",
            "\n",
            "======== Epoch 155 =========\n",
            "Train loss : 0.321474, Test loss : 0.257221, Validation loss : 0.287184\n",
            "\n",
            "======== Epoch 156 =========\n",
            "Train loss : 0.320013, Test loss : 0.255911, Validation loss : 0.285770\n",
            "\n",
            "======== Epoch 157 =========\n",
            "Train loss : 0.318557, Test loss : 0.254777, Validation loss : 0.284179\n",
            "\n",
            "======== Epoch 158 =========\n",
            "Train loss : 0.317113, Test loss : 0.253629, Validation loss : 0.282631\n",
            "\n",
            "======== Epoch 159 =========\n",
            "Train loss : 0.315680, Test loss : 0.252442, Validation loss : 0.281111\n",
            "\n",
            "======== Epoch 160 =========\n",
            "Train loss : 0.314257, Test loss : 0.251230, Validation loss : 0.279655\n",
            "\n",
            "======== Epoch 161 =========\n",
            "Train loss : 0.312842, Test loss : 0.250158, Validation loss : 0.278070\n",
            "\n",
            "======== Epoch 162 =========\n",
            "Train loss : 0.311434, Test loss : 0.248951, Validation loss : 0.276654\n",
            "\n",
            "======== Epoch 163 =========\n",
            "Train loss : 0.310035, Test loss : 0.247917, Validation loss : 0.275057\n",
            "\n",
            "======== Epoch 164 =========\n",
            "Train loss : 0.308646, Test loss : 0.246608, Validation loss : 0.273775\n",
            "\n",
            "======== Epoch 165 =========\n",
            "Train loss : 0.307263, Test loss : 0.245746, Validation loss : 0.272033\n",
            "\n",
            "======== Epoch 166 =========\n",
            "Train loss : 0.305890, Test loss : 0.244300, Validation loss : 0.270938\n",
            "\n",
            "======== Epoch 167 =========\n",
            "Train loss : 0.304520, Test loss : 0.243566, Validation loss : 0.269095\n",
            "\n",
            "======== Epoch 168 =========\n",
            "Train loss : 0.303161, Test loss : 0.242160, Validation loss : 0.267991\n",
            "\n",
            "======== Epoch 169 =========\n",
            "Train loss : 0.301803, Test loss : 0.241317, Validation loss : 0.266280\n",
            "\n",
            "======== Epoch 170 =========\n",
            "Train loss : 0.300461, Test loss : 0.240031, Validation loss : 0.265084\n",
            "\n",
            "======== Epoch 171 =========\n",
            "Train loss : 0.299121, Test loss : 0.239082, Validation loss : 0.263529\n",
            "\n",
            "======== Epoch 172 =========\n",
            "Train loss : 0.297792, Test loss : 0.237924, Validation loss : 0.262214\n",
            "\n",
            "======== Epoch 173 =========\n",
            "Train loss : 0.296473, Test loss : 0.237048, Validation loss : 0.260627\n",
            "\n",
            "======== Epoch 174 =========\n",
            "Train loss : 0.295159, Test loss : 0.235756, Validation loss : 0.259485\n",
            "\n",
            "======== Epoch 175 =========\n",
            "Train loss : 0.293849, Test loss : 0.234786, Validation loss : 0.258030\n",
            "\n",
            "======== Epoch 176 =========\n",
            "Train loss : 0.292550, Test loss : 0.233859, Validation loss : 0.256536\n",
            "\n",
            "======== Epoch 177 =========\n",
            "Train loss : 0.291259, Test loss : 0.232739, Validation loss : 0.255278\n",
            "\n",
            "======== Epoch 178 =========\n",
            "Train loss : 0.289973, Test loss : 0.231719, Validation loss : 0.253904\n",
            "\n",
            "======== Epoch 179 =========\n",
            "Train loss : 0.288697, Test loss : 0.230720, Validation loss : 0.252546\n",
            "\n",
            "======== Epoch 180 =========\n",
            "Train loss : 0.287429, Test loss : 0.229773, Validation loss : 0.251146\n",
            "\n",
            "======== Epoch 181 =========\n",
            "Train loss : 0.286168, Test loss : 0.228661, Validation loss : 0.249938\n",
            "\n",
            "======== Epoch 182 =========\n",
            "Train loss : 0.284917, Test loss : 0.227787, Validation loss : 0.248482\n",
            "\n",
            "======== Epoch 183 =========\n",
            "Train loss : 0.283672, Test loss : 0.226659, Validation loss : 0.247316\n",
            "\n",
            "======== Epoch 184 =========\n",
            "Train loss : 0.282435, Test loss : 0.225840, Validation loss : 0.245854\n",
            "\n",
            "======== Epoch 185 =========\n",
            "Train loss : 0.281206, Test loss : 0.224777, Validation loss : 0.244644\n",
            "\n",
            "======== Epoch 186 =========\n",
            "Train loss : 0.279985, Test loss : 0.223805, Validation loss : 0.243372\n",
            "\n",
            "======== Epoch 187 =========\n",
            "Train loss : 0.278774, Test loss : 0.222818, Validation loss : 0.242129\n",
            "\n",
            "======== Epoch 188 =========\n",
            "Train loss : 0.277571, Test loss : 0.221927, Validation loss : 0.240814\n",
            "\n",
            "======== Epoch 189 =========\n",
            "Train loss : 0.276375, Test loss : 0.220946, Validation loss : 0.239579\n",
            "\n",
            "======== Epoch 190 =========\n",
            "Train loss : 0.275188, Test loss : 0.220041, Validation loss : 0.238308\n",
            "\n",
            "======== Epoch 191 =========\n",
            "Train loss : 0.274006, Test loss : 0.219076, Validation loss : 0.237106\n",
            "\n",
            "======== Epoch 192 =========\n",
            "Train loss : 0.272834, Test loss : 0.218176, Validation loss : 0.235860\n",
            "\n",
            "======== Epoch 193 =========\n",
            "Train loss : 0.271667, Test loss : 0.217281, Validation loss : 0.234612\n",
            "\n",
            "======== Epoch 194 =========\n",
            "Train loss : 0.270510, Test loss : 0.216362, Validation loss : 0.233416\n",
            "\n",
            "======== Epoch 195 =========\n",
            "Train loss : 0.269360, Test loss : 0.215455, Validation loss : 0.232201\n",
            "\n",
            "======== Epoch 196 =========\n",
            "Train loss : 0.268217, Test loss : 0.214535, Validation loss : 0.231036\n",
            "\n",
            "======== Epoch 197 =========\n",
            "Train loss : 0.267082, Test loss : 0.213693, Validation loss : 0.229788\n",
            "\n",
            "======== Epoch 198 =========\n",
            "Train loss : 0.265954, Test loss : 0.212810, Validation loss : 0.228614\n",
            "\n",
            "======== Epoch 199 =========\n",
            "Train loss : 0.264835, Test loss : 0.211881, Validation loss : 0.227493\n",
            "\n",
            "======== Epoch 200 =========\n",
            "Train loss : 0.263721, Test loss : 0.211081, Validation loss : 0.226261\n",
            "\n",
            "======== Epoch 201 =========\n",
            "Train loss : 0.262614, Test loss : 0.210132, Validation loss : 0.225187\n",
            "\n",
            "======== Epoch 202 =========\n",
            "Train loss : 0.261516, Test loss : 0.209310, Validation loss : 0.224009\n",
            "\n",
            "======== Epoch 203 =========\n",
            "Train loss : 0.260425, Test loss : 0.208471, Validation loss : 0.222855\n",
            "\n",
            "======== Epoch 204 =========\n",
            "Train loss : 0.259343, Test loss : 0.207626, Validation loss : 0.221722\n",
            "\n",
            "======== Epoch 205 =========\n",
            "Train loss : 0.258269, Test loss : 0.206762, Validation loss : 0.220621\n",
            "\n",
            "======== Epoch 206 =========\n",
            "Train loss : 0.257202, Test loss : 0.205973, Validation loss : 0.219468\n",
            "\n",
            "======== Epoch 207 =========\n",
            "Train loss : 0.256142, Test loss : 0.205053, Validation loss : 0.218457\n",
            "\n",
            "======== Epoch 208 =========\n",
            "Train loss : 0.255090, Test loss : 0.204329, Validation loss : 0.217267\n",
            "\n",
            "======== Epoch 209 =========\n",
            "Train loss : 0.254045, Test loss : 0.203454, Validation loss : 0.216237\n",
            "\n",
            "======== Epoch 210 =========\n",
            "Train loss : 0.253007, Test loss : 0.202652, Validation loss : 0.215149\n",
            "\n",
            "======== Epoch 211 =========\n",
            "Train loss : 0.251977, Test loss : 0.201847, Validation loss : 0.214088\n",
            "\n",
            "======== Epoch 212 =========\n",
            "Train loss : 0.250954, Test loss : 0.201071, Validation loss : 0.213002\n",
            "\n",
            "======== Epoch 213 =========\n",
            "Train loss : 0.249939, Test loss : 0.200243, Validation loss : 0.211986\n",
            "\n",
            "======== Epoch 214 =========\n",
            "Train loss : 0.248930, Test loss : 0.199505, Validation loss : 0.210892\n",
            "\n",
            "======== Epoch 215 =========\n",
            "Train loss : 0.247930, Test loss : 0.198691, Validation loss : 0.209889\n",
            "\n",
            "======== Epoch 216 =========\n",
            "Train loss : 0.246936, Test loss : 0.197918, Validation loss : 0.208855\n",
            "\n",
            "======== Epoch 217 =========\n",
            "Train loss : 0.245950, Test loss : 0.197231, Validation loss : 0.207762\n",
            "\n",
            "======== Epoch 218 =========\n",
            "Train loss : 0.244970, Test loss : 0.196386, Validation loss : 0.206816\n",
            "\n",
            "======== Epoch 219 =========\n",
            "Train loss : 0.243998, Test loss : 0.195671, Validation loss : 0.205771\n",
            "\n",
            "======== Epoch 220 =========\n",
            "Train loss : 0.243032, Test loss : 0.194920, Validation loss : 0.204771\n",
            "\n",
            "======== Epoch 221 =========\n",
            "Train loss : 0.242072, Test loss : 0.194205, Validation loss : 0.203749\n",
            "\n",
            "======== Epoch 222 =========\n",
            "Train loss : 0.241119, Test loss : 0.193403, Validation loss : 0.202818\n",
            "\n",
            "======== Epoch 223 =========\n",
            "Train loss : 0.240173, Test loss : 0.192722, Validation loss : 0.201786\n",
            "\n",
            "======== Epoch 224 =========\n",
            "Train loss : 0.239234, Test loss : 0.191963, Validation loss : 0.200840\n",
            "\n",
            "======== Epoch 225 =========\n",
            "Train loss : 0.238300, Test loss : 0.191293, Validation loss : 0.199830\n",
            "\n",
            "======== Epoch 226 =========\n",
            "Train loss : 0.237374, Test loss : 0.190464, Validation loss : 0.198961\n",
            "\n",
            "======== Epoch 227 =========\n",
            "Train loss : 0.236455, Test loss : 0.189855, Validation loss : 0.197924\n",
            "\n",
            "======== Epoch 228 =========\n",
            "Train loss : 0.235541, Test loss : 0.189106, Validation loss : 0.197017\n",
            "\n",
            "======== Epoch 229 =========\n",
            "Train loss : 0.234634, Test loss : 0.188370, Validation loss : 0.196108\n",
            "\n",
            "======== Epoch 230 =========\n",
            "Train loss : 0.233735, Test loss : 0.187797, Validation loss : 0.195075\n",
            "\n",
            "======== Epoch 231 =========\n",
            "Train loss : 0.232841, Test loss : 0.186955, Validation loss : 0.194278\n",
            "\n",
            "======== Epoch 232 =========\n",
            "Train loss : 0.231954, Test loss : 0.186377, Validation loss : 0.193270\n",
            "\n",
            "======== Epoch 233 =========\n",
            "Train loss : 0.231072, Test loss : 0.185730, Validation loss : 0.192338\n",
            "\n",
            "======== Epoch 234 =========\n",
            "Train loss : 0.230198, Test loss : 0.184891, Validation loss : 0.191563\n",
            "\n",
            "======== Epoch 235 =========\n",
            "Train loss : 0.229330, Test loss : 0.184407, Validation loss : 0.190514\n",
            "\n",
            "======== Epoch 236 =========\n",
            "Train loss : 0.228469, Test loss : 0.183604, Validation loss : 0.189739\n",
            "\n",
            "======== Epoch 237 =========\n",
            "Train loss : 0.227614, Test loss : 0.183101, Validation loss : 0.188730\n",
            "\n",
            "======== Epoch 238 =========\n",
            "Train loss : 0.226767, Test loss : 0.182294, Validation loss : 0.187981\n",
            "\n",
            "======== Epoch 239 =========\n",
            "Train loss : 0.225925, Test loss : 0.181760, Validation loss : 0.187020\n",
            "\n",
            "======== Epoch 240 =========\n",
            "Train loss : 0.225090, Test loss : 0.181014, Validation loss : 0.186244\n",
            "\n",
            "======== Epoch 241 =========\n",
            "Train loss : 0.224262, Test loss : 0.180495, Validation loss : 0.185292\n",
            "\n",
            "======== Epoch 242 =========\n",
            "Train loss : 0.223439, Test loss : 0.179745, Validation loss : 0.184536\n",
            "\n",
            "======== Epoch 243 =========\n",
            "Train loss : 0.222622, Test loss : 0.179278, Validation loss : 0.183567\n",
            "\n",
            "======== Epoch 244 =========\n",
            "Train loss : 0.221812, Test loss : 0.178497, Validation loss : 0.182858\n",
            "\n",
            "======== Epoch 245 =========\n",
            "Train loss : 0.221008, Test loss : 0.178012, Validation loss : 0.181924\n",
            "\n",
            "======== Epoch 246 =========\n",
            "Train loss : 0.220209, Test loss : 0.177337, Validation loss : 0.181151\n",
            "\n",
            "======== Epoch 247 =========\n",
            "Train loss : 0.219416, Test loss : 0.176752, Validation loss : 0.180318\n",
            "\n",
            "======== Epoch 248 =========\n",
            "Train loss : 0.218629, Test loss : 0.176109, Validation loss : 0.179541\n",
            "\n",
            "======== Epoch 249 =========\n",
            "Train loss : 0.217848, Test loss : 0.175535, Validation loss : 0.178719\n",
            "\n",
            "======== Epoch 250 =========\n",
            "Train loss : 0.217073, Test loss : 0.175076, Validation loss : 0.177816\n",
            "\n",
            "======== Epoch 251 =========\n",
            "Train loss : 0.216303, Test loss : 0.174276, Validation loss : 0.177189\n",
            "\n",
            "======== Epoch 252 =========\n",
            "Train loss : 0.215539, Test loss : 0.173895, Validation loss : 0.176248\n",
            "\n",
            "======== Epoch 253 =========\n",
            "Train loss : 0.214781, Test loss : 0.173138, Validation loss : 0.175606\n",
            "\n",
            "======== Epoch 254 =========\n",
            "Train loss : 0.214028, Test loss : 0.172754, Validation loss : 0.174688\n",
            "\n",
            "======== Epoch 255 =========\n",
            "Train loss : 0.213281, Test loss : 0.172071, Validation loss : 0.174005\n",
            "\n",
            "======== Epoch 256 =========\n",
            "Train loss : 0.212539, Test loss : 0.171538, Validation loss : 0.173219\n",
            "\n",
            "======== Epoch 257 =========\n",
            "Train loss : 0.211802, Test loss : 0.170944, Validation loss : 0.172488\n",
            "\n",
            "======== Epoch 258 =========\n",
            "Train loss : 0.211071, Test loss : 0.170458, Validation loss : 0.171687\n",
            "\n",
            "======== Epoch 259 =========\n",
            "Train loss : 0.210346, Test loss : 0.169837, Validation loss : 0.170997\n",
            "\n",
            "======== Epoch 260 =========\n",
            "Train loss : 0.209625, Test loss : 0.169393, Validation loss : 0.170178\n",
            "\n",
            "======== Epoch 261 =========\n",
            "Train loss : 0.208910, Test loss : 0.168762, Validation loss : 0.169510\n",
            "\n",
            "======== Epoch 262 =========\n",
            "Train loss : 0.208200, Test loss : 0.168309, Validation loss : 0.168722\n",
            "\n",
            "======== Epoch 263 =========\n",
            "Train loss : 0.207495, Test loss : 0.167743, Validation loss : 0.168024\n",
            "\n",
            "======== Epoch 264 =========\n",
            "Train loss : 0.206795, Test loss : 0.167171, Validation loss : 0.167334\n",
            "\n",
            "======== Epoch 265 =========\n",
            "Train loss : 0.206099, Test loss : 0.166718, Validation loss : 0.166570\n",
            "\n",
            "======== Epoch 266 =========\n",
            "Train loss : 0.205409, Test loss : 0.166158, Validation loss : 0.165891\n",
            "\n",
            "======== Epoch 267 =========\n",
            "Train loss : 0.204723, Test loss : 0.165689, Validation loss : 0.165155\n",
            "\n",
            "======== Epoch 268 =========\n",
            "Train loss : 0.204042, Test loss : 0.165090, Validation loss : 0.164524\n",
            "\n",
            "======== Epoch 269 =========\n",
            "Train loss : 0.203366, Test loss : 0.164684, Validation loss : 0.163759\n",
            "\n",
            "======== Epoch 270 =========\n",
            "Train loss : 0.202696, Test loss : 0.164131, Validation loss : 0.163106\n",
            "\n",
            "======== Epoch 271 =========\n",
            "Train loss : 0.202029, Test loss : 0.163697, Validation loss : 0.162382\n",
            "\n",
            "======== Epoch 272 =========\n",
            "Train loss : 0.201368, Test loss : 0.163113, Validation loss : 0.161767\n",
            "\n",
            "======== Epoch 273 =========\n",
            "Train loss : 0.200711, Test loss : 0.162683, Validation loss : 0.161054\n",
            "\n",
            "======== Epoch 274 =========\n",
            "Train loss : 0.200059, Test loss : 0.162154, Validation loss : 0.160414\n",
            "\n",
            "======== Epoch 275 =========\n",
            "Train loss : 0.199411, Test loss : 0.161769, Validation loss : 0.159685\n",
            "\n",
            "======== Epoch 276 =========\n",
            "Train loss : 0.198768, Test loss : 0.161170, Validation loss : 0.159108\n",
            "\n",
            "======== Epoch 277 =========\n",
            "Train loss : 0.198129, Test loss : 0.160790, Validation loss : 0.158389\n",
            "\n",
            "======== Epoch 278 =========\n",
            "Train loss : 0.197495, Test loss : 0.160222, Validation loss : 0.157808\n",
            "\n",
            "======== Epoch 279 =========\n",
            "Train loss : 0.196865, Test loss : 0.159924, Validation loss : 0.157049\n",
            "\n",
            "======== Epoch 280 =========\n",
            "Train loss : 0.196241, Test loss : 0.159315, Validation loss : 0.156506\n",
            "\n",
            "======== Epoch 281 =========\n",
            "Train loss : 0.195620, Test loss : 0.158917, Validation loss : 0.155830\n",
            "\n",
            "======== Epoch 282 =========\n",
            "Train loss : 0.195005, Test loss : 0.158427, Validation loss : 0.155224\n",
            "\n",
            "======== Epoch 283 =========\n",
            "Train loss : 0.194393, Test loss : 0.157977, Validation loss : 0.154596\n",
            "\n",
            "======== Epoch 284 =========\n",
            "Train loss : 0.193785, Test loss : 0.157572, Validation loss : 0.153943\n",
            "\n",
            "======== Epoch 285 =========\n",
            "Train loss : 0.193182, Test loss : 0.157056, Validation loss : 0.153372\n",
            "\n",
            "======== Epoch 286 =========\n",
            "Train loss : 0.192584, Test loss : 0.156671, Validation loss : 0.152725\n",
            "\n",
            "======== Epoch 287 =========\n",
            "Train loss : 0.191990, Test loss : 0.156197, Validation loss : 0.152141\n",
            "\n",
            "======== Epoch 288 =========\n",
            "Train loss : 0.191401, Test loss : 0.155771, Validation loss : 0.151533\n",
            "\n",
            "======== Epoch 289 =========\n",
            "Train loss : 0.190816, Test loss : 0.155396, Validation loss : 0.150897\n",
            "\n",
            "======== Epoch 290 =========\n",
            "Train loss : 0.190235, Test loss : 0.154864, Validation loss : 0.150373\n",
            "\n",
            "======== Epoch 291 =========\n",
            "Train loss : 0.189658, Test loss : 0.154509, Validation loss : 0.149741\n",
            "\n",
            "======== Epoch 292 =========\n",
            "Train loss : 0.189085, Test loss : 0.154082, Validation loss : 0.149162\n",
            "\n",
            "======== Epoch 293 =========\n",
            "Train loss : 0.188517, Test loss : 0.153677, Validation loss : 0.148573\n",
            "\n",
            "======== Epoch 294 =========\n",
            "Train loss : 0.187952, Test loss : 0.153186, Validation loss : 0.148042\n",
            "\n",
            "======== Epoch 295 =========\n",
            "Train loss : 0.187392, Test loss : 0.152850, Validation loss : 0.147426\n",
            "\n",
            "======== Epoch 296 =========\n",
            "Train loss : 0.186836, Test loss : 0.152337, Validation loss : 0.146924\n",
            "\n",
            "======== Epoch 297 =========\n",
            "Train loss : 0.186283, Test loss : 0.152075, Validation loss : 0.146271\n",
            "\n",
            "======== Epoch 298 =========\n",
            "Train loss : 0.185735, Test loss : 0.151520, Validation loss : 0.145810\n",
            "\n",
            "======== Epoch 299 =========\n",
            "Train loss : 0.185191, Test loss : 0.151245, Validation loss : 0.145178\n",
            "\n",
            "======== Epoch 300 =========\n",
            "Train loss : 0.184651, Test loss : 0.150742, Validation loss : 0.144695\n",
            "\n",
            "======== Epoch 301 =========\n",
            "Train loss : 0.184114, Test loss : 0.150455, Validation loss : 0.144084\n",
            "\n",
            "======== Epoch 302 =========\n",
            "Train loss : 0.183582, Test loss : 0.149940, Validation loss : 0.143618\n",
            "\n",
            "======== Epoch 303 =========\n",
            "Train loss : 0.183053, Test loss : 0.149705, Validation loss : 0.142987\n",
            "\n",
            "======== Epoch 304 =========\n",
            "Train loss : 0.182527, Test loss : 0.149152, Validation loss : 0.142552\n",
            "\n",
            "======== Epoch 305 =========\n",
            "Train loss : 0.182002, Test loss : 0.148911, Validation loss : 0.141934\n",
            "\n",
            "======== Epoch 306 =========\n",
            "Train loss : 0.181480, Test loss : 0.148401, Validation loss : 0.141482\n",
            "\n",
            "======== Epoch 307 =========\n",
            "Train loss : 0.180963, Test loss : 0.148164, Validation loss : 0.140874\n",
            "\n",
            "======== Epoch 308 =========\n",
            "Train loss : 0.180449, Test loss : 0.147688, Validation loss : 0.140411\n",
            "\n",
            "======== Epoch 309 =========\n",
            "Train loss : 0.179938, Test loss : 0.147314, Validation loss : 0.139896\n",
            "\n",
            "======== Epoch 310 =========\n",
            "Train loss : 0.179432, Test loss : 0.147006, Validation loss : 0.139348\n",
            "\n",
            "======== Epoch 311 =========\n",
            "Train loss : 0.178929, Test loss : 0.146557, Validation loss : 0.138889\n",
            "\n",
            "======== Epoch 312 =========\n",
            "Train loss : 0.178429, Test loss : 0.146311, Validation loss : 0.138317\n",
            "\n",
            "======== Epoch 313 =========\n",
            "Train loss : 0.177932, Test loss : 0.145814, Validation loss : 0.137894\n",
            "\n",
            "======== Epoch 314 =========\n",
            "Train loss : 0.177440, Test loss : 0.145595, Validation loss : 0.137320\n",
            "\n",
            "======== Epoch 315 =========\n",
            "Train loss : 0.176950, Test loss : 0.145086, Validation loss : 0.136915\n",
            "\n",
            "======== Epoch 316 =========\n",
            "Train loss : 0.176464, Test loss : 0.144889, Validation loss : 0.136339\n",
            "\n",
            "======== Epoch 317 =========\n",
            "Train loss : 0.175982, Test loss : 0.144411, Validation loss : 0.135927\n",
            "\n",
            "======== Epoch 318 =========\n",
            "Train loss : 0.175502, Test loss : 0.144203, Validation loss : 0.135366\n",
            "\n",
            "======== Epoch 319 =========\n",
            "Train loss : 0.175026, Test loss : 0.143672, Validation loss : 0.134992\n",
            "\n",
            "======== Epoch 320 =========\n",
            "Train loss : 0.174552, Test loss : 0.143568, Validation loss : 0.134383\n",
            "\n",
            "======== Epoch 321 =========\n",
            "Train loss : 0.174081, Test loss : 0.142989, Validation loss : 0.134043\n",
            "\n",
            "======== Epoch 322 =========\n",
            "Train loss : 0.173614, Test loss : 0.142841, Validation loss : 0.133470\n",
            "\n",
            "======== Epoch 323 =========\n",
            "Train loss : 0.173151, Test loss : 0.142351, Validation loss : 0.133091\n",
            "\n",
            "======== Epoch 324 =========\n",
            "Train loss : 0.172691, Test loss : 0.142138, Validation loss : 0.132565\n",
            "\n",
            "======== Epoch 325 =========\n",
            "Train loss : 0.172234, Test loss : 0.141681, Validation loss : 0.132178\n",
            "\n",
            "======== Epoch 326 =========\n",
            "Train loss : 0.171781, Test loss : 0.141480, Validation loss : 0.131656\n",
            "\n",
            "======== Epoch 327 =========\n",
            "Train loss : 0.171330, Test loss : 0.141025, Validation loss : 0.131274\n",
            "\n",
            "======== Epoch 328 =========\n",
            "Train loss : 0.170884, Test loss : 0.140798, Validation loss : 0.130777\n",
            "\n",
            "======== Epoch 329 =========\n",
            "Train loss : 0.170439, Test loss : 0.140438, Validation loss : 0.130350\n",
            "\n",
            "======== Epoch 330 =========\n",
            "Train loss : 0.169998, Test loss : 0.140124, Validation loss : 0.129903\n",
            "\n",
            "======== Epoch 331 =========\n",
            "Train loss : 0.169560, Test loss : 0.139797, Validation loss : 0.129466\n",
            "\n",
            "======== Epoch 332 =========\n",
            "Train loss : 0.169125, Test loss : 0.139491, Validation loss : 0.129023\n",
            "\n",
            "======== Epoch 333 =========\n",
            "Train loss : 0.168693, Test loss : 0.139198, Validation loss : 0.128576\n",
            "\n",
            "======== Epoch 334 =========\n",
            "Train loss : 0.168263, Test loss : 0.138867, Validation loss : 0.128153\n",
            "\n",
            "======== Epoch 335 =========\n",
            "Train loss : 0.167835, Test loss : 0.138613, Validation loss : 0.127689\n",
            "\n",
            "======== Epoch 336 =========\n",
            "Train loss : 0.167409, Test loss : 0.138235, Validation loss : 0.127292\n",
            "\n",
            "======== Epoch 337 =========\n",
            "Train loss : 0.166985, Test loss : 0.138036, Validation loss : 0.126804\n",
            "\n",
            "======== Epoch 338 =========\n",
            "Train loss : 0.166562, Test loss : 0.137637, Validation loss : 0.126423\n",
            "\n",
            "======== Epoch 339 =========\n",
            "Train loss : 0.166139, Test loss : 0.137401, Validation loss : 0.125961\n",
            "\n",
            "======== Epoch 340 =========\n",
            "Train loss : 0.165713, Test loss : 0.137090, Validation loss : 0.125538\n",
            "\n",
            "======== Epoch 341 =========\n",
            "Train loss : 0.165290, Test loss : 0.136766, Validation loss : 0.125127\n",
            "\n",
            "======== Epoch 342 =========\n",
            "Train loss : 0.164872, Test loss : 0.136524, Validation loss : 0.124679\n",
            "\n",
            "======== Epoch 343 =========\n",
            "Train loss : 0.164458, Test loss : 0.136156, Validation loss : 0.124299\n",
            "\n",
            "======== Epoch 344 =========\n",
            "Train loss : 0.164048, Test loss : 0.135910, Validation loss : 0.123862\n",
            "\n",
            "======== Epoch 345 =========\n",
            "Train loss : 0.163643, Test loss : 0.135576, Validation loss : 0.123475\n",
            "\n",
            "======== Epoch 346 =========\n",
            "Train loss : 0.163241, Test loss : 0.135297, Validation loss : 0.123062\n",
            "\n",
            "======== Epoch 347 =========\n",
            "Train loss : 0.162841, Test loss : 0.135034, Validation loss : 0.122653\n",
            "\n",
            "======== Epoch 348 =========\n",
            "Train loss : 0.162445, Test loss : 0.134728, Validation loss : 0.122271\n",
            "\n",
            "======== Epoch 349 =========\n",
            "Train loss : 0.162053, Test loss : 0.134519, Validation loss : 0.121846\n",
            "\n",
            "======== Epoch 350 =========\n",
            "Train loss : 0.161666, Test loss : 0.134139, Validation loss : 0.121511\n",
            "\n",
            "======== Epoch 351 =========\n",
            "Train loss : 0.161283, Test loss : 0.133987, Validation loss : 0.121070\n",
            "\n",
            "======== Epoch 352 =========\n",
            "Train loss : 0.160904, Test loss : 0.133615, Validation loss : 0.120742\n",
            "\n",
            "======== Epoch 353 =========\n",
            "Train loss : 0.160529, Test loss : 0.133427, Validation loss : 0.120328\n",
            "\n",
            "======== Epoch 354 =========\n",
            "Train loss : 0.160154, Test loss : 0.133098, Validation loss : 0.119985\n",
            "\n",
            "======== Epoch 355 =========\n",
            "Train loss : 0.159781, Test loss : 0.132909, Validation loss : 0.119580\n",
            "\n",
            "======== Epoch 356 =========\n",
            "Train loss : 0.159412, Test loss : 0.132605, Validation loss : 0.119234\n",
            "\n",
            "======== Epoch 357 =========\n",
            "Train loss : 0.159048, Test loss : 0.132352, Validation loss : 0.118869\n",
            "\n",
            "======== Epoch 358 =========\n",
            "Train loss : 0.158685, Test loss : 0.132079, Validation loss : 0.118515\n",
            "\n",
            "======== Epoch 359 =========\n",
            "Train loss : 0.158326, Test loss : 0.131863, Validation loss : 0.118138\n",
            "\n",
            "======== Epoch 360 =========\n",
            "Train loss : 0.157968, Test loss : 0.131530, Validation loss : 0.117819\n",
            "\n",
            "======== Epoch 361 =========\n",
            "Train loss : 0.157614, Test loss : 0.131399, Validation loss : 0.117410\n",
            "\n",
            "======== Epoch 362 =========\n",
            "Train loss : 0.157262, Test loss : 0.131020, Validation loss : 0.117118\n",
            "\n",
            "======== Epoch 363 =========\n",
            "Train loss : 0.156913, Test loss : 0.130928, Validation loss : 0.116699\n",
            "\n",
            "======== Epoch 364 =========\n",
            "Train loss : 0.156565, Test loss : 0.130493, Validation loss : 0.116439\n",
            "\n",
            "======== Epoch 365 =========\n",
            "Train loss : 0.156220, Test loss : 0.130396, Validation loss : 0.116027\n",
            "\n",
            "======== Epoch 366 =========\n",
            "Train loss : 0.155876, Test loss : 0.130060, Validation loss : 0.115727\n",
            "\n",
            "======== Epoch 367 =========\n",
            "Train loss : 0.155535, Test loss : 0.129908, Validation loss : 0.115348\n",
            "\n",
            "======== Epoch 368 =========\n",
            "Train loss : 0.155198, Test loss : 0.129561, Validation loss : 0.115059\n",
            "\n",
            "======== Epoch 369 =========\n",
            "Train loss : 0.154863, Test loss : 0.129432, Validation loss : 0.114677\n",
            "\n",
            "======== Epoch 370 =========\n",
            "Train loss : 0.154530, Test loss : 0.129066, Validation loss : 0.114403\n",
            "\n",
            "======== Epoch 371 =========\n",
            "Train loss : 0.154200, Test loss : 0.128972, Validation loss : 0.114012\n",
            "\n",
            "======== Epoch 372 =========\n",
            "Train loss : 0.153871, Test loss : 0.128590, Validation loss : 0.113750\n",
            "\n",
            "======== Epoch 373 =========\n",
            "Train loss : 0.153545, Test loss : 0.128494, Validation loss : 0.113367\n",
            "\n",
            "======== Epoch 374 =========\n",
            "Train loss : 0.153221, Test loss : 0.128102, Validation loss : 0.113115\n",
            "\n",
            "======== Epoch 375 =========\n",
            "Train loss : 0.152899, Test loss : 0.128029, Validation loss : 0.112728\n",
            "\n",
            "======== Epoch 376 =========\n",
            "Train loss : 0.152579, Test loss : 0.127686, Validation loss : 0.112459\n",
            "\n",
            "======== Epoch 377 =========\n",
            "Train loss : 0.152262, Test loss : 0.127621, Validation loss : 0.112075\n",
            "\n",
            "======== Epoch 378 =========\n",
            "Train loss : 0.151947, Test loss : 0.127203, Validation loss : 0.111845\n",
            "\n",
            "======== Epoch 379 =========\n",
            "Train loss : 0.151634, Test loss : 0.127165, Validation loss : 0.111456\n",
            "\n",
            "======== Epoch 380 =========\n",
            "Train loss : 0.151323, Test loss : 0.126777, Validation loss : 0.111218\n",
            "\n",
            "======== Epoch 381 =========\n",
            "Train loss : 0.151014, Test loss : 0.126724, Validation loss : 0.110841\n",
            "\n",
            "======== Epoch 382 =========\n",
            "Train loss : 0.150708, Test loss : 0.126347, Validation loss : 0.110603\n",
            "\n",
            "======== Epoch 383 =========\n",
            "Train loss : 0.150403, Test loss : 0.126277, Validation loss : 0.110239\n",
            "\n",
            "======== Epoch 384 =========\n",
            "Train loss : 0.150100, Test loss : 0.125912, Validation loss : 0.110001\n",
            "\n",
            "======== Epoch 385 =========\n",
            "Train loss : 0.149799, Test loss : 0.125875, Validation loss : 0.109630\n",
            "\n",
            "======== Epoch 386 =========\n",
            "Train loss : 0.149500, Test loss : 0.125448, Validation loss : 0.109415\n",
            "\n",
            "======== Epoch 387 =========\n",
            "Train loss : 0.149203, Test loss : 0.125421, Validation loss : 0.109045\n",
            "\n",
            "======== Epoch 388 =========\n",
            "Train loss : 0.148907, Test loss : 0.125072, Validation loss : 0.108810\n",
            "\n",
            "======== Epoch 389 =========\n",
            "Train loss : 0.148613, Test loss : 0.124962, Validation loss : 0.108479\n",
            "\n",
            "======== Epoch 390 =========\n",
            "Train loss : 0.148321, Test loss : 0.124696, Validation loss : 0.108215\n",
            "\n",
            "======== Epoch 391 =========\n",
            "Train loss : 0.148031, Test loss : 0.124553, Validation loss : 0.107902\n",
            "\n",
            "======== Epoch 392 =========\n",
            "Train loss : 0.147742, Test loss : 0.124298, Validation loss : 0.107638\n",
            "\n",
            "======== Epoch 393 =========\n",
            "Train loss : 0.147456, Test loss : 0.124112, Validation loss : 0.107348\n",
            "\n",
            "======== Epoch 394 =========\n",
            "Train loss : 0.147171, Test loss : 0.123932, Validation loss : 0.107057\n",
            "\n",
            "======== Epoch 395 =========\n",
            "Train loss : 0.146888, Test loss : 0.123728, Validation loss : 0.106778\n",
            "\n",
            "======== Epoch 396 =========\n",
            "Train loss : 0.146606, Test loss : 0.123504, Validation loss : 0.106510\n",
            "\n",
            "======== Epoch 397 =========\n",
            "Train loss : 0.146326, Test loss : 0.123345, Validation loss : 0.106218\n",
            "\n",
            "======== Epoch 398 =========\n",
            "Train loss : 0.146046, Test loss : 0.123084, Validation loss : 0.105968\n",
            "\n",
            "======== Epoch 399 =========\n",
            "Train loss : 0.145768, Test loss : 0.122965, Validation loss : 0.105664\n",
            "\n",
            "======== Epoch 400 =========\n",
            "Train loss : 0.145491, Test loss : 0.122721, Validation loss : 0.105410\n",
            "\n",
            "======== Epoch 401 =========\n",
            "Train loss : 0.145216, Test loss : 0.122538, Validation loss : 0.105134\n",
            "\n",
            "======== Epoch 402 =========\n",
            "Train loss : 0.144943, Test loss : 0.122340, Validation loss : 0.104867\n",
            "\n",
            "======== Epoch 403 =========\n",
            "Train loss : 0.144671, Test loss : 0.122151, Validation loss : 0.104597\n",
            "\n",
            "======== Epoch 404 =========\n",
            "Train loss : 0.144400, Test loss : 0.121948, Validation loss : 0.104335\n",
            "\n",
            "======== Epoch 405 =========\n",
            "Train loss : 0.144131, Test loss : 0.121779, Validation loss : 0.104062\n",
            "\n",
            "======== Epoch 406 =========\n",
            "Train loss : 0.143863, Test loss : 0.121577, Validation loss : 0.103804\n",
            "\n",
            "======== Epoch 407 =========\n",
            "Train loss : 0.143596, Test loss : 0.121383, Validation loss : 0.103544\n",
            "\n",
            "======== Epoch 408 =========\n",
            "Train loss : 0.143330, Test loss : 0.121204, Validation loss : 0.103281\n",
            "\n",
            "======== Epoch 409 =========\n",
            "Train loss : 0.143066, Test loss : 0.121053, Validation loss : 0.103009\n",
            "\n",
            "======== Epoch 410 =========\n",
            "Train loss : 0.142804, Test loss : 0.120811, Validation loss : 0.102774\n",
            "\n",
            "======== Epoch 411 =========\n",
            "Train loss : 0.142544, Test loss : 0.120614, Validation loss : 0.102515\n",
            "\n",
            "======== Epoch 412 =========\n",
            "Train loss : 0.142285, Test loss : 0.120466, Validation loss : 0.102246\n",
            "\n",
            "======== Epoch 413 =========\n",
            "Train loss : 0.142026, Test loss : 0.120262, Validation loss : 0.101999\n",
            "\n",
            "======== Epoch 414 =========\n",
            "Train loss : 0.141769, Test loss : 0.120114, Validation loss : 0.101733\n",
            "\n",
            "======== Epoch 415 =========\n",
            "Train loss : 0.141514, Test loss : 0.119890, Validation loss : 0.101498\n",
            "\n",
            "======== Epoch 416 =========\n",
            "Train loss : 0.141260, Test loss : 0.119736, Validation loss : 0.101239\n",
            "\n",
            "======== Epoch 417 =========\n",
            "Train loss : 0.141007, Test loss : 0.119533, Validation loss : 0.101000\n",
            "\n",
            "======== Epoch 418 =========\n",
            "Train loss : 0.140757, Test loss : 0.119417, Validation loss : 0.100731\n",
            "\n",
            "======== Epoch 419 =========\n",
            "Train loss : 0.140507, Test loss : 0.119183, Validation loss : 0.100507\n",
            "\n",
            "======== Epoch 420 =========\n",
            "Train loss : 0.140260, Test loss : 0.119041, Validation loss : 0.100252\n",
            "\n",
            "======== Epoch 421 =========\n",
            "Train loss : 0.140013, Test loss : 0.118825, Validation loss : 0.100026\n",
            "\n",
            "======== Epoch 422 =========\n",
            "Train loss : 0.139769, Test loss : 0.118737, Validation loss : 0.099754\n",
            "\n",
            "======== Epoch 423 =========\n",
            "Train loss : 0.139526, Test loss : 0.118482, Validation loss : 0.099543\n",
            "\n",
            "======== Epoch 424 =========\n",
            "Train loss : 0.139284, Test loss : 0.118381, Validation loss : 0.099280\n",
            "\n",
            "======== Epoch 425 =========\n",
            "Train loss : 0.139044, Test loss : 0.118136, Validation loss : 0.099068\n",
            "\n",
            "======== Epoch 426 =========\n",
            "Train loss : 0.138806, Test loss : 0.118040, Validation loss : 0.098807\n",
            "\n",
            "======== Epoch 427 =========\n",
            "Train loss : 0.138569, Test loss : 0.117815, Validation loss : 0.098592\n",
            "\n",
            "======== Epoch 428 =========\n",
            "Train loss : 0.138333, Test loss : 0.117733, Validation loss : 0.098331\n",
            "\n",
            "======== Epoch 429 =========\n",
            "Train loss : 0.138099, Test loss : 0.117483, Validation loss : 0.098127\n",
            "\n",
            "======== Epoch 430 =========\n",
            "Train loss : 0.137866, Test loss : 0.117379, Validation loss : 0.097875\n",
            "\n",
            "======== Epoch 431 =========\n",
            "Train loss : 0.137635, Test loss : 0.117141, Validation loss : 0.097669\n",
            "\n",
            "======== Epoch 432 =========\n",
            "Train loss : 0.137403, Test loss : 0.117042, Validation loss : 0.097418\n",
            "\n",
            "======== Epoch 433 =========\n",
            "Train loss : 0.137172, Test loss : 0.116843, Validation loss : 0.097203\n",
            "\n",
            "======== Epoch 434 =========\n",
            "Train loss : 0.136943, Test loss : 0.116662, Validation loss : 0.096975\n",
            "\n",
            "======== Epoch 435 =========\n",
            "Train loss : 0.136716, Test loss : 0.116539, Validation loss : 0.096737\n",
            "\n",
            "======== Epoch 436 =========\n",
            "Train loss : 0.136490, Test loss : 0.116341, Validation loss : 0.096525\n",
            "\n",
            "======== Epoch 437 =========\n",
            "Train loss : 0.136265, Test loss : 0.116214, Validation loss : 0.096288\n",
            "\n",
            "======== Epoch 438 =========\n",
            "Train loss : 0.136042, Test loss : 0.116027, Validation loss : 0.096073\n",
            "\n",
            "======== Epoch 439 =========\n",
            "Train loss : 0.135819, Test loss : 0.115902, Validation loss : 0.095835\n",
            "\n",
            "======== Epoch 440 =========\n",
            "Train loss : 0.135596, Test loss : 0.115707, Validation loss : 0.095623\n",
            "\n",
            "======== Epoch 441 =========\n",
            "Train loss : 0.135373, Test loss : 0.115575, Validation loss : 0.095391\n",
            "\n",
            "======== Epoch 442 =========\n",
            "Train loss : 0.135152, Test loss : 0.115394, Validation loss : 0.095178\n",
            "\n",
            "======== Epoch 443 =========\n",
            "Train loss : 0.134933, Test loss : 0.115250, Validation loss : 0.094954\n",
            "\n",
            "======== Epoch 444 =========\n",
            "Train loss : 0.134715, Test loss : 0.115091, Validation loss : 0.094736\n",
            "\n",
            "======== Epoch 445 =========\n",
            "Train loss : 0.134498, Test loss : 0.114926, Validation loss : 0.094522\n",
            "\n",
            "======== Epoch 446 =========\n",
            "Train loss : 0.134282, Test loss : 0.114789, Validation loss : 0.094300\n",
            "\n",
            "======== Epoch 447 =========\n",
            "Train loss : 0.134067, Test loss : 0.114615, Validation loss : 0.094089\n",
            "\n",
            "======== Epoch 448 =========\n",
            "Train loss : 0.133851, Test loss : 0.114463, Validation loss : 0.093873\n",
            "\n",
            "======== Epoch 449 =========\n",
            "Train loss : 0.133635, Test loss : 0.114306, Validation loss : 0.093660\n",
            "\n",
            "======== Epoch 450 =========\n",
            "Train loss : 0.133421, Test loss : 0.114167, Validation loss : 0.093443\n",
            "\n",
            "======== Epoch 451 =========\n",
            "Train loss : 0.133208, Test loss : 0.113979, Validation loss : 0.093242\n",
            "\n",
            "======== Epoch 452 =========\n",
            "Train loss : 0.132995, Test loss : 0.113854, Validation loss : 0.093020\n",
            "\n",
            "======== Epoch 453 =========\n",
            "Train loss : 0.132779, Test loss : 0.113674, Validation loss : 0.092816\n",
            "\n",
            "======== Epoch 454 =========\n",
            "Train loss : 0.132564, Test loss : 0.113546, Validation loss : 0.092598\n",
            "\n",
            "======== Epoch 455 =========\n",
            "Train loss : 0.132351, Test loss : 0.113314, Validation loss : 0.092396\n",
            "\n",
            "======== Epoch 456 =========\n",
            "Train loss : 0.132138, Test loss : 0.113217, Validation loss : 0.092162\n",
            "\n",
            "======== Epoch 457 =========\n",
            "Train loss : 0.131927, Test loss : 0.113047, Validation loss : 0.091951\n",
            "\n",
            "======== Epoch 458 =========\n",
            "Train loss : 0.131717, Test loss : 0.112917, Validation loss : 0.091730\n",
            "\n",
            "======== Epoch 459 =========\n",
            "Train loss : 0.131508, Test loss : 0.112736, Validation loss : 0.091526\n",
            "\n",
            "======== Epoch 460 =========\n",
            "Train loss : 0.131300, Test loss : 0.112609, Validation loss : 0.091307\n",
            "\n",
            "======== Epoch 461 =========\n",
            "Train loss : 0.131093, Test loss : 0.112432, Validation loss : 0.091104\n",
            "\n",
            "======== Epoch 462 =========\n",
            "Train loss : 0.130888, Test loss : 0.112309, Validation loss : 0.090887\n",
            "\n",
            "======== Epoch 463 =========\n",
            "Train loss : 0.130680, Test loss : 0.112143, Validation loss : 0.090677\n",
            "\n",
            "======== Epoch 464 =========\n",
            "Train loss : 0.130468, Test loss : 0.111986, Validation loss : 0.090466\n",
            "\n",
            "======== Epoch 465 =========\n",
            "Train loss : 0.130258, Test loss : 0.111818, Validation loss : 0.090259\n",
            "\n",
            "======== Epoch 466 =========\n",
            "Train loss : 0.130048, Test loss : 0.111684, Validation loss : 0.090044\n",
            "\n",
            "======== Epoch 467 =========\n",
            "Train loss : 0.129840, Test loss : 0.111522, Validation loss : 0.089838\n",
            "\n",
            "======== Epoch 468 =========\n",
            "Train loss : 0.129635, Test loss : 0.111377, Validation loss : 0.089635\n",
            "\n",
            "======== Epoch 469 =========\n",
            "Train loss : 0.129440, Test loss : 0.111204, Validation loss : 0.089446\n",
            "\n",
            "======== Epoch 470 =========\n",
            "Train loss : 0.129248, Test loss : 0.111087, Validation loss : 0.089244\n",
            "\n",
            "======== Epoch 471 =========\n",
            "Train loss : 0.129058, Test loss : 0.110937, Validation loss : 0.089055\n",
            "\n",
            "======== Epoch 472 =========\n",
            "Train loss : 0.128868, Test loss : 0.110816, Validation loss : 0.088861\n",
            "\n",
            "======== Epoch 473 =========\n",
            "Train loss : 0.128680, Test loss : 0.110653, Validation loss : 0.088673\n",
            "\n",
            "======== Epoch 474 =========\n",
            "Train loss : 0.128493, Test loss : 0.110593, Validation loss : 0.088466\n",
            "\n",
            "======== Epoch 475 =========\n",
            "Train loss : 0.128307, Test loss : 0.110425, Validation loss : 0.088291\n",
            "\n",
            "======== Epoch 476 =========\n",
            "Train loss : 0.128121, Test loss : 0.110370, Validation loss : 0.088086\n",
            "\n",
            "======== Epoch 477 =========\n",
            "Train loss : 0.127936, Test loss : 0.110211, Validation loss : 0.087905\n",
            "\n",
            "======== Epoch 478 =========\n",
            "Train loss : 0.127744, Test loss : 0.110122, Validation loss : 0.087706\n",
            "\n",
            "======== Epoch 479 =========\n",
            "Train loss : 0.127554, Test loss : 0.109999, Validation loss : 0.087519\n",
            "\n",
            "======== Epoch 480 =========\n",
            "Train loss : 0.127365, Test loss : 0.109880, Validation loss : 0.087337\n",
            "\n",
            "======== Epoch 481 =========\n",
            "Train loss : 0.127178, Test loss : 0.109772, Validation loss : 0.087161\n",
            "\n",
            "======== Epoch 482 =========\n",
            "Train loss : 0.126996, Test loss : 0.109649, Validation loss : 0.086989\n",
            "\n",
            "======== Epoch 483 =========\n",
            "Train loss : 0.126815, Test loss : 0.109523, Validation loss : 0.086820\n",
            "\n",
            "======== Epoch 484 =========\n",
            "Train loss : 0.126635, Test loss : 0.109442, Validation loss : 0.086639\n",
            "\n",
            "======== Epoch 485 =========\n",
            "Train loss : 0.126455, Test loss : 0.109286, Validation loss : 0.086480\n",
            "\n",
            "======== Epoch 486 =========\n",
            "Train loss : 0.126277, Test loss : 0.109227, Validation loss : 0.086296\n",
            "\n",
            "======== Epoch 487 =========\n",
            "Train loss : 0.126100, Test loss : 0.109014, Validation loss : 0.086146\n",
            "\n",
            "======== Epoch 488 =========\n",
            "Train loss : 0.125924, Test loss : 0.109016, Validation loss : 0.085948\n",
            "\n",
            "======== Epoch 489 =========\n",
            "Train loss : 0.125748, Test loss : 0.108821, Validation loss : 0.085803\n",
            "\n",
            "======== Epoch 490 =========\n",
            "Train loss : 0.125574, Test loss : 0.108783, Validation loss : 0.085619\n",
            "\n",
            "======== Epoch 491 =========\n",
            "Train loss : 0.125400, Test loss : 0.108614, Validation loss : 0.085469\n",
            "\n",
            "======== Epoch 492 =========\n",
            "Train loss : 0.125227, Test loss : 0.108564, Validation loss : 0.085290\n",
            "\n",
            "======== Epoch 493 =========\n",
            "Train loss : 0.125055, Test loss : 0.108395, Validation loss : 0.085144\n",
            "\n",
            "======== Epoch 494 =========\n",
            "Train loss : 0.124888, Test loss : 0.108338, Validation loss : 0.084970\n",
            "\n",
            "======== Epoch 495 =========\n",
            "Train loss : 0.124722, Test loss : 0.108175, Validation loss : 0.084825\n",
            "\n",
            "======== Epoch 496 =========\n",
            "Train loss : 0.124557, Test loss : 0.108123, Validation loss : 0.084654\n",
            "\n",
            "======== Epoch 497 =========\n",
            "Train loss : 0.124396, Test loss : 0.107975, Validation loss : 0.084510\n",
            "\n",
            "======== Epoch 498 =========\n",
            "Train loss : 0.124235, Test loss : 0.107921, Validation loss : 0.084343\n",
            "\n",
            "======== Epoch 499 =========\n",
            "Train loss : 0.124075, Test loss : 0.107755, Validation loss : 0.084197\n",
            "\n",
            "======== Epoch 500 =========\n",
            "Train loss : 0.123915, Test loss : 0.107728, Validation loss : 0.084026\n",
            "\n",
            "======== Epoch 501 =========\n",
            "Train loss : 0.123759, Test loss : 0.107591, Validation loss : 0.083886\n",
            "\n",
            "======== Epoch 502 =========\n",
            "Train loss : 0.123605, Test loss : 0.107510, Validation loss : 0.083733\n",
            "\n",
            "======== Epoch 503 =========\n",
            "Train loss : 0.123452, Test loss : 0.107403, Validation loss : 0.083588\n",
            "\n",
            "======== Epoch 504 =========\n",
            "Train loss : 0.123300, Test loss : 0.107315, Validation loss : 0.083439\n",
            "\n",
            "======== Epoch 505 =========\n",
            "Train loss : 0.123148, Test loss : 0.107218, Validation loss : 0.083293\n",
            "\n",
            "======== Epoch 506 =========\n",
            "Train loss : 0.122998, Test loss : 0.107135, Validation loss : 0.083145\n",
            "\n",
            "======== Epoch 507 =========\n",
            "Train loss : 0.122848, Test loss : 0.107014, Validation loss : 0.083007\n",
            "\n",
            "======== Epoch 508 =========\n",
            "Train loss : 0.122699, Test loss : 0.106947, Validation loss : 0.082857\n",
            "\n",
            "======== Epoch 509 =========\n",
            "Train loss : 0.122551, Test loss : 0.106824, Validation loss : 0.082721\n",
            "\n",
            "======== Epoch 510 =========\n",
            "Train loss : 0.122403, Test loss : 0.106755, Validation loss : 0.082574\n",
            "\n",
            "======== Epoch 511 =========\n",
            "Train loss : 0.122256, Test loss : 0.106650, Validation loss : 0.082435\n",
            "\n",
            "======== Epoch 512 =========\n",
            "Train loss : 0.122110, Test loss : 0.106558, Validation loss : 0.082295\n",
            "\n",
            "======== Epoch 513 =========\n",
            "Train loss : 0.121965, Test loss : 0.106430, Validation loss : 0.082155\n",
            "\n",
            "======== Epoch 514 =========\n",
            "Train loss : 0.121821, Test loss : 0.106399, Validation loss : 0.082002\n",
            "\n",
            "======== Epoch 515 =========\n",
            "Train loss : 0.121677, Test loss : 0.106258, Validation loss : 0.081875\n",
            "\n",
            "======== Epoch 516 =========\n",
            "Train loss : 0.121534, Test loss : 0.106210, Validation loss : 0.081728\n",
            "\n",
            "======== Epoch 517 =========\n",
            "Train loss : 0.121392, Test loss : 0.106097, Validation loss : 0.081596\n",
            "\n",
            "======== Epoch 518 =========\n",
            "Train loss : 0.121250, Test loss : 0.106012, Validation loss : 0.081459\n",
            "\n",
            "======== Epoch 519 =========\n",
            "Train loss : 0.121109, Test loss : 0.105919, Validation loss : 0.081325\n",
            "\n",
            "======== Epoch 520 =========\n",
            "Train loss : 0.120969, Test loss : 0.105838, Validation loss : 0.081188\n",
            "\n",
            "======== Epoch 521 =========\n",
            "Train loss : 0.120830, Test loss : 0.105752, Validation loss : 0.081054\n",
            "\n",
            "======== Epoch 522 =========\n",
            "Train loss : 0.120691, Test loss : 0.105652, Validation loss : 0.080924\n",
            "\n",
            "======== Epoch 523 =========\n",
            "Train loss : 0.120553, Test loss : 0.105586, Validation loss : 0.080786\n",
            "\n",
            "======== Epoch 524 =========\n",
            "Train loss : 0.120415, Test loss : 0.105483, Validation loss : 0.080658\n",
            "\n",
            "======== Epoch 525 =========\n",
            "Train loss : 0.120279, Test loss : 0.105402, Validation loss : 0.080526\n",
            "\n",
            "======== Epoch 526 =========\n",
            "Train loss : 0.120144, Test loss : 0.105309, Validation loss : 0.080397\n",
            "\n",
            "======== Epoch 527 =========\n",
            "Train loss : 0.120009, Test loss : 0.105222, Validation loss : 0.080268\n",
            "\n",
            "======== Epoch 528 =========\n",
            "Train loss : 0.119875, Test loss : 0.105107, Validation loss : 0.080137\n",
            "\n",
            "======== Epoch 529 =========\n",
            "Train loss : 0.119742, Test loss : 0.105068, Validation loss : 0.079999\n",
            "\n",
            "======== Epoch 530 =========\n",
            "Train loss : 0.119608, Test loss : 0.104968, Validation loss : 0.079874\n",
            "\n",
            "======== Epoch 531 =========\n",
            "Train loss : 0.119469, Test loss : 0.104901, Validation loss : 0.079743\n",
            "\n",
            "======== Epoch 532 =========\n",
            "Train loss : 0.119330, Test loss : 0.104815, Validation loss : 0.079616\n",
            "\n",
            "======== Epoch 533 =========\n",
            "Train loss : 0.119192, Test loss : 0.104742, Validation loss : 0.079488\n",
            "\n",
            "======== Epoch 534 =========\n",
            "Train loss : 0.119055, Test loss : 0.104657, Validation loss : 0.079362\n",
            "\n",
            "======== Epoch 535 =========\n",
            "Train loss : 0.118918, Test loss : 0.104584, Validation loss : 0.079236\n",
            "\n",
            "======== Epoch 536 =========\n",
            "Train loss : 0.118784, Test loss : 0.104491, Validation loss : 0.079114\n",
            "\n",
            "======== Epoch 537 =========\n",
            "Train loss : 0.118651, Test loss : 0.104424, Validation loss : 0.078988\n",
            "\n",
            "======== Epoch 538 =========\n",
            "Train loss : 0.118520, Test loss : 0.104325, Validation loss : 0.078869\n",
            "\n",
            "======== Epoch 539 =========\n",
            "Train loss : 0.118391, Test loss : 0.104270, Validation loss : 0.078742\n",
            "\n",
            "======== Epoch 540 =========\n",
            "Train loss : 0.118263, Test loss : 0.104159, Validation loss : 0.078628\n",
            "\n",
            "======== Epoch 541 =========\n",
            "Train loss : 0.118135, Test loss : 0.104106, Validation loss : 0.078502\n",
            "\n",
            "======== Epoch 542 =========\n",
            "Train loss : 0.118008, Test loss : 0.104006, Validation loss : 0.078387\n",
            "\n",
            "======== Epoch 543 =========\n",
            "Train loss : 0.117882, Test loss : 0.103901, Validation loss : 0.078265\n",
            "\n",
            "======== Epoch 544 =========\n",
            "Train loss : 0.117757, Test loss : 0.103865, Validation loss : 0.078137\n",
            "\n",
            "======== Epoch 545 =========\n",
            "Train loss : 0.117632, Test loss : 0.103763, Validation loss : 0.078024\n",
            "\n",
            "======== Epoch 546 =========\n",
            "Train loss : 0.117507, Test loss : 0.103711, Validation loss : 0.077902\n",
            "\n",
            "======== Epoch 547 =========\n",
            "Train loss : 0.117383, Test loss : 0.103612, Validation loss : 0.077790\n",
            "\n",
            "======== Epoch 548 =========\n",
            "Train loss : 0.117260, Test loss : 0.103555, Validation loss : 0.077669\n",
            "\n",
            "======== Epoch 549 =========\n",
            "Train loss : 0.117137, Test loss : 0.103462, Validation loss : 0.077557\n",
            "\n",
            "======== Epoch 550 =========\n",
            "Train loss : 0.117015, Test loss : 0.103406, Validation loss : 0.077438\n",
            "\n",
            "======== Epoch 551 =========\n",
            "Train loss : 0.116893, Test loss : 0.103315, Validation loss : 0.077327\n",
            "\n",
            "======== Epoch 552 =========\n",
            "Train loss : 0.116772, Test loss : 0.103242, Validation loss : 0.077213\n",
            "\n",
            "======== Epoch 553 =========\n",
            "Train loss : 0.116652, Test loss : 0.103169, Validation loss : 0.077099\n",
            "\n",
            "======== Epoch 554 =========\n",
            "Train loss : 0.116533, Test loss : 0.103085, Validation loss : 0.076988\n",
            "\n",
            "======== Epoch 555 =========\n",
            "Train loss : 0.116414, Test loss : 0.103025, Validation loss : 0.076873\n",
            "\n",
            "======== Epoch 556 =========\n",
            "Train loss : 0.116296, Test loss : 0.102936, Validation loss : 0.076765\n",
            "\n",
            "======== Epoch 557 =========\n",
            "Train loss : 0.116179, Test loss : 0.102871, Validation loss : 0.076652\n",
            "\n",
            "======== Epoch 558 =========\n",
            "Train loss : 0.116062, Test loss : 0.102787, Validation loss : 0.076544\n",
            "\n",
            "======== Epoch 559 =========\n",
            "Train loss : 0.115946, Test loss : 0.102716, Validation loss : 0.076433\n",
            "\n",
            "======== Epoch 560 =========\n",
            "Train loss : 0.115831, Test loss : 0.102648, Validation loss : 0.076323\n",
            "\n",
            "======== Epoch 561 =========\n",
            "Train loss : 0.115716, Test loss : 0.102562, Validation loss : 0.076216\n",
            "\n",
            "======== Epoch 562 =========\n",
            "Train loss : 0.115602, Test loss : 0.102494, Validation loss : 0.076107\n",
            "\n",
            "======== Epoch 563 =========\n",
            "Train loss : 0.115488, Test loss : 0.102418, Validation loss : 0.076000\n",
            "\n",
            "======== Epoch 564 =========\n",
            "Train loss : 0.115376, Test loss : 0.102346, Validation loss : 0.075892\n",
            "\n",
            "======== Epoch 565 =========\n",
            "Train loss : 0.115264, Test loss : 0.102273, Validation loss : 0.075786\n",
            "\n",
            "======== Epoch 566 =========\n",
            "Train loss : 0.115152, Test loss : 0.102200, Validation loss : 0.075680\n",
            "\n",
            "======== Epoch 567 =========\n",
            "Train loss : 0.115041, Test loss : 0.102129, Validation loss : 0.075575\n",
            "\n",
            "======== Epoch 568 =========\n",
            "Train loss : 0.114930, Test loss : 0.102052, Validation loss : 0.075470\n",
            "\n",
            "======== Epoch 569 =========\n",
            "Train loss : 0.114820, Test loss : 0.101983, Validation loss : 0.075365\n",
            "\n",
            "======== Epoch 570 =========\n",
            "Train loss : 0.114710, Test loss : 0.101914, Validation loss : 0.075261\n",
            "\n",
            "======== Epoch 571 =========\n",
            "Train loss : 0.114601, Test loss : 0.101839, Validation loss : 0.075158\n",
            "\n",
            "======== Epoch 572 =========\n",
            "Train loss : 0.114492, Test loss : 0.101768, Validation loss : 0.075054\n",
            "\n",
            "======== Epoch 573 =========\n",
            "Train loss : 0.114384, Test loss : 0.101705, Validation loss : 0.074951\n",
            "\n",
            "======== Epoch 574 =========\n",
            "Train loss : 0.114276, Test loss : 0.101627, Validation loss : 0.074850\n",
            "\n",
            "======== Epoch 575 =========\n",
            "Train loss : 0.114169, Test loss : 0.101565, Validation loss : 0.074747\n",
            "\n",
            "======== Epoch 576 =========\n",
            "Train loss : 0.114062, Test loss : 0.101488, Validation loss : 0.074647\n",
            "\n",
            "======== Epoch 577 =========\n",
            "Train loss : 0.113956, Test loss : 0.101428, Validation loss : 0.074545\n",
            "\n",
            "======== Epoch 578 =========\n",
            "Train loss : 0.113850, Test loss : 0.101349, Validation loss : 0.074447\n",
            "\n",
            "======== Epoch 579 =========\n",
            "Train loss : 0.113745, Test loss : 0.101289, Validation loss : 0.074346\n",
            "\n",
            "======== Epoch 580 =========\n",
            "Train loss : 0.113640, Test loss : 0.101209, Validation loss : 0.074248\n",
            "\n",
            "======== Epoch 581 =========\n",
            "Train loss : 0.113536, Test loss : 0.101151, Validation loss : 0.074148\n",
            "\n",
            "======== Epoch 582 =========\n",
            "Train loss : 0.113431, Test loss : 0.101073, Validation loss : 0.074052\n",
            "\n",
            "======== Epoch 583 =========\n",
            "Train loss : 0.113328, Test loss : 0.101018, Validation loss : 0.073952\n",
            "\n",
            "======== Epoch 584 =========\n",
            "Train loss : 0.113225, Test loss : 0.100943, Validation loss : 0.073856\n",
            "\n",
            "======== Epoch 585 =========\n",
            "Train loss : 0.113122, Test loss : 0.100873, Validation loss : 0.073759\n",
            "\n",
            "======== Epoch 586 =========\n",
            "Train loss : 0.113020, Test loss : 0.100819, Validation loss : 0.073661\n",
            "\n",
            "======== Epoch 587 =========\n",
            "Train loss : 0.112918, Test loss : 0.100731, Validation loss : 0.073569\n",
            "\n",
            "======== Epoch 588 =========\n",
            "Train loss : 0.112817, Test loss : 0.100687, Validation loss : 0.073470\n",
            "\n",
            "======== Epoch 589 =========\n",
            "Train loss : 0.112717, Test loss : 0.100600, Validation loss : 0.073379\n",
            "\n",
            "======== Epoch 590 =========\n",
            "Train loss : 0.112616, Test loss : 0.100550, Validation loss : 0.073281\n",
            "\n",
            "======== Epoch 591 =========\n",
            "Train loss : 0.112517, Test loss : 0.100476, Validation loss : 0.073188\n",
            "\n",
            "======== Epoch 592 =========\n",
            "Train loss : 0.112417, Test loss : 0.100410, Validation loss : 0.073095\n",
            "\n",
            "======== Epoch 593 =========\n",
            "Train loss : 0.112318, Test loss : 0.100351, Validation loss : 0.073001\n",
            "\n",
            "======== Epoch 594 =========\n",
            "Train loss : 0.112220, Test loss : 0.100272, Validation loss : 0.072910\n",
            "\n",
            "======== Epoch 595 =========\n",
            "Train loss : 0.112122, Test loss : 0.100226, Validation loss : 0.072815\n",
            "\n",
            "======== Epoch 596 =========\n",
            "Train loss : 0.112024, Test loss : 0.100151, Validation loss : 0.072725\n",
            "\n",
            "======== Epoch 597 =========\n",
            "Train loss : 0.111926, Test loss : 0.100089, Validation loss : 0.072633\n",
            "\n",
            "======== Epoch 598 =========\n",
            "Train loss : 0.111829, Test loss : 0.100025, Validation loss : 0.072542\n",
            "\n",
            "======== Epoch 599 =========\n",
            "Train loss : 0.111733, Test loss : 0.099960, Validation loss : 0.072452\n",
            "\n",
            "======== Epoch 600 =========\n",
            "Train loss : 0.111637, Test loss : 0.099907, Validation loss : 0.072360\n",
            "\n",
            "======== Epoch 601 =========\n",
            "Train loss : 0.111541, Test loss : 0.099830, Validation loss : 0.072272\n",
            "\n",
            "======== Epoch 602 =========\n",
            "Train loss : 0.111446, Test loss : 0.099775, Validation loss : 0.072182\n",
            "\n",
            "======== Epoch 603 =========\n",
            "Train loss : 0.111351, Test loss : 0.099714, Validation loss : 0.072092\n",
            "\n",
            "======== Epoch 604 =========\n",
            "Train loss : 0.111256, Test loss : 0.099642, Validation loss : 0.072005\n",
            "\n",
            "======== Epoch 605 =========\n",
            "Train loss : 0.111162, Test loss : 0.099597, Validation loss : 0.071914\n",
            "\n",
            "======== Epoch 606 =========\n",
            "Train loss : 0.111068, Test loss : 0.099524, Validation loss : 0.071829\n",
            "\n",
            "======== Epoch 607 =========\n",
            "Train loss : 0.110975, Test loss : 0.099462, Validation loss : 0.071741\n",
            "\n",
            "======== Epoch 608 =========\n",
            "Train loss : 0.110882, Test loss : 0.099407, Validation loss : 0.071653\n",
            "\n",
            "======== Epoch 609 =========\n",
            "Train loss : 0.110789, Test loss : 0.099340, Validation loss : 0.071568\n",
            "\n",
            "======== Epoch 610 =========\n",
            "Train loss : 0.110697, Test loss : 0.099279, Validation loss : 0.071481\n",
            "\n",
            "======== Epoch 611 =========\n",
            "Train loss : 0.110605, Test loss : 0.099229, Validation loss : 0.071395\n",
            "\n",
            "======== Epoch 612 =========\n",
            "Train loss : 0.110514, Test loss : 0.099158, Validation loss : 0.071311\n",
            "\n",
            "======== Epoch 613 =========\n",
            "Train loss : 0.110422, Test loss : 0.099102, Validation loss : 0.071225\n",
            "\n",
            "======== Epoch 614 =========\n",
            "Train loss : 0.110332, Test loss : 0.099040, Validation loss : 0.071141\n",
            "\n",
            "======== Epoch 615 =========\n",
            "Train loss : 0.110241, Test loss : 0.098984, Validation loss : 0.071056\n",
            "\n",
            "======== Epoch 616 =========\n",
            "Train loss : 0.110151, Test loss : 0.098917, Validation loss : 0.070973\n",
            "\n",
            "======== Epoch 617 =========\n",
            "Train loss : 0.110062, Test loss : 0.098867, Validation loss : 0.070889\n",
            "\n",
            "======== Epoch 618 =========\n",
            "Train loss : 0.109973, Test loss : 0.098800, Validation loss : 0.070807\n",
            "\n",
            "======== Epoch 619 =========\n",
            "Train loss : 0.109884, Test loss : 0.098744, Validation loss : 0.070723\n",
            "\n",
            "======== Epoch 620 =========\n",
            "Train loss : 0.109795, Test loss : 0.098688, Validation loss : 0.070641\n",
            "\n",
            "======== Epoch 621 =========\n",
            "Train loss : 0.109707, Test loss : 0.098627, Validation loss : 0.070560\n",
            "\n",
            "======== Epoch 622 =========\n",
            "Train loss : 0.109619, Test loss : 0.098568, Validation loss : 0.070478\n",
            "\n",
            "======== Epoch 623 =========\n",
            "Train loss : 0.109532, Test loss : 0.098516, Validation loss : 0.070396\n",
            "\n",
            "======== Epoch 624 =========\n",
            "Train loss : 0.109445, Test loss : 0.098454, Validation loss : 0.070316\n",
            "\n",
            "======== Epoch 625 =========\n",
            "Train loss : 0.109358, Test loss : 0.098392, Validation loss : 0.070235\n",
            "\n",
            "======== Epoch 626 =========\n",
            "Train loss : 0.109271, Test loss : 0.098342, Validation loss : 0.070154\n",
            "\n",
            "======== Epoch 627 =========\n",
            "Train loss : 0.109185, Test loss : 0.098273, Validation loss : 0.070077\n",
            "\n",
            "======== Epoch 628 =========\n",
            "Train loss : 0.109100, Test loss : 0.098231, Validation loss : 0.069995\n",
            "\n",
            "======== Epoch 629 =========\n",
            "Train loss : 0.109014, Test loss : 0.098158, Validation loss : 0.069918\n",
            "\n",
            "======== Epoch 630 =========\n",
            "Train loss : 0.108929, Test loss : 0.098116, Validation loss : 0.069837\n",
            "\n",
            "======== Epoch 631 =========\n",
            "Train loss : 0.108845, Test loss : 0.098047, Validation loss : 0.069761\n",
            "\n",
            "======== Epoch 632 =========\n",
            "Train loss : 0.108761, Test loss : 0.098002, Validation loss : 0.069681\n",
            "\n",
            "======== Epoch 633 =========\n",
            "Train loss : 0.108677, Test loss : 0.097940, Validation loss : 0.069605\n",
            "\n",
            "======== Epoch 634 =========\n",
            "Train loss : 0.108593, Test loss : 0.097878, Validation loss : 0.069528\n",
            "\n",
            "======== Epoch 635 =========\n",
            "Train loss : 0.108510, Test loss : 0.097834, Validation loss : 0.069449\n",
            "\n",
            "======== Epoch 636 =========\n",
            "Train loss : 0.108427, Test loss : 0.097776, Validation loss : 0.069373\n",
            "\n",
            "======== Epoch 637 =========\n",
            "Train loss : 0.108344, Test loss : 0.097715, Validation loss : 0.069298\n",
            "\n",
            "======== Epoch 638 =========\n",
            "Train loss : 0.108262, Test loss : 0.097667, Validation loss : 0.069221\n",
            "\n",
            "======== Epoch 639 =========\n",
            "Train loss : 0.108180, Test loss : 0.097603, Validation loss : 0.069146\n",
            "\n",
            "======== Epoch 640 =========\n",
            "Train loss : 0.108098, Test loss : 0.097550, Validation loss : 0.069071\n",
            "\n",
            "======== Epoch 641 =========\n",
            "Train loss : 0.108017, Test loss : 0.097506, Validation loss : 0.068995\n",
            "\n",
            "======== Epoch 642 =========\n",
            "Train loss : 0.107936, Test loss : 0.097431, Validation loss : 0.068923\n",
            "\n",
            "======== Epoch 643 =========\n",
            "Train loss : 0.107855, Test loss : 0.097399, Validation loss : 0.068845\n",
            "\n",
            "======== Epoch 644 =========\n",
            "Train loss : 0.107775, Test loss : 0.097322, Validation loss : 0.068774\n",
            "\n",
            "======== Epoch 645 =========\n",
            "Train loss : 0.107695, Test loss : 0.097295, Validation loss : 0.068696\n",
            "\n",
            "======== Epoch 646 =========\n",
            "Train loss : 0.107615, Test loss : 0.097214, Validation loss : 0.068627\n",
            "\n",
            "======== Epoch 647 =========\n",
            "Train loss : 0.107536, Test loss : 0.097190, Validation loss : 0.068549\n",
            "\n",
            "======== Epoch 648 =========\n",
            "Train loss : 0.107457, Test loss : 0.097108, Validation loss : 0.068481\n",
            "\n",
            "======== Epoch 649 =========\n",
            "Train loss : 0.107378, Test loss : 0.097072, Validation loss : 0.068406\n",
            "\n",
            "======== Epoch 650 =========\n",
            "Train loss : 0.107299, Test loss : 0.097018, Validation loss : 0.068334\n",
            "\n",
            "======== Epoch 651 =========\n",
            "Train loss : 0.107221, Test loss : 0.096960, Validation loss : 0.068262\n",
            "\n",
            "======== Epoch 652 =========\n",
            "Train loss : 0.107143, Test loss : 0.096915, Validation loss : 0.068189\n",
            "\n",
            "======== Epoch 653 =========\n",
            "Train loss : 0.107066, Test loss : 0.096855, Validation loss : 0.068119\n",
            "\n",
            "======== Epoch 654 =========\n",
            "Train loss : 0.106988, Test loss : 0.096815, Validation loss : 0.068047\n",
            "\n",
            "======== Epoch 655 =========\n",
            "Train loss : 0.106911, Test loss : 0.096749, Validation loss : 0.067978\n",
            "\n",
            "======== Epoch 656 =========\n",
            "Train loss : 0.106834, Test loss : 0.096709, Validation loss : 0.067905\n",
            "\n",
            "======== Epoch 657 =========\n",
            "Train loss : 0.106758, Test loss : 0.096661, Validation loss : 0.067834\n",
            "\n",
            "======== Epoch 658 =========\n",
            "Train loss : 0.106682, Test loss : 0.096593, Validation loss : 0.067767\n",
            "\n",
            "======== Epoch 659 =========\n",
            "Train loss : 0.106606, Test loss : 0.096567, Validation loss : 0.067695\n",
            "\n",
            "======== Epoch 660 =========\n",
            "Train loss : 0.106530, Test loss : 0.096487, Validation loss : 0.067629\n",
            "\n",
            "======== Epoch 661 =========\n",
            "Train loss : 0.106455, Test loss : 0.096455, Validation loss : 0.067558\n",
            "\n",
            "======== Epoch 662 =========\n",
            "Train loss : 0.106380, Test loss : 0.096403, Validation loss : 0.067489\n",
            "\n",
            "======== Epoch 663 =========\n",
            "Train loss : 0.106305, Test loss : 0.096347, Validation loss : 0.067421\n",
            "\n",
            "======== Epoch 664 =========\n",
            "Train loss : 0.106230, Test loss : 0.096312, Validation loss : 0.067352\n",
            "\n",
            "======== Epoch 665 =========\n",
            "Train loss : 0.106156, Test loss : 0.096240, Validation loss : 0.067286\n",
            "\n",
            "======== Epoch 666 =========\n",
            "Train loss : 0.106082, Test loss : 0.096207, Validation loss : 0.067217\n",
            "\n",
            "======== Epoch 667 =========\n",
            "Train loss : 0.106008, Test loss : 0.096156, Validation loss : 0.067149\n",
            "\n",
            "======== Epoch 668 =========\n",
            "Train loss : 0.105935, Test loss : 0.096098, Validation loss : 0.067084\n",
            "\n",
            "======== Epoch 669 =========\n",
            "Train loss : 0.105862, Test loss : 0.096068, Validation loss : 0.067015\n",
            "\n",
            "======== Epoch 670 =========\n",
            "Train loss : 0.105789, Test loss : 0.095992, Validation loss : 0.066951\n",
            "\n",
            "======== Epoch 671 =========\n",
            "Train loss : 0.105716, Test loss : 0.095960, Validation loss : 0.066883\n",
            "\n",
            "======== Epoch 672 =========\n",
            "Train loss : 0.105644, Test loss : 0.095902, Validation loss : 0.066819\n",
            "\n",
            "======== Epoch 673 =========\n",
            "Train loss : 0.105572, Test loss : 0.095861, Validation loss : 0.066752\n",
            "\n",
            "======== Epoch 674 =========\n",
            "Train loss : 0.105500, Test loss : 0.095795, Validation loss : 0.066689\n",
            "\n",
            "======== Epoch 675 =========\n",
            "Train loss : 0.105428, Test loss : 0.095779, Validation loss : 0.066620\n",
            "\n",
            "======== Epoch 676 =========\n",
            "Train loss : 0.105357, Test loss : 0.095690, Validation loss : 0.066560\n",
            "\n",
            "======== Epoch 677 =========\n",
            "Train loss : 0.105286, Test loss : 0.095676, Validation loss : 0.066491\n",
            "\n",
            "======== Epoch 678 =========\n",
            "Train loss : 0.105215, Test loss : 0.095604, Validation loss : 0.066430\n",
            "\n",
            "======== Epoch 679 =========\n",
            "Train loss : 0.105145, Test loss : 0.095582, Validation loss : 0.066363\n",
            "\n",
            "======== Epoch 680 =========\n",
            "Train loss : 0.105074, Test loss : 0.095510, Validation loss : 0.066302\n",
            "\n",
            "======== Epoch 681 =========\n",
            "Train loss : 0.105004, Test loss : 0.095474, Validation loss : 0.066237\n",
            "\n",
            "======== Epoch 682 =========\n",
            "Train loss : 0.104934, Test loss : 0.095439, Validation loss : 0.066173\n",
            "\n",
            "======== Epoch 683 =========\n",
            "Train loss : 0.104865, Test loss : 0.095372, Validation loss : 0.066112\n",
            "\n",
            "======== Epoch 684 =========\n",
            "Train loss : 0.104795, Test loss : 0.095341, Validation loss : 0.066047\n",
            "\n",
            "======== Epoch 685 =========\n",
            "Train loss : 0.104726, Test loss : 0.095276, Validation loss : 0.065987\n",
            "\n",
            "======== Epoch 686 =========\n",
            "Train loss : 0.104658, Test loss : 0.095248, Validation loss : 0.065923\n",
            "\n",
            "======== Epoch 687 =========\n",
            "Train loss : 0.104589, Test loss : 0.095195, Validation loss : 0.065862\n",
            "\n",
            "======== Epoch 688 =========\n",
            "Train loss : 0.104521, Test loss : 0.095140, Validation loss : 0.065801\n",
            "\n",
            "======== Epoch 689 =========\n",
            "Train loss : 0.104453, Test loss : 0.095114, Validation loss : 0.065737\n",
            "\n",
            "======== Epoch 690 =========\n",
            "Train loss : 0.104385, Test loss : 0.095054, Validation loss : 0.065678\n",
            "\n",
            "======== Epoch 691 =========\n",
            "Train loss : 0.104317, Test loss : 0.095010, Validation loss : 0.065617\n",
            "\n",
            "======== Epoch 692 =========\n",
            "Train loss : 0.104250, Test loss : 0.094972, Validation loss : 0.065555\n",
            "\n",
            "======== Epoch 693 =========\n",
            "Train loss : 0.104183, Test loss : 0.094916, Validation loss : 0.065496\n",
            "\n",
            "======== Epoch 694 =========\n",
            "Train loss : 0.104116, Test loss : 0.094880, Validation loss : 0.065435\n",
            "\n",
            "======== Epoch 695 =========\n",
            "Train loss : 0.104049, Test loss : 0.094835, Validation loss : 0.065375\n",
            "\n",
            "======== Epoch 696 =========\n",
            "Train loss : 0.103983, Test loss : 0.094785, Validation loss : 0.065316\n",
            "\n",
            "======== Epoch 697 =========\n",
            "Train loss : 0.103916, Test loss : 0.094740, Validation loss : 0.065256\n",
            "\n",
            "======== Epoch 698 =========\n",
            "Train loss : 0.103850, Test loss : 0.094710, Validation loss : 0.065195\n",
            "\n",
            "======== Epoch 699 =========\n",
            "Train loss : 0.103784, Test loss : 0.094650, Validation loss : 0.065138\n",
            "\n",
            "======== Epoch 700 =========\n",
            "Train loss : 0.103719, Test loss : 0.094616, Validation loss : 0.065078\n",
            "\n",
            "======== Epoch 701 =========\n",
            "Train loss : 0.103654, Test loss : 0.094575, Validation loss : 0.065020\n",
            "\n",
            "======== Epoch 702 =========\n",
            "Train loss : 0.103589, Test loss : 0.094517, Validation loss : 0.064963\n",
            "\n",
            "======== Epoch 703 =========\n",
            "Train loss : 0.103524, Test loss : 0.094484, Validation loss : 0.064904\n",
            "\n",
            "======== Epoch 704 =========\n",
            "Train loss : 0.103459, Test loss : 0.094429, Validation loss : 0.064847\n",
            "\n",
            "======== Epoch 705 =========\n",
            "Train loss : 0.103395, Test loss : 0.094416, Validation loss : 0.064786\n",
            "\n",
            "======== Epoch 706 =========\n",
            "Train loss : 0.103330, Test loss : 0.094340, Validation loss : 0.064732\n",
            "\n",
            "======== Epoch 707 =========\n",
            "Train loss : 0.103266, Test loss : 0.094315, Validation loss : 0.064673\n",
            "\n",
            "======== Epoch 708 =========\n",
            "Train loss : 0.103203, Test loss : 0.094267, Validation loss : 0.064616\n",
            "\n",
            "======== Epoch 709 =========\n",
            "Train loss : 0.103139, Test loss : 0.094218, Validation loss : 0.064561\n",
            "\n",
            "======== Epoch 710 =========\n",
            "Train loss : 0.103076, Test loss : 0.094182, Validation loss : 0.064504\n",
            "\n",
            "======== Epoch 711 =========\n",
            "Train loss : 0.103013, Test loss : 0.094143, Validation loss : 0.064447\n",
            "\n",
            "======== Epoch 712 =========\n",
            "Train loss : 0.102950, Test loss : 0.094105, Validation loss : 0.064391\n",
            "\n",
            "======== Epoch 713 =========\n",
            "Train loss : 0.102887, Test loss : 0.094044, Validation loss : 0.064337\n",
            "\n",
            "======== Epoch 714 =========\n",
            "Train loss : 0.102825, Test loss : 0.094016, Validation loss : 0.064280\n",
            "\n",
            "======== Epoch 715 =========\n",
            "Train loss : 0.102762, Test loss : 0.093968, Validation loss : 0.064225\n",
            "\n",
            "======== Epoch 716 =========\n",
            "Train loss : 0.102700, Test loss : 0.093944, Validation loss : 0.064168\n",
            "\n",
            "======== Epoch 717 =========\n",
            "Train loss : 0.102639, Test loss : 0.093873, Validation loss : 0.064116\n",
            "\n",
            "======== Epoch 718 =========\n",
            "Train loss : 0.102577, Test loss : 0.093857, Validation loss : 0.064059\n",
            "\n",
            "======== Epoch 719 =========\n",
            "Train loss : 0.102516, Test loss : 0.093796, Validation loss : 0.064006\n",
            "\n",
            "======== Epoch 720 =========\n",
            "Train loss : 0.102454, Test loss : 0.093790, Validation loss : 0.063948\n",
            "\n",
            "======== Epoch 721 =========\n",
            "Train loss : 0.102393, Test loss : 0.093705, Validation loss : 0.063899\n",
            "\n",
            "======== Epoch 722 =========\n",
            "Train loss : 0.102333, Test loss : 0.093692, Validation loss : 0.063842\n",
            "\n",
            "======== Epoch 723 =========\n",
            "Train loss : 0.102272, Test loss : 0.093636, Validation loss : 0.063790\n",
            "\n",
            "======== Epoch 724 =========\n",
            "Train loss : 0.102212, Test loss : 0.093606, Validation loss : 0.063735\n",
            "\n",
            "======== Epoch 725 =========\n",
            "Train loss : 0.102151, Test loss : 0.093564, Validation loss : 0.063682\n",
            "\n",
            "======== Epoch 726 =========\n",
            "Train loss : 0.102091, Test loss : 0.093522, Validation loss : 0.063630\n",
            "\n",
            "======== Epoch 727 =========\n",
            "Train loss : 0.102031, Test loss : 0.093481, Validation loss : 0.063577\n",
            "\n",
            "======== Epoch 728 =========\n",
            "Train loss : 0.101972, Test loss : 0.093437, Validation loss : 0.063525\n",
            "\n",
            "======== Epoch 729 =========\n",
            "Train loss : 0.101912, Test loss : 0.093401, Validation loss : 0.063472\n",
            "\n",
            "======== Epoch 730 =========\n",
            "Train loss : 0.101853, Test loss : 0.093375, Validation loss : 0.063418\n",
            "\n",
            "======== Epoch 731 =========\n",
            "Train loss : 0.101794, Test loss : 0.093311, Validation loss : 0.063369\n",
            "\n",
            "======== Epoch 732 =========\n",
            "Train loss : 0.101735, Test loss : 0.093291, Validation loss : 0.063315\n",
            "\n",
            "======== Epoch 733 =========\n",
            "Train loss : 0.101677, Test loss : 0.093241, Validation loss : 0.063265\n",
            "\n",
            "======== Epoch 734 =========\n",
            "Train loss : 0.101618, Test loss : 0.093199, Validation loss : 0.063213\n",
            "\n",
            "======== Epoch 735 =========\n",
            "Train loss : 0.101560, Test loss : 0.093168, Validation loss : 0.063162\n",
            "\n",
            "======== Epoch 736 =========\n",
            "Train loss : 0.101502, Test loss : 0.093132, Validation loss : 0.063110\n",
            "\n",
            "======== Epoch 737 =========\n",
            "Train loss : 0.101444, Test loss : 0.093081, Validation loss : 0.063061\n",
            "\n",
            "======== Epoch 738 =========\n",
            "Train loss : 0.101386, Test loss : 0.093059, Validation loss : 0.063008\n",
            "\n",
            "======== Epoch 739 =========\n",
            "Train loss : 0.101329, Test loss : 0.093006, Validation loss : 0.062959\n",
            "\n",
            "======== Epoch 740 =========\n",
            "Train loss : 0.101271, Test loss : 0.092966, Validation loss : 0.062909\n",
            "\n",
            "======== Epoch 741 =========\n",
            "Train loss : 0.101214, Test loss : 0.092940, Validation loss : 0.062858\n",
            "\n",
            "======== Epoch 742 =========\n",
            "Train loss : 0.101157, Test loss : 0.092888, Validation loss : 0.062809\n",
            "\n",
            "======== Epoch 743 =========\n",
            "Train loss : 0.101100, Test loss : 0.092864, Validation loss : 0.062759\n",
            "\n",
            "======== Epoch 744 =========\n",
            "Train loss : 0.101044, Test loss : 0.092815, Validation loss : 0.062710\n",
            "\n",
            "======== Epoch 745 =========\n",
            "Train loss : 0.100987, Test loss : 0.092785, Validation loss : 0.062660\n",
            "\n",
            "======== Epoch 746 =========\n",
            "Train loss : 0.100931, Test loss : 0.092732, Validation loss : 0.062612\n",
            "\n",
            "======== Epoch 747 =========\n",
            "Train loss : 0.100875, Test loss : 0.092713, Validation loss : 0.062562\n",
            "\n",
            "======== Epoch 748 =========\n",
            "Train loss : 0.100819, Test loss : 0.092659, Validation loss : 0.062515\n",
            "\n",
            "======== Epoch 749 =========\n",
            "Train loss : 0.100763, Test loss : 0.092634, Validation loss : 0.062465\n",
            "\n",
            "======== Epoch 750 =========\n",
            "Train loss : 0.100708, Test loss : 0.092587, Validation loss : 0.062418\n",
            "\n",
            "======== Epoch 751 =========\n",
            "Train loss : 0.100653, Test loss : 0.092555, Validation loss : 0.062369\n",
            "\n",
            "======== Epoch 752 =========\n",
            "Train loss : 0.100597, Test loss : 0.092516, Validation loss : 0.062321\n",
            "\n",
            "======== Epoch 753 =========\n",
            "Train loss : 0.100542, Test loss : 0.092485, Validation loss : 0.062273\n",
            "\n",
            "======== Epoch 754 =========\n",
            "Train loss : 0.100488, Test loss : 0.092442, Validation loss : 0.062226\n",
            "\n",
            "======== Epoch 755 =========\n",
            "Train loss : 0.100433, Test loss : 0.092409, Validation loss : 0.062178\n",
            "\n",
            "======== Epoch 756 =========\n",
            "Train loss : 0.100378, Test loss : 0.092364, Validation loss : 0.062132\n",
            "\n",
            "======== Epoch 757 =========\n",
            "Train loss : 0.100324, Test loss : 0.092339, Validation loss : 0.062084\n",
            "\n",
            "======== Epoch 758 =========\n",
            "Train loss : 0.100270, Test loss : 0.092286, Validation loss : 0.062038\n",
            "\n",
            "======== Epoch 759 =========\n",
            "Train loss : 0.100216, Test loss : 0.092267, Validation loss : 0.061990\n",
            "\n",
            "======== Epoch 760 =========\n",
            "Train loss : 0.100162, Test loss : 0.092177, Validation loss : 0.061941\n",
            "\n",
            "======== Epoch 761 =========\n",
            "Train loss : 0.100108, Test loss : 0.092201, Validation loss : 0.061889\n",
            "\n",
            "======== Epoch 762 =========\n",
            "Train loss : 0.100055, Test loss : 0.092141, Validation loss : 0.061845\n",
            "\n",
            "======== Epoch 763 =========\n",
            "Train loss : 0.100002, Test loss : 0.092115, Validation loss : 0.061798\n",
            "\n",
            "======== Epoch 764 =========\n",
            "Train loss : 0.099948, Test loss : 0.092079, Validation loss : 0.061753\n",
            "\n",
            "======== Epoch 765 =========\n",
            "Train loss : 0.099895, Test loss : 0.092038, Validation loss : 0.061708\n",
            "\n",
            "======== Epoch 766 =========\n",
            "Train loss : 0.099843, Test loss : 0.092008, Validation loss : 0.061663\n",
            "\n",
            "======== Epoch 767 =========\n",
            "Train loss : 0.099790, Test loss : 0.091964, Validation loss : 0.061618\n",
            "\n",
            "======== Epoch 768 =========\n",
            "Train loss : 0.099737, Test loss : 0.091938, Validation loss : 0.061573\n",
            "\n",
            "======== Epoch 769 =========\n",
            "Train loss : 0.099685, Test loss : 0.091896, Validation loss : 0.061528\n",
            "\n",
            "======== Epoch 770 =========\n",
            "Train loss : 0.099632, Test loss : 0.091869, Validation loss : 0.061483\n",
            "\n",
            "======== Epoch 771 =========\n",
            "Train loss : 0.099580, Test loss : 0.091826, Validation loss : 0.061439\n",
            "\n",
            "======== Epoch 772 =========\n",
            "Train loss : 0.099528, Test loss : 0.091798, Validation loss : 0.061395\n",
            "\n",
            "======== Epoch 773 =========\n",
            "Train loss : 0.099477, Test loss : 0.091756, Validation loss : 0.061351\n",
            "\n",
            "======== Epoch 774 =========\n",
            "Train loss : 0.099425, Test loss : 0.091727, Validation loss : 0.061307\n",
            "\n",
            "======== Epoch 775 =========\n",
            "Train loss : 0.099373, Test loss : 0.091690, Validation loss : 0.061263\n",
            "\n",
            "======== Epoch 776 =========\n",
            "Train loss : 0.099322, Test loss : 0.091656, Validation loss : 0.061220\n",
            "\n",
            "======== Epoch 777 =========\n",
            "Train loss : 0.099271, Test loss : 0.091618, Validation loss : 0.061176\n",
            "\n",
            "======== Epoch 778 =========\n",
            "Train loss : 0.099220, Test loss : 0.091589, Validation loss : 0.061132\n",
            "\n",
            "======== Epoch 779 =========\n",
            "Train loss : 0.099169, Test loss : 0.091554, Validation loss : 0.061089\n",
            "\n",
            "======== Epoch 780 =========\n",
            "Train loss : 0.099118, Test loss : 0.091516, Validation loss : 0.061046\n",
            "\n",
            "======== Epoch 781 =========\n",
            "Train loss : 0.099067, Test loss : 0.091486, Validation loss : 0.061003\n",
            "\n",
            "======== Epoch 782 =========\n",
            "Train loss : 0.099017, Test loss : 0.091447, Validation loss : 0.060960\n",
            "\n",
            "======== Epoch 783 =========\n",
            "Train loss : 0.098967, Test loss : 0.091419, Validation loss : 0.060917\n",
            "\n",
            "======== Epoch 784 =========\n",
            "Train loss : 0.098917, Test loss : 0.091378, Validation loss : 0.060875\n",
            "\n",
            "======== Epoch 785 =========\n",
            "Train loss : 0.098867, Test loss : 0.091355, Validation loss : 0.060832\n",
            "\n",
            "======== Epoch 786 =========\n",
            "Train loss : 0.098817, Test loss : 0.091309, Validation loss : 0.060790\n",
            "\n",
            "======== Epoch 787 =========\n",
            "Train loss : 0.098767, Test loss : 0.091289, Validation loss : 0.060748\n",
            "\n",
            "======== Epoch 788 =========\n",
            "Train loss : 0.098717, Test loss : 0.091242, Validation loss : 0.060707\n",
            "\n",
            "======== Epoch 789 =========\n",
            "Train loss : 0.098668, Test loss : 0.091223, Validation loss : 0.060664\n",
            "\n",
            "======== Epoch 790 =========\n",
            "Train loss : 0.098619, Test loss : 0.091174, Validation loss : 0.060623\n",
            "\n",
            "======== Epoch 791 =========\n",
            "Train loss : 0.098570, Test loss : 0.091160, Validation loss : 0.060581\n",
            "\n",
            "======== Epoch 792 =========\n",
            "Train loss : 0.098521, Test loss : 0.091108, Validation loss : 0.060541\n",
            "\n",
            "======== Epoch 793 =========\n",
            "Train loss : 0.098472, Test loss : 0.091087, Validation loss : 0.060498\n",
            "\n",
            "======== Epoch 794 =========\n",
            "Train loss : 0.098423, Test loss : 0.091049, Validation loss : 0.060458\n",
            "\n",
            "======== Epoch 795 =========\n",
            "Train loss : 0.098375, Test loss : 0.091021, Validation loss : 0.060417\n",
            "\n",
            "======== Epoch 796 =========\n",
            "Train loss : 0.098326, Test loss : 0.090985, Validation loss : 0.060377\n",
            "\n",
            "======== Epoch 797 =========\n",
            "Train loss : 0.098278, Test loss : 0.090950, Validation loss : 0.060336\n",
            "\n",
            "======== Epoch 798 =========\n",
            "Train loss : 0.098230, Test loss : 0.090928, Validation loss : 0.060295\n",
            "\n",
            "======== Epoch 799 =========\n",
            "Train loss : 0.098182, Test loss : 0.090880, Validation loss : 0.060256\n",
            "\n",
            "======== Epoch 800 =========\n",
            "Train loss : 0.098134, Test loss : 0.090866, Validation loss : 0.060215\n",
            "\n",
            "======== Epoch 801 =========\n",
            "Train loss : 0.098086, Test loss : 0.090813, Validation loss : 0.060176\n",
            "\n",
            "======== Epoch 802 =========\n",
            "Train loss : 0.098039, Test loss : 0.090801, Validation loss : 0.060136\n",
            "\n",
            "======== Epoch 803 =========\n",
            "Train loss : 0.097991, Test loss : 0.090753, Validation loss : 0.060097\n",
            "\n",
            "======== Epoch 804 =========\n",
            "Train loss : 0.097944, Test loss : 0.090733, Validation loss : 0.060057\n",
            "\n",
            "======== Epoch 805 =========\n",
            "Train loss : 0.097897, Test loss : 0.090691, Validation loss : 0.060019\n",
            "\n",
            "======== Epoch 806 =========\n",
            "Train loss : 0.097850, Test loss : 0.090664, Validation loss : 0.059980\n",
            "\n",
            "======== Epoch 807 =========\n",
            "Train loss : 0.097803, Test loss : 0.090639, Validation loss : 0.059941\n",
            "\n",
            "======== Epoch 808 =========\n",
            "Train loss : 0.097756, Test loss : 0.090595, Validation loss : 0.059904\n",
            "\n",
            "======== Epoch 809 =========\n",
            "Train loss : 0.097710, Test loss : 0.090575, Validation loss : 0.059865\n",
            "\n",
            "======== Epoch 810 =========\n",
            "Train loss : 0.097663, Test loss : 0.090533, Validation loss : 0.059827\n",
            "\n",
            "======== Epoch 811 =========\n",
            "Train loss : 0.097617, Test loss : 0.090505, Validation loss : 0.059789\n",
            "\n",
            "======== Epoch 812 =========\n",
            "Train loss : 0.097571, Test loss : 0.090470, Validation loss : 0.059751\n",
            "\n",
            "======== Epoch 813 =========\n",
            "Train loss : 0.097525, Test loss : 0.090439, Validation loss : 0.059713\n",
            "\n",
            "======== Epoch 814 =========\n",
            "Train loss : 0.097479, Test loss : 0.090412, Validation loss : 0.059676\n",
            "\n",
            "======== Epoch 815 =========\n",
            "Train loss : 0.097434, Test loss : 0.090373, Validation loss : 0.059638\n",
            "\n",
            "======== Epoch 816 =========\n",
            "Train loss : 0.097388, Test loss : 0.090347, Validation loss : 0.059601\n",
            "\n",
            "======== Epoch 817 =========\n",
            "Train loss : 0.097343, Test loss : 0.090314, Validation loss : 0.059564\n",
            "\n",
            "======== Epoch 818 =========\n",
            "Train loss : 0.097297, Test loss : 0.090283, Validation loss : 0.059527\n",
            "\n",
            "======== Epoch 819 =========\n",
            "Train loss : 0.097252, Test loss : 0.090257, Validation loss : 0.059489\n",
            "\n",
            "======== Epoch 820 =========\n",
            "Train loss : 0.097207, Test loss : 0.090209, Validation loss : 0.059453\n",
            "\n",
            "======== Epoch 821 =========\n",
            "Train loss : 0.097162, Test loss : 0.090201, Validation loss : 0.059415\n",
            "\n",
            "======== Epoch 822 =========\n",
            "Train loss : 0.097117, Test loss : 0.090145, Validation loss : 0.059380\n",
            "\n",
            "======== Epoch 823 =========\n",
            "Train loss : 0.097073, Test loss : 0.090141, Validation loss : 0.059342\n",
            "\n",
            "======== Epoch 824 =========\n",
            "Train loss : 0.097028, Test loss : 0.090085, Validation loss : 0.059308\n",
            "\n",
            "======== Epoch 825 =========\n",
            "Train loss : 0.096984, Test loss : 0.090077, Validation loss : 0.059270\n",
            "\n",
            "======== Epoch 826 =========\n",
            "Train loss : 0.096939, Test loss : 0.090029, Validation loss : 0.059235\n",
            "\n",
            "======== Epoch 827 =========\n",
            "Train loss : 0.096895, Test loss : 0.090006, Validation loss : 0.059199\n",
            "\n",
            "======== Epoch 828 =========\n",
            "Train loss : 0.096851, Test loss : 0.089975, Validation loss : 0.059163\n",
            "\n",
            "======== Epoch 829 =========\n",
            "Train loss : 0.096807, Test loss : 0.089944, Validation loss : 0.059127\n",
            "\n",
            "======== Epoch 830 =========\n",
            "Train loss : 0.096764, Test loss : 0.089918, Validation loss : 0.059092\n",
            "\n",
            "======== Epoch 831 =========\n",
            "Train loss : 0.096720, Test loss : 0.089882, Validation loss : 0.059057\n",
            "\n",
            "======== Epoch 832 =========\n",
            "Train loss : 0.096676, Test loss : 0.089859, Validation loss : 0.059021\n",
            "\n",
            "======== Epoch 833 =========\n",
            "Train loss : 0.096633, Test loss : 0.089814, Validation loss : 0.058987\n",
            "\n",
            "======== Epoch 834 =========\n",
            "Train loss : 0.096590, Test loss : 0.089807, Validation loss : 0.058950\n",
            "\n",
            "======== Epoch 835 =========\n",
            "Train loss : 0.096547, Test loss : 0.089710, Validation loss : 0.058913\n",
            "\n",
            "======== Epoch 836 =========\n",
            "Train loss : 0.096504, Test loss : 0.089759, Validation loss : 0.058872\n",
            "\n",
            "======== Epoch 837 =========\n",
            "Train loss : 0.096461, Test loss : 0.089686, Validation loss : 0.058842\n",
            "\n",
            "======== Epoch 838 =========\n",
            "Train loss : 0.096418, Test loss : 0.089685, Validation loss : 0.058805\n",
            "\n",
            "======== Epoch 839 =========\n",
            "Train loss : 0.096375, Test loss : 0.089634, Validation loss : 0.058773\n",
            "\n",
            "======== Epoch 840 =========\n",
            "Train loss : 0.096333, Test loss : 0.089622, Validation loss : 0.058737\n",
            "\n",
            "======== Epoch 841 =========\n",
            "Train loss : 0.096290, Test loss : 0.089573, Validation loss : 0.058704\n",
            "\n",
            "======== Epoch 842 =========\n",
            "Train loss : 0.096248, Test loss : 0.089574, Validation loss : 0.058669\n",
            "\n",
            "======== Epoch 843 =========\n",
            "Train loss : 0.096206, Test loss : 0.089511, Validation loss : 0.058637\n",
            "\n",
            "======== Epoch 844 =========\n",
            "Train loss : 0.096163, Test loss : 0.089512, Validation loss : 0.058602\n",
            "\n",
            "======== Epoch 845 =========\n",
            "Train loss : 0.096121, Test loss : 0.089459, Validation loss : 0.058570\n",
            "\n",
            "======== Epoch 846 =========\n",
            "Train loss : 0.096080, Test loss : 0.089450, Validation loss : 0.058535\n",
            "\n",
            "======== Epoch 847 =========\n",
            "Train loss : 0.096038, Test loss : 0.089404, Validation loss : 0.058504\n",
            "\n",
            "======== Epoch 848 =========\n",
            "Train loss : 0.095996, Test loss : 0.089390, Validation loss : 0.058469\n",
            "\n",
            "======== Epoch 849 =========\n",
            "Train loss : 0.095955, Test loss : 0.089350, Validation loss : 0.058438\n",
            "\n",
            "======== Epoch 850 =========\n",
            "Train loss : 0.095913, Test loss : 0.089326, Validation loss : 0.058404\n",
            "\n",
            "======== Epoch 851 =========\n",
            "Train loss : 0.095872, Test loss : 0.089299, Validation loss : 0.058372\n",
            "\n",
            "======== Epoch 852 =========\n",
            "Train loss : 0.095831, Test loss : 0.089262, Validation loss : 0.058339\n",
            "\n",
            "======== Epoch 853 =========\n",
            "Train loss : 0.095790, Test loss : 0.089249, Validation loss : 0.058305\n",
            "\n",
            "======== Epoch 854 =========\n",
            "Train loss : 0.095749, Test loss : 0.089201, Validation loss : 0.058275\n",
            "\n",
            "======== Epoch 855 =========\n",
            "Train loss : 0.095708, Test loss : 0.089191, Validation loss : 0.058241\n",
            "\n",
            "======== Epoch 856 =========\n",
            "Train loss : 0.095667, Test loss : 0.089145, Validation loss : 0.058210\n",
            "\n",
            "======== Epoch 857 =========\n",
            "Train loss : 0.095626, Test loss : 0.089139, Validation loss : 0.058176\n",
            "\n",
            "======== Epoch 858 =========\n",
            "Train loss : 0.095586, Test loss : 0.089084, Validation loss : 0.058146\n",
            "\n",
            "======== Epoch 859 =========\n",
            "Train loss : 0.095545, Test loss : 0.089079, Validation loss : 0.058113\n",
            "\n",
            "======== Epoch 860 =========\n",
            "Train loss : 0.095505, Test loss : 0.089034, Validation loss : 0.058082\n",
            "\n",
            "======== Epoch 861 =========\n",
            "Train loss : 0.095465, Test loss : 0.089019, Validation loss : 0.058050\n",
            "\n",
            "======== Epoch 862 =========\n",
            "Train loss : 0.095424, Test loss : 0.088983, Validation loss : 0.058018\n",
            "\n",
            "======== Epoch 863 =========\n",
            "Train loss : 0.095384, Test loss : 0.088955, Validation loss : 0.057987\n",
            "\n",
            "======== Epoch 864 =========\n",
            "Train loss : 0.095344, Test loss : 0.088933, Validation loss : 0.057956\n",
            "\n",
            "======== Epoch 865 =========\n",
            "Train loss : 0.095304, Test loss : 0.088902, Validation loss : 0.057924\n",
            "\n",
            "======== Epoch 866 =========\n",
            "Train loss : 0.095265, Test loss : 0.088878, Validation loss : 0.057894\n",
            "\n",
            "======== Epoch 867 =========\n",
            "Train loss : 0.095225, Test loss : 0.088842, Validation loss : 0.057863\n",
            "\n",
            "======== Epoch 868 =========\n",
            "Train loss : 0.095185, Test loss : 0.088819, Validation loss : 0.057831\n",
            "\n",
            "======== Epoch 869 =========\n",
            "Train loss : 0.095146, Test loss : 0.088803, Validation loss : 0.057800\n",
            "\n",
            "======== Epoch 870 =========\n",
            "Train loss : 0.095107, Test loss : 0.088753, Validation loss : 0.057771\n",
            "\n",
            "======== Epoch 871 =========\n",
            "Train loss : 0.095068, Test loss : 0.088753, Validation loss : 0.057739\n",
            "\n",
            "======== Epoch 872 =========\n",
            "Train loss : 0.095028, Test loss : 0.088696, Validation loss : 0.057710\n",
            "\n",
            "======== Epoch 873 =========\n",
            "Train loss : 0.094989, Test loss : 0.088696, Validation loss : 0.057678\n",
            "\n",
            "======== Epoch 874 =========\n",
            "Train loss : 0.094951, Test loss : 0.088648, Validation loss : 0.057650\n",
            "\n",
            "======== Epoch 875 =========\n",
            "Train loss : 0.094912, Test loss : 0.088635, Validation loss : 0.057619\n",
            "\n",
            "======== Epoch 876 =========\n",
            "Train loss : 0.094873, Test loss : 0.088602, Validation loss : 0.057589\n",
            "\n",
            "======== Epoch 877 =========\n",
            "Train loss : 0.094834, Test loss : 0.088576, Validation loss : 0.057559\n",
            "\n",
            "======== Epoch 878 =========\n",
            "Train loss : 0.094796, Test loss : 0.088543, Validation loss : 0.057530\n",
            "\n",
            "======== Epoch 879 =========\n",
            "Train loss : 0.094757, Test loss : 0.088538, Validation loss : 0.057499\n",
            "\n",
            "======== Epoch 880 =========\n",
            "Train loss : 0.094719, Test loss : 0.088483, Validation loss : 0.057471\n",
            "\n",
            "======== Epoch 881 =========\n",
            "Train loss : 0.094681, Test loss : 0.088481, Validation loss : 0.057440\n",
            "\n",
            "======== Epoch 882 =========\n",
            "Train loss : 0.094643, Test loss : 0.088435, Validation loss : 0.057412\n",
            "\n",
            "======== Epoch 883 =========\n",
            "Train loss : 0.094605, Test loss : 0.088415, Validation loss : 0.057382\n",
            "\n",
            "======== Epoch 884 =========\n",
            "Train loss : 0.094567, Test loss : 0.088396, Validation loss : 0.057353\n",
            "\n",
            "======== Epoch 885 =========\n",
            "Train loss : 0.094529, Test loss : 0.088357, Validation loss : 0.057325\n",
            "\n",
            "======== Epoch 886 =========\n",
            "Train loss : 0.094491, Test loss : 0.088346, Validation loss : 0.057295\n",
            "\n",
            "======== Epoch 887 =========\n",
            "Train loss : 0.094454, Test loss : 0.088303, Validation loss : 0.057267\n",
            "\n",
            "======== Epoch 888 =========\n",
            "Train loss : 0.094416, Test loss : 0.088284, Validation loss : 0.057238\n",
            "\n",
            "======== Epoch 889 =========\n",
            "Train loss : 0.094379, Test loss : 0.088253, Validation loss : 0.057210\n",
            "\n",
            "======== Epoch 890 =========\n",
            "Train loss : 0.094341, Test loss : 0.088244, Validation loss : 0.057180\n",
            "\n",
            "======== Epoch 891 =========\n",
            "Train loss : 0.094304, Test loss : 0.088195, Validation loss : 0.057154\n",
            "\n",
            "======== Epoch 892 =========\n",
            "Train loss : 0.094267, Test loss : 0.088190, Validation loss : 0.057124\n",
            "\n",
            "======== Epoch 893 =========\n",
            "Train loss : 0.094230, Test loss : 0.088147, Validation loss : 0.057096\n",
            "\n",
            "======== Epoch 894 =========\n",
            "Train loss : 0.094193, Test loss : 0.088132, Validation loss : 0.057068\n",
            "\n",
            "======== Epoch 895 =========\n",
            "Train loss : 0.094156, Test loss : 0.088094, Validation loss : 0.057041\n",
            "\n",
            "======== Epoch 896 =========\n",
            "Train loss : 0.094119, Test loss : 0.088090, Validation loss : 0.057012\n",
            "\n",
            "======== Epoch 897 =========\n",
            "Train loss : 0.094082, Test loss : 0.088041, Validation loss : 0.056985\n",
            "\n",
            "======== Epoch 898 =========\n",
            "Train loss : 0.094046, Test loss : 0.088034, Validation loss : 0.056956\n",
            "\n",
            "======== Epoch 899 =========\n",
            "Train loss : 0.094009, Test loss : 0.087953, Validation loss : 0.056925\n",
            "\n",
            "======== Epoch 900 =========\n",
            "Train loss : 0.093973, Test loss : 0.087989, Validation loss : 0.056894\n",
            "\n",
            "======== Epoch 901 =========\n",
            "Train loss : 0.093936, Test loss : 0.087934, Validation loss : 0.056868\n",
            "\n",
            "======== Epoch 902 =========\n",
            "Train loss : 0.093900, Test loss : 0.087933, Validation loss : 0.056839\n",
            "\n",
            "======== Epoch 903 =========\n",
            "Train loss : 0.093864, Test loss : 0.087883, Validation loss : 0.056813\n",
            "\n",
            "======== Epoch 904 =========\n",
            "Train loss : 0.093828, Test loss : 0.087877, Validation loss : 0.056785\n",
            "\n",
            "======== Epoch 905 =========\n",
            "Train loss : 0.093793, Test loss : 0.087836, Validation loss : 0.056759\n",
            "\n",
            "======== Epoch 906 =========\n",
            "Train loss : 0.093757, Test loss : 0.087831, Validation loss : 0.056730\n",
            "\n",
            "======== Epoch 907 =========\n",
            "Train loss : 0.093721, Test loss : 0.087780, Validation loss : 0.056705\n",
            "\n",
            "======== Epoch 908 =========\n",
            "Train loss : 0.093686, Test loss : 0.087782, Validation loss : 0.056677\n",
            "\n",
            "======== Epoch 909 =========\n",
            "Train loss : 0.093650, Test loss : 0.087727, Validation loss : 0.056651\n",
            "\n",
            "======== Epoch 910 =========\n",
            "Train loss : 0.093615, Test loss : 0.087728, Validation loss : 0.056624\n",
            "\n",
            "======== Epoch 911 =========\n",
            "Train loss : 0.093580, Test loss : 0.087684, Validation loss : 0.056598\n",
            "\n",
            "======== Epoch 912 =========\n",
            "Train loss : 0.093544, Test loss : 0.087675, Validation loss : 0.056571\n",
            "\n",
            "======== Epoch 913 =========\n",
            "Train loss : 0.093509, Test loss : 0.087630, Validation loss : 0.056545\n",
            "\n",
            "======== Epoch 914 =========\n",
            "Train loss : 0.093474, Test loss : 0.087616, Validation loss : 0.056517\n",
            "\n",
            "======== Epoch 915 =========\n",
            "Train loss : 0.093439, Test loss : 0.087592, Validation loss : 0.056492\n",
            "\n",
            "======== Epoch 916 =========\n",
            "Train loss : 0.093405, Test loss : 0.087567, Validation loss : 0.056465\n",
            "\n",
            "======== Epoch 917 =========\n",
            "Train loss : 0.093370, Test loss : 0.087535, Validation loss : 0.056439\n",
            "\n",
            "======== Epoch 918 =========\n",
            "Train loss : 0.093335, Test loss : 0.087518, Validation loss : 0.056413\n",
            "\n",
            "======== Epoch 919 =========\n",
            "Train loss : 0.093301, Test loss : 0.087486, Validation loss : 0.056387\n",
            "\n",
            "======== Epoch 920 =========\n",
            "Train loss : 0.093266, Test loss : 0.087467, Validation loss : 0.056361\n",
            "\n",
            "======== Epoch 921 =========\n",
            "Train loss : 0.093232, Test loss : 0.087429, Validation loss : 0.056335\n",
            "\n",
            "======== Epoch 922 =========\n",
            "Train loss : 0.093197, Test loss : 0.087422, Validation loss : 0.056309\n",
            "\n",
            "======== Epoch 923 =========\n",
            "Train loss : 0.093163, Test loss : 0.087383, Validation loss : 0.056284\n",
            "\n",
            "======== Epoch 924 =========\n",
            "Train loss : 0.093129, Test loss : 0.087368, Validation loss : 0.056258\n",
            "\n",
            "======== Epoch 925 =========\n",
            "Train loss : 0.093095, Test loss : 0.087338, Validation loss : 0.056232\n",
            "\n",
            "======== Epoch 926 =========\n",
            "Train loss : 0.093061, Test loss : 0.087314, Validation loss : 0.056207\n",
            "\n",
            "======== Epoch 927 =========\n",
            "Train loss : 0.093027, Test loss : 0.087287, Validation loss : 0.056182\n",
            "\n",
            "======== Epoch 928 =========\n",
            "Train loss : 0.092993, Test loss : 0.087271, Validation loss : 0.056157\n",
            "\n",
            "======== Epoch 929 =========\n",
            "Train loss : 0.092960, Test loss : 0.087234, Validation loss : 0.056132\n",
            "\n",
            "======== Epoch 930 =========\n",
            "Train loss : 0.092926, Test loss : 0.087221, Validation loss : 0.056106\n",
            "\n",
            "======== Epoch 931 =========\n",
            "Train loss : 0.092892, Test loss : 0.087184, Validation loss : 0.056082\n",
            "\n",
            "======== Epoch 932 =========\n",
            "Train loss : 0.092859, Test loss : 0.087174, Validation loss : 0.056056\n",
            "\n",
            "======== Epoch 933 =========\n",
            "Train loss : 0.092825, Test loss : 0.087139, Validation loss : 0.056032\n",
            "\n",
            "======== Epoch 934 =========\n",
            "Train loss : 0.092792, Test loss : 0.087130, Validation loss : 0.056007\n",
            "\n",
            "======== Epoch 935 =========\n",
            "Train loss : 0.092759, Test loss : 0.087084, Validation loss : 0.055983\n",
            "\n",
            "======== Epoch 936 =========\n",
            "Train loss : 0.092726, Test loss : 0.087074, Validation loss : 0.055958\n",
            "\n",
            "======== Epoch 937 =========\n",
            "Train loss : 0.092693, Test loss : 0.087046, Validation loss : 0.055934\n",
            "\n",
            "======== Epoch 938 =========\n",
            "Train loss : 0.092659, Test loss : 0.087021, Validation loss : 0.055909\n",
            "\n",
            "======== Epoch 939 =========\n",
            "Train loss : 0.092626, Test loss : 0.087001, Validation loss : 0.055885\n",
            "\n",
            "======== Epoch 940 =========\n",
            "Train loss : 0.092594, Test loss : 0.086971, Validation loss : 0.055861\n",
            "\n",
            "======== Epoch 941 =========\n",
            "Train loss : 0.092561, Test loss : 0.086952, Validation loss : 0.055837\n",
            "\n",
            "======== Epoch 942 =========\n",
            "Train loss : 0.092528, Test loss : 0.086926, Validation loss : 0.055813\n",
            "\n",
            "======== Epoch 943 =========\n",
            "Train loss : 0.092496, Test loss : 0.086901, Validation loss : 0.055789\n",
            "\n",
            "======== Epoch 944 =========\n",
            "Train loss : 0.092463, Test loss : 0.086873, Validation loss : 0.055765\n",
            "\n",
            "======== Epoch 945 =========\n",
            "Train loss : 0.092431, Test loss : 0.086859, Validation loss : 0.055741\n",
            "\n",
            "======== Epoch 946 =========\n",
            "Train loss : 0.092398, Test loss : 0.086832, Validation loss : 0.055718\n",
            "\n",
            "======== Epoch 947 =========\n",
            "Train loss : 0.092366, Test loss : 0.086805, Validation loss : 0.055695\n",
            "\n",
            "======== Epoch 948 =========\n",
            "Train loss : 0.092334, Test loss : 0.086782, Validation loss : 0.055671\n",
            "\n",
            "======== Epoch 949 =========\n",
            "Train loss : 0.092301, Test loss : 0.086760, Validation loss : 0.055647\n",
            "\n",
            "======== Epoch 950 =========\n",
            "Train loss : 0.092269, Test loss : 0.086733, Validation loss : 0.055624\n",
            "\n",
            "======== Epoch 951 =========\n",
            "Train loss : 0.092237, Test loss : 0.086717, Validation loss : 0.055601\n",
            "\n",
            "======== Epoch 952 =========\n",
            "Train loss : 0.092205, Test loss : 0.086683, Validation loss : 0.055578\n",
            "\n",
            "======== Epoch 953 =========\n",
            "Train loss : 0.092173, Test loss : 0.086672, Validation loss : 0.055555\n",
            "\n",
            "======== Epoch 954 =========\n",
            "Train loss : 0.092142, Test loss : 0.086635, Validation loss : 0.055532\n",
            "\n",
            "======== Epoch 955 =========\n",
            "Train loss : 0.092110, Test loss : 0.086622, Validation loss : 0.055508\n",
            "\n",
            "======== Epoch 956 =========\n",
            "Train loss : 0.092078, Test loss : 0.086600, Validation loss : 0.055486\n",
            "\n",
            "======== Epoch 957 =========\n",
            "Train loss : 0.092047, Test loss : 0.086521, Validation loss : 0.055457\n",
            "\n",
            "======== Epoch 958 =========\n",
            "Train loss : 0.092015, Test loss : 0.086563, Validation loss : 0.055432\n",
            "\n",
            "======== Epoch 959 =========\n",
            "Train loss : 0.091984, Test loss : 0.086514, Validation loss : 0.055411\n",
            "\n",
            "======== Epoch 960 =========\n",
            "Train loss : 0.091952, Test loss : 0.086505, Validation loss : 0.055388\n",
            "\n",
            "======== Epoch 961 =========\n",
            "Train loss : 0.091921, Test loss : 0.086473, Validation loss : 0.055365\n",
            "\n",
            "======== Epoch 962 =========\n",
            "Train loss : 0.091890, Test loss : 0.086454, Validation loss : 0.055343\n",
            "\n",
            "======== Epoch 963 =========\n",
            "Train loss : 0.091859, Test loss : 0.086430, Validation loss : 0.055321\n",
            "\n",
            "======== Epoch 964 =========\n",
            "Train loss : 0.091828, Test loss : 0.086410, Validation loss : 0.055299\n",
            "\n",
            "======== Epoch 965 =========\n",
            "Train loss : 0.091797, Test loss : 0.086392, Validation loss : 0.055277\n",
            "\n",
            "======== Epoch 966 =========\n",
            "Train loss : 0.091766, Test loss : 0.086356, Validation loss : 0.055255\n",
            "\n",
            "======== Epoch 967 =========\n",
            "Train loss : 0.091735, Test loss : 0.086347, Validation loss : 0.055233\n",
            "\n",
            "======== Epoch 968 =========\n",
            "Train loss : 0.091704, Test loss : 0.086310, Validation loss : 0.055212\n",
            "\n",
            "======== Epoch 969 =========\n",
            "Train loss : 0.091673, Test loss : 0.086298, Validation loss : 0.055190\n",
            "\n",
            "======== Epoch 970 =========\n",
            "Train loss : 0.091643, Test loss : 0.086268, Validation loss : 0.055169\n",
            "\n",
            "======== Epoch 971 =========\n",
            "Train loss : 0.091612, Test loss : 0.086256, Validation loss : 0.055146\n",
            "\n",
            "======== Epoch 972 =========\n",
            "Train loss : 0.091582, Test loss : 0.086220, Validation loss : 0.055125\n",
            "\n",
            "======== Epoch 973 =========\n",
            "Train loss : 0.091551, Test loss : 0.086210, Validation loss : 0.055103\n",
            "\n",
            "======== Epoch 974 =========\n",
            "Train loss : 0.091521, Test loss : 0.086176, Validation loss : 0.055082\n",
            "\n",
            "======== Epoch 975 =========\n",
            "Train loss : 0.091491, Test loss : 0.086158, Validation loss : 0.055060\n",
            "\n",
            "======== Epoch 976 =========\n",
            "Train loss : 0.091460, Test loss : 0.086139, Validation loss : 0.055039\n",
            "\n",
            "======== Epoch 977 =========\n",
            "Train loss : 0.091430, Test loss : 0.086109, Validation loss : 0.055018\n",
            "\n",
            "======== Epoch 978 =========\n",
            "Train loss : 0.091400, Test loss : 0.086092, Validation loss : 0.054997\n",
            "\n",
            "======== Epoch 979 =========\n",
            "Train loss : 0.091370, Test loss : 0.086068, Validation loss : 0.054976\n",
            "\n",
            "======== Epoch 980 =========\n",
            "Train loss : 0.091340, Test loss : 0.086050, Validation loss : 0.054955\n",
            "\n",
            "======== Epoch 981 =========\n",
            "Train loss : 0.091310, Test loss : 0.086022, Validation loss : 0.054933\n",
            "\n",
            "======== Epoch 982 =========\n",
            "Train loss : 0.091280, Test loss : 0.086007, Validation loss : 0.054913\n",
            "\n",
            "======== Epoch 983 =========\n",
            "Train loss : 0.091251, Test loss : 0.085972, Validation loss : 0.054892\n",
            "\n",
            "======== Epoch 984 =========\n",
            "Train loss : 0.091221, Test loss : 0.085959, Validation loss : 0.054871\n",
            "\n",
            "======== Epoch 985 =========\n",
            "Train loss : 0.091191, Test loss : 0.085936, Validation loss : 0.054851\n",
            "\n",
            "======== Epoch 986 =========\n",
            "Train loss : 0.091162, Test loss : 0.085915, Validation loss : 0.054830\n",
            "\n",
            "======== Epoch 987 =========\n",
            "Train loss : 0.091132, Test loss : 0.085879, Validation loss : 0.054810\n",
            "\n",
            "======== Epoch 988 =========\n",
            "Train loss : 0.091103, Test loss : 0.085872, Validation loss : 0.054789\n",
            "\n",
            "======== Epoch 989 =========\n",
            "Train loss : 0.091074, Test loss : 0.085838, Validation loss : 0.054769\n",
            "\n",
            "======== Epoch 990 =========\n",
            "Train loss : 0.091044, Test loss : 0.085834, Validation loss : 0.054748\n",
            "\n",
            "======== Epoch 991 =========\n",
            "Train loss : 0.091015, Test loss : 0.085793, Validation loss : 0.054729\n",
            "\n",
            "======== Epoch 992 =========\n",
            "Train loss : 0.090986, Test loss : 0.085782, Validation loss : 0.054708\n",
            "\n",
            "======== Epoch 993 =========\n",
            "Train loss : 0.090957, Test loss : 0.085752, Validation loss : 0.054687\n",
            "\n",
            "======== Epoch 994 =========\n",
            "Train loss : 0.090928, Test loss : 0.085741, Validation loss : 0.054668\n",
            "\n",
            "======== Epoch 995 =========\n",
            "Train loss : 0.090899, Test loss : 0.085706, Validation loss : 0.054648\n",
            "\n",
            "======== Epoch 996 =========\n",
            "Train loss : 0.090870, Test loss : 0.085694, Validation loss : 0.054627\n",
            "\n",
            "======== Epoch 997 =========\n",
            "Train loss : 0.090841, Test loss : 0.085669, Validation loss : 0.054608\n",
            "\n",
            "======== Epoch 998 =========\n",
            "Train loss : 0.090812, Test loss : 0.085649, Validation loss : 0.054588\n",
            "\n",
            "======== Epoch 999 =========\n",
            "Train loss : 0.090784, Test loss : 0.085624, Validation loss : 0.054567\n",
            "\n",
            "======== Epoch 1000 =========\n",
            "Train loss : 0.090755, Test loss : 0.085610, Validation loss : 0.054548\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Scoring\n",
        "분류에 대한 평가 지표로는 아래와 같은 지표들이 사용 가능하다.  \n",
        "\n",
        "- Accuracy(정확도) : 정확히 예측한 Example 수 / 전체 Example 수\n",
        "- Precision(정밀도) : 실제로 맞춘 Example 수 / 특정 Class라고 예측한 Example 수\n",
        "  - 3가지 Class에 대해서 Average precision을 계산해서 도출한다.\n",
        "- Recall(재현률) : 실제로 맞춘 Eaxmple 수 / 실제 특정 Class의 Example 수\n",
        "  - 3가지 Class에 대해서 Average recall을 계산해서 도출한다.\n",
        "- F-1 Score : 2 * (precision X recall) / (precision + recall) (조화 평균)\n",
        "- Confusion matrix를 통해 한 눈에 확인이 가능하다."
      ],
      "metadata": {
        "id": "o2GmWRSpbHVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy 측정\n",
        "def get_result_class(pred):\n",
        "  result = [] # 예측된 Class를 저장할 배열\n",
        "  pred = pred.numpy()\n",
        "  \n",
        "  for example in range(len(pred)):\n",
        "    result.append(np.argmax(pred[example]))\n",
        "    # 가장 큰 값이 나온 index가, 즉 예측된 class가 된다.\n",
        "\n",
        "  return result\n",
        "  # 몇 개나 맞췄는지 정확도를 반환한다.\n",
        "\n",
        "def print_score(org_set, pred_set, set_name):\n",
        "  print(\"Accuracy of\", set_name, \"set : \", round(met.accuracy_score(org_set, pred_set) * 100, 3))\n",
        "  print(\"Precision of\", set_name, \"set : \", round(met.precision_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print(\"Recall of\", set_name, \"set : \", round(met.recall_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print(\"F-1 Score of\", set_name, \"set : \", round(met.f1_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print()\n",
        "  print(met.confusion_matrix(org_set, pred_set))\n",
        "  print(\"=================================\")\n",
        "\n",
        "with torch.no_grad():\n",
        "# torch.no_grad() 함수를 통해, weight 업데이트 없이 테스트가 가능하다.\n",
        "  train_pred = model(x_train)\n",
        "  test_pred = model(x_test)\n",
        "  valid_pred = model(x_valid)\n",
        "\n",
        "train_result = get_result_class(train_pred)\n",
        "test_result = get_result_class(test_pred)\n",
        "valid_result = get_result_class(valid_pred)\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "print_score(y_train, train_result, \"train\")\n",
        "print_score(y_test, test_result, \"test\")\n",
        "print_score(y_valid, valid_result, \"valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeGizBI0hBlJ",
        "outputId": "6a93ab5a-6b00-4ea4-a031-19a988414296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "\n",
            "Accuracy of  train  set :  97.778\n",
            "Precision of  train  set :  97.908\n",
            "Recall of  train  set :  97.778\n",
            "F-1 Score of  train  set :  97.774\n",
            "\n",
            "[[27  0  0]\n",
            " [ 0 29  2]\n",
            " [ 0  0 32]]\n",
            "=================================\n",
            "Accuracy of  test  set :  96.667\n",
            "Precision of  test  set :  97.143\n",
            "Recall of  test  set :  96.667\n",
            "F-1 Score of  test  set :  96.722\n",
            "\n",
            "[[12  0  0]\n",
            " [ 0  6  0]\n",
            " [ 0  1 11]]\n",
            "=================================\n",
            "Accuracy of  valid  set :  100.0\n",
            "Precision of  valid  set :  100.0\n",
            "Recall of  valid  set :  100.0\n",
            "F-1 Score of  valid  set :  100.0\n",
            "\n",
            "[[11  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0  6]]\n",
            "=================================\n"
          ]
        }
      ]
    }
  ]
}