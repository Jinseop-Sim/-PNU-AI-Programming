{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 201724500 심진섭 Machine learning assignment #2\n",
        "## 1. Get dataset\n",
        "\n",
        ">가장 먼저, pdf에서 제공받은 iris(붓꽃) dataset을 가져와 읽어온다.\n",
        "\n",
        "이전 과제와는 다르게 iris data로 데이터가 고정되었다.\n",
        "기계 학습에서 가장 유명한 데이터로, 아래와 같은 Attribute를 가진다.\n",
        "- Sepal length (cm) : 꽃받침의 길이\n",
        "- Sepal width (cm) : 꽃받침의 너비\n",
        "- Petal length (cm) : 꽃잎의 길이\n",
        "- Petal width (cm) : 꽃잎의 너비\n",
        "\n",
        "위의 4가지 Attribute를 통해 총 150개의 Example을 아래 3가지 class에 대해 학습한다.\n",
        "- Setosa : 부채 붓꽃\n",
        "- Versicolour : 버시칼라 붓꽃\n",
        "- Virginica : 버지니카 붓꽃\n",
        "\n",
        "## 1-1. 왜 Pytorch를 사용했는가?\n",
        "이번 과제에서는 Keras, tensorflow 등 여러 프레임워크를 사용할 수 있지만 나는 Pytorch를 사용해보기로 했다.  \n",
        "아래와 같은 이유로 Pytorch를 선택하게 되었다.  \n",
        "- 이전에 학습한 적이 있어 다른 프레임워크들에 비해 익숙하다.\n",
        "- 문법의 형태가 기존 파이썬에서 크게 벗어나지 않아 학습이 쉽다.\n"
      ],
      "metadata": {
        "id": "Pu6a3S77MzT6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WUzBSFI3NXPR",
        "outputId": "8ab060a5-5b46-4f48-9290-40d44e6a8700"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal-length  sepal-width  petal-length  petal-width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-903ef28a-77c4-4344-b05c-f982c8f4b272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal-length</th>\n",
              "      <th>sepal-width</th>\n",
              "      <th>petal-length</th>\n",
              "      <th>petal-width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-903ef28a-77c4-4344-b05c-f982c8f4b272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-903ef28a-77c4-4344-b05c-f982c8f4b272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-903ef28a-77c4-4344-b05c-f982c8f4b272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sklearn.metrics as met\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "col_names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
        "df = pd.read_csv('iris.data', names=col_names)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data preprocessing\n",
        "먼저, 아래와 같이 데이터 전처리를 진행한다.\n",
        "- Categorical data로는 학습 및 분류가 불가능하다.\n",
        "  - 따라서 Numerical data로 factorize() 함수를 통해 변환한다.\n",
        "- Pytorch를 통해 기계 학습을 진행하려면 array가 아닌 Tensor의 형태여야한다.\n",
        "  - torch.from_numpy() 함수를 이용해 변환한다.\n",
        "- Train 60%, Test 20%, Valid 20%로 dataset을 분할해야 한다.\n",
        "  - Scikit learn 패키지의 train_test_split을 이용해서 random하게 분할한다.\n",
        "    - 먼저 Train : Test를 60 : 40으로 분할한다.\n",
        "    - 이후 Test : valid를 50 : 50으로 다시 분할한다.\n",
        "\n",
        "아래와 같은 shape의 가공된 학습 데이터가 만들어진다.\n",
        "- Train set : [90, 4]\n",
        "- Test set : [30, 4]\n",
        "- Valid set : [30, 4]"
      ],
      "metadata": {
        "id": "ZD8WM6NaOxR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 우선 학습을 위해 Dataset을 입력과 결과로 자른다.\n",
        "# 이 때, 학습을 위해 Categorical data로 되어있는 y를 Numerical 하게 변환해준다.\n",
        "df['species'], _ = df['species'].factorize() # Categorical -> Numerical\n",
        "\n",
        "x = df.iloc[:,0:4].values # 입력\n",
        "y = df.iloc[:,4].values # 출력\n",
        "\n",
        "# Pytorch를 통한 기계학습을 위해 Array를 Tensor로 바꾸어 준다.\n",
        "x = torch.from_numpy(x).type(torch.float)\n",
        "y = torch.from_numpy(y).type(torch.long)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
        "x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "print(x_valid.shape, y_valid.shape)"
      ],
      "metadata": {
        "id": "MA_1kWyaO04q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82aac8c0-571d-42a5-92b4-4d8430ba0553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([90, 4]) torch.Size([90])\n",
            "torch.Size([30, 4]) torch.Size([30])\n",
            "torch.Size([30, 4]) torch.Size([30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Neural Network Learning\n",
        "이제 실제로 Feedforward Neural Netwrok를 구성하여 실제로 데이터를 학습시켜 볼 차례이다.  \n",
        "\n",
        "### Network architecture\n",
        "Layer를 쌓는 방식은 자유이므로, 나는 아래와 같이 간단한 network를 구성하였다.\n",
        "- Fully connected layer (90 * 4 -> 90 * 256)\n",
        "- ReLU (Activation function)\n",
        "- Fully connected layer (90 * 256 -> 90 * 128)\n",
        "- ReLU (Activation function)\n",
        "- Fully connected layer (90 * 128 -> 90 * 3)  \n",
        "\n",
        "최초에는 Layer의 크기를 16, 32와 같이 적게 시도했다.  \n",
        "이후 64, 128, 256과 같이 점차 늘려갈 수록 더 높은 정확도를 보였다.  \n",
        "하지만 512, 1024와 같이 너무 많은 neuron의 수는 오히려 정확도를 떨어트림을 확인할 수 있었다.  \n",
        "\n",
        "### Optimizer\n",
        "Optimizer은, weight를 어떤 방식으로 최적화 시켜나갈 것인지에 대한 설정이다.  \n",
        "Stochastic Gradient Descent를 기본적으로 채택하며, hyperparameter에 대한 설정은 자유이므로, 아래와 같이 설정했다.\n",
        "- learning rate(alpha) : 0.01[링크 텍스트](https://)\n",
        "\n",
        "### Loss function\n",
        "Loss function은 Categorical cross entropy 방식으로 고정인데,  \n",
        "Keras의 Categorical cross entropy와 Pytorch의 nn.CrossEntropy는 동일한 기능을 제공한다.  \n",
        "\n",
        "Epoch가 진행될 수록 낮아지는 loss를 확인할 수 있다."
      ],
      "metadata": {
        "id": "yBMJ36bno5RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 3)\n",
        ")\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "## Training 과정\n",
        "\n",
        "for epoch in range(1000):\n",
        "  optimizer.zero_grad() # 이전 epoch에서 쌓인 정보 초기화\n",
        "\n",
        "  train_output = model(x_train) # Feedforward\n",
        "  train_loss = cross_entropy(train_output, y_train) # Calculate loss\n",
        "  train_loss.backward() # Backpropagation, gradient를 계산하는 것\n",
        "  optimizer.step() # 위에서 얻은 정보를 통해 weight를 update한다.\n",
        "\n",
        "  test_output = model(x_test) # Test set에 대한 feedforward\n",
        "  test_loss = cross_entropy(test_output, y_test) # Test set의 loss\n",
        "\n",
        "  valid_output = model(x_valid) # Valid set에 대한 feedforward\n",
        "  valid_loss = cross_entropy(valid_output, y_valid) # Valid set의 loss\n",
        "\n",
        "  print(\"======== Epoch %d =========\" % (epoch + 1))\n",
        "  print(\"Train loss : %f, Test loss : %f, Validation loss : %f\" % (train_loss.item(), test_loss.item(), valid_loss.item()))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSbwma2NSl4b",
        "outputId": "8174b25e-3b6c-4ce3-db35-22108c6abc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 =========\n",
            "Train loss : 1.129534, Test loss : 0.997465, Validation loss : 1.098567\n",
            "\n",
            "======== Epoch 2 =========\n",
            "Train loss : 1.035208, Test loss : 0.983516, Validation loss : 1.060391\n",
            "\n",
            "======== Epoch 3 =========\n",
            "Train loss : 1.003998, Test loss : 0.966623, Validation loss : 1.029106\n",
            "\n",
            "======== Epoch 4 =========\n",
            "Train loss : 0.980955, Test loss : 0.947367, Validation loss : 1.005977\n",
            "\n",
            "======== Epoch 5 =========\n",
            "Train loss : 0.961987, Test loss : 0.928860, Validation loss : 0.985704\n",
            "\n",
            "======== Epoch 6 =========\n",
            "Train loss : 0.945482, Test loss : 0.911618, Validation loss : 0.968372\n",
            "\n",
            "======== Epoch 7 =========\n",
            "Train loss : 0.931072, Test loss : 0.894385, Validation loss : 0.952844\n",
            "\n",
            "======== Epoch 8 =========\n",
            "Train loss : 0.917335, Test loss : 0.878441, Validation loss : 0.937466\n",
            "\n",
            "======== Epoch 9 =========\n",
            "Train loss : 0.904273, Test loss : 0.862167, Validation loss : 0.922879\n",
            "\n",
            "======== Epoch 10 =========\n",
            "Train loss : 0.891383, Test loss : 0.846532, Validation loss : 0.908236\n",
            "\n",
            "======== Epoch 11 =========\n",
            "Train loss : 0.878454, Test loss : 0.830284, Validation loss : 0.893263\n",
            "\n",
            "======== Epoch 12 =========\n",
            "Train loss : 0.865447, Test loss : 0.814959, Validation loss : 0.878702\n",
            "\n",
            "======== Epoch 13 =========\n",
            "Train loss : 0.852762, Test loss : 0.799304, Validation loss : 0.864411\n",
            "\n",
            "======== Epoch 14 =========\n",
            "Train loss : 0.840292, Test loss : 0.784371, Validation loss : 0.850018\n",
            "\n",
            "======== Epoch 15 =========\n",
            "Train loss : 0.827876, Test loss : 0.769126, Validation loss : 0.836151\n",
            "\n",
            "======== Epoch 16 =========\n",
            "Train loss : 0.815449, Test loss : 0.755310, Validation loss : 0.822366\n",
            "\n",
            "======== Epoch 17 =========\n",
            "Train loss : 0.803732, Test loss : 0.741348, Validation loss : 0.810005\n",
            "\n",
            "======== Epoch 18 =========\n",
            "Train loss : 0.792533, Test loss : 0.728544, Validation loss : 0.797591\n",
            "\n",
            "======== Epoch 19 =========\n",
            "Train loss : 0.781820, Test loss : 0.715762, Validation loss : 0.786128\n",
            "\n",
            "======== Epoch 20 =========\n",
            "Train loss : 0.771429, Test loss : 0.703679, Validation loss : 0.774359\n",
            "\n",
            "======== Epoch 21 =========\n",
            "Train loss : 0.761322, Test loss : 0.691673, Validation loss : 0.763405\n",
            "\n",
            "======== Epoch 22 =========\n",
            "Train loss : 0.751462, Test loss : 0.680353, Validation loss : 0.752406\n",
            "\n",
            "======== Epoch 23 =========\n",
            "Train loss : 0.741825, Test loss : 0.669075, Validation loss : 0.741856\n",
            "\n",
            "======== Epoch 24 =========\n",
            "Train loss : 0.732417, Test loss : 0.658324, Validation loss : 0.731464\n",
            "\n",
            "======== Epoch 25 =========\n",
            "Train loss : 0.723233, Test loss : 0.647807, Validation loss : 0.721258\n",
            "\n",
            "======== Epoch 26 =========\n",
            "Train loss : 0.714267, Test loss : 0.637633, Validation loss : 0.711476\n",
            "\n",
            "======== Epoch 27 =========\n",
            "Train loss : 0.705504, Test loss : 0.627679, Validation loss : 0.701996\n",
            "\n",
            "======== Epoch 28 =========\n",
            "Train loss : 0.696976, Test loss : 0.618206, Validation loss : 0.692535\n",
            "\n",
            "======== Epoch 29 =========\n",
            "Train loss : 0.688686, Test loss : 0.608844, Validation loss : 0.683634\n",
            "\n",
            "======== Epoch 30 =========\n",
            "Train loss : 0.680597, Test loss : 0.599927, Validation loss : 0.674786\n",
            "\n",
            "======== Epoch 31 =========\n",
            "Train loss : 0.672732, Test loss : 0.591296, Validation loss : 0.666108\n",
            "\n",
            "======== Epoch 32 =========\n",
            "Train loss : 0.665063, Test loss : 0.582864, Validation loss : 0.657923\n",
            "\n",
            "======== Epoch 33 =========\n",
            "Train loss : 0.657648, Test loss : 0.574678, Validation loss : 0.649918\n",
            "\n",
            "======== Epoch 34 =========\n",
            "Train loss : 0.650419, Test loss : 0.566889, Validation loss : 0.642123\n",
            "\n",
            "======== Epoch 35 =========\n",
            "Train loss : 0.643406, Test loss : 0.559271, Validation loss : 0.634525\n",
            "\n",
            "======== Epoch 36 =========\n",
            "Train loss : 0.636571, Test loss : 0.551838, Validation loss : 0.627007\n",
            "\n",
            "======== Epoch 37 =========\n",
            "Train loss : 0.629925, Test loss : 0.544791, Validation loss : 0.619714\n",
            "\n",
            "======== Epoch 38 =========\n",
            "Train loss : 0.623431, Test loss : 0.537880, Validation loss : 0.612781\n",
            "\n",
            "======== Epoch 39 =========\n",
            "Train loss : 0.617139, Test loss : 0.530977, Validation loss : 0.606049\n",
            "\n",
            "======== Epoch 40 =========\n",
            "Train loss : 0.611005, Test loss : 0.524619, Validation loss : 0.599402\n",
            "\n",
            "======== Epoch 41 =========\n",
            "Train loss : 0.605052, Test loss : 0.518082, Validation loss : 0.593035\n",
            "\n",
            "======== Epoch 42 =========\n",
            "Train loss : 0.599267, Test loss : 0.512182, Validation loss : 0.586693\n",
            "\n",
            "======== Epoch 43 =========\n",
            "Train loss : 0.593610, Test loss : 0.506065, Validation loss : 0.580704\n",
            "\n",
            "======== Epoch 44 =========\n",
            "Train loss : 0.588133, Test loss : 0.500591, Validation loss : 0.574731\n",
            "\n",
            "======== Epoch 45 =========\n",
            "Train loss : 0.582801, Test loss : 0.494872, Validation loss : 0.568960\n",
            "\n",
            "======== Epoch 46 =========\n",
            "Train loss : 0.577602, Test loss : 0.489738, Validation loss : 0.563302\n",
            "\n",
            "======== Epoch 47 =========\n",
            "Train loss : 0.572549, Test loss : 0.484313, Validation loss : 0.557893\n",
            "\n",
            "======== Epoch 48 =========\n",
            "Train loss : 0.567611, Test loss : 0.479432, Validation loss : 0.552539\n",
            "\n",
            "======== Epoch 49 =========\n",
            "Train loss : 0.562818, Test loss : 0.474411, Validation loss : 0.547378\n",
            "\n",
            "======== Epoch 50 =========\n",
            "Train loss : 0.558147, Test loss : 0.469867, Validation loss : 0.542242\n",
            "\n",
            "======== Epoch 51 =========\n",
            "Train loss : 0.553601, Test loss : 0.465039, Validation loss : 0.537416\n",
            "\n",
            "======== Epoch 52 =========\n",
            "Train loss : 0.549153, Test loss : 0.460744, Validation loss : 0.532497\n",
            "\n",
            "======== Epoch 53 =========\n",
            "Train loss : 0.544828, Test loss : 0.456225, Validation loss : 0.527901\n",
            "\n",
            "======== Epoch 54 =========\n",
            "Train loss : 0.540612, Test loss : 0.452110, Validation loss : 0.523300\n",
            "\n",
            "======== Epoch 55 =========\n",
            "Train loss : 0.536493, Test loss : 0.447943, Validation loss : 0.518856\n",
            "\n",
            "======== Epoch 56 =========\n",
            "Train loss : 0.532478, Test loss : 0.444030, Validation loss : 0.514493\n",
            "\n",
            "======== Epoch 57 =========\n",
            "Train loss : 0.528564, Test loss : 0.440070, Validation loss : 0.510305\n",
            "\n",
            "======== Epoch 58 =========\n",
            "Train loss : 0.524725, Test loss : 0.436361, Validation loss : 0.506124\n",
            "\n",
            "======== Epoch 59 =========\n",
            "Train loss : 0.520996, Test loss : 0.432609, Validation loss : 0.502121\n",
            "\n",
            "======== Epoch 60 =========\n",
            "Train loss : 0.517332, Test loss : 0.429044, Validation loss : 0.498175\n",
            "\n",
            "======== Epoch 61 =========\n",
            "Train loss : 0.513761, Test loss : 0.425587, Validation loss : 0.494297\n",
            "\n",
            "======== Epoch 62 =========\n",
            "Train loss : 0.510271, Test loss : 0.422120, Validation loss : 0.490573\n",
            "\n",
            "======== Epoch 63 =========\n",
            "Train loss : 0.506850, Test loss : 0.418855, Validation loss : 0.486849\n",
            "\n",
            "======== Epoch 64 =========\n",
            "Train loss : 0.503509, Test loss : 0.415560, Validation loss : 0.483278\n",
            "\n",
            "======== Epoch 65 =========\n",
            "Train loss : 0.500232, Test loss : 0.412442, Validation loss : 0.479706\n",
            "\n",
            "======== Epoch 66 =========\n",
            "Train loss : 0.497025, Test loss : 0.409327, Validation loss : 0.476281\n",
            "\n",
            "======== Epoch 67 =========\n",
            "Train loss : 0.493885, Test loss : 0.406375, Validation loss : 0.472814\n",
            "\n",
            "======== Epoch 68 =========\n",
            "Train loss : 0.490807, Test loss : 0.403382, Validation loss : 0.469543\n",
            "\n",
            "======== Epoch 69 =========\n",
            "Train loss : 0.487784, Test loss : 0.400515, Validation loss : 0.466264\n",
            "\n",
            "======== Epoch 70 =========\n",
            "Train loss : 0.484822, Test loss : 0.397667, Validation loss : 0.463098\n",
            "\n",
            "======== Epoch 71 =========\n",
            "Train loss : 0.481914, Test loss : 0.394922, Validation loss : 0.459953\n",
            "\n",
            "======== Epoch 72 =========\n",
            "Train loss : 0.479062, Test loss : 0.392286, Validation loss : 0.456805\n",
            "\n",
            "======== Epoch 73 =========\n",
            "Train loss : 0.476260, Test loss : 0.389623, Validation loss : 0.453794\n",
            "\n",
            "======== Epoch 74 =========\n",
            "Train loss : 0.473505, Test loss : 0.387045, Validation loss : 0.450808\n",
            "\n",
            "======== Epoch 75 =========\n",
            "Train loss : 0.470799, Test loss : 0.384495, Validation loss : 0.447896\n",
            "\n",
            "======== Epoch 76 =========\n",
            "Train loss : 0.468136, Test loss : 0.381992, Validation loss : 0.445045\n",
            "\n",
            "======== Epoch 77 =========\n",
            "Train loss : 0.465516, Test loss : 0.379564, Validation loss : 0.442212\n",
            "\n",
            "======== Epoch 78 =========\n",
            "Train loss : 0.462940, Test loss : 0.377189, Validation loss : 0.439407\n",
            "\n",
            "======== Epoch 79 =========\n",
            "Train loss : 0.460404, Test loss : 0.374846, Validation loss : 0.436654\n",
            "\n",
            "======== Epoch 80 =========\n",
            "Train loss : 0.457907, Test loss : 0.372538, Validation loss : 0.433961\n",
            "\n",
            "======== Epoch 81 =========\n",
            "Train loss : 0.455446, Test loss : 0.370277, Validation loss : 0.431297\n",
            "\n",
            "======== Epoch 82 =========\n",
            "Train loss : 0.453023, Test loss : 0.368033, Validation loss : 0.428701\n",
            "\n",
            "======== Epoch 83 =========\n",
            "Train loss : 0.450634, Test loss : 0.365874, Validation loss : 0.426085\n",
            "\n",
            "======== Epoch 84 =========\n",
            "Train loss : 0.448279, Test loss : 0.363694, Validation loss : 0.423570\n",
            "\n",
            "======== Epoch 85 =========\n",
            "Train loss : 0.445956, Test loss : 0.361563, Validation loss : 0.421087\n",
            "\n",
            "======== Epoch 86 =========\n",
            "Train loss : 0.443667, Test loss : 0.359500, Validation loss : 0.418595\n",
            "\n",
            "======== Epoch 87 =========\n",
            "Train loss : 0.441408, Test loss : 0.357430, Validation loss : 0.416181\n",
            "\n",
            "======== Epoch 88 =========\n",
            "Train loss : 0.439177, Test loss : 0.355406, Validation loss : 0.413780\n",
            "\n",
            "======== Epoch 89 =========\n",
            "Train loss : 0.436975, Test loss : 0.353433, Validation loss : 0.411381\n",
            "\n",
            "======== Epoch 90 =========\n",
            "Train loss : 0.434799, Test loss : 0.351458, Validation loss : 0.409054\n",
            "\n",
            "======== Epoch 91 =========\n",
            "Train loss : 0.432649, Test loss : 0.349532, Validation loss : 0.406729\n",
            "\n",
            "======== Epoch 92 =========\n",
            "Train loss : 0.430525, Test loss : 0.347616, Validation loss : 0.404453\n",
            "\n",
            "======== Epoch 93 =========\n",
            "Train loss : 0.428426, Test loss : 0.345743, Validation loss : 0.402183\n",
            "\n",
            "======== Epoch 94 =========\n",
            "Train loss : 0.426353, Test loss : 0.343866, Validation loss : 0.399980\n",
            "\n",
            "======== Epoch 95 =========\n",
            "Train loss : 0.424307, Test loss : 0.342040, Validation loss : 0.397770\n",
            "\n",
            "======== Epoch 96 =========\n",
            "Train loss : 0.422282, Test loss : 0.340218, Validation loss : 0.395614\n",
            "\n",
            "======== Epoch 97 =========\n",
            "Train loss : 0.420282, Test loss : 0.338434, Validation loss : 0.393466\n",
            "\n",
            "======== Epoch 98 =========\n",
            "Train loss : 0.418304, Test loss : 0.336675, Validation loss : 0.391344\n",
            "\n",
            "======== Epoch 99 =========\n",
            "Train loss : 0.416344, Test loss : 0.334956, Validation loss : 0.389218\n",
            "\n",
            "======== Epoch 100 =========\n",
            "Train loss : 0.414405, Test loss : 0.333229, Validation loss : 0.387150\n",
            "\n",
            "======== Epoch 101 =========\n",
            "Train loss : 0.412485, Test loss : 0.331525, Validation loss : 0.385092\n",
            "\n",
            "======== Epoch 102 =========\n",
            "Train loss : 0.410584, Test loss : 0.329853, Validation loss : 0.383051\n",
            "\n",
            "======== Epoch 103 =========\n",
            "Train loss : 0.408701, Test loss : 0.328186, Validation loss : 0.381029\n",
            "\n",
            "======== Epoch 104 =========\n",
            "Train loss : 0.406835, Test loss : 0.326556, Validation loss : 0.379013\n",
            "\n",
            "======== Epoch 105 =========\n",
            "Train loss : 0.404985, Test loss : 0.324932, Validation loss : 0.377031\n",
            "\n",
            "======== Epoch 106 =========\n",
            "Train loss : 0.403153, Test loss : 0.323304, Validation loss : 0.375090\n",
            "\n",
            "======== Epoch 107 =========\n",
            "Train loss : 0.401334, Test loss : 0.321708, Validation loss : 0.373150\n",
            "\n",
            "======== Epoch 108 =========\n",
            "Train loss : 0.399533, Test loss : 0.320147, Validation loss : 0.371211\n",
            "\n",
            "======== Epoch 109 =========\n",
            "Train loss : 0.397748, Test loss : 0.318597, Validation loss : 0.369279\n",
            "\n",
            "======== Epoch 110 =========\n",
            "Train loss : 0.395977, Test loss : 0.317062, Validation loss : 0.367368\n",
            "\n",
            "======== Epoch 111 =========\n",
            "Train loss : 0.394220, Test loss : 0.315518, Validation loss : 0.365504\n",
            "\n",
            "======== Epoch 112 =========\n",
            "Train loss : 0.392478, Test loss : 0.314007, Validation loss : 0.363637\n",
            "\n",
            "======== Epoch 113 =========\n",
            "Train loss : 0.390749, Test loss : 0.312511, Validation loss : 0.361796\n",
            "\n",
            "======== Epoch 114 =========\n",
            "Train loss : 0.389034, Test loss : 0.311025, Validation loss : 0.359958\n",
            "\n",
            "======== Epoch 115 =========\n",
            "Train loss : 0.387332, Test loss : 0.309554, Validation loss : 0.358137\n",
            "\n",
            "======== Epoch 116 =========\n",
            "Train loss : 0.385642, Test loss : 0.308123, Validation loss : 0.356298\n",
            "\n",
            "======== Epoch 117 =========\n",
            "Train loss : 0.383965, Test loss : 0.306659, Validation loss : 0.354526\n",
            "\n",
            "======== Epoch 118 =========\n",
            "Train loss : 0.382299, Test loss : 0.305229, Validation loss : 0.352744\n",
            "\n",
            "======== Epoch 119 =========\n",
            "Train loss : 0.380646, Test loss : 0.303809, Validation loss : 0.350977\n",
            "\n",
            "======== Epoch 120 =========\n",
            "Train loss : 0.379003, Test loss : 0.302397, Validation loss : 0.349229\n",
            "\n",
            "======== Epoch 121 =========\n",
            "Train loss : 0.377371, Test loss : 0.301013, Validation loss : 0.347471\n",
            "\n",
            "======== Epoch 122 =========\n",
            "Train loss : 0.375751, Test loss : 0.299651, Validation loss : 0.345714\n",
            "\n",
            "======== Epoch 123 =========\n",
            "Train loss : 0.374141, Test loss : 0.298246, Validation loss : 0.344036\n",
            "\n",
            "======== Epoch 124 =========\n",
            "Train loss : 0.372541, Test loss : 0.296890, Validation loss : 0.342321\n",
            "\n",
            "======== Epoch 125 =========\n",
            "Train loss : 0.370953, Test loss : 0.295504, Validation loss : 0.340668\n",
            "\n",
            "======== Epoch 126 =========\n",
            "Train loss : 0.369375, Test loss : 0.294180, Validation loss : 0.338964\n",
            "\n",
            "======== Epoch 127 =========\n",
            "Train loss : 0.367808, Test loss : 0.292854, Validation loss : 0.337288\n",
            "\n",
            "======== Epoch 128 =========\n",
            "Train loss : 0.366250, Test loss : 0.291546, Validation loss : 0.335613\n",
            "\n",
            "======== Epoch 129 =========\n",
            "Train loss : 0.364701, Test loss : 0.290217, Validation loss : 0.333984\n",
            "\n",
            "======== Epoch 130 =========\n",
            "Train loss : 0.363162, Test loss : 0.288924, Validation loss : 0.332332\n",
            "\n",
            "======== Epoch 131 =========\n",
            "Train loss : 0.361631, Test loss : 0.287634, Validation loss : 0.330701\n",
            "\n",
            "======== Epoch 132 =========\n",
            "Train loss : 0.360109, Test loss : 0.286343, Validation loss : 0.329094\n",
            "\n",
            "======== Epoch 133 =========\n",
            "Train loss : 0.358596, Test loss : 0.285072, Validation loss : 0.327480\n",
            "\n",
            "======== Epoch 134 =========\n",
            "Train loss : 0.357091, Test loss : 0.283830, Validation loss : 0.325859\n",
            "\n",
            "======== Epoch 135 =========\n",
            "Train loss : 0.355595, Test loss : 0.282568, Validation loss : 0.324280\n",
            "\n",
            "======== Epoch 136 =========\n",
            "Train loss : 0.354108, Test loss : 0.281318, Validation loss : 0.322704\n",
            "\n",
            "======== Epoch 137 =========\n",
            "Train loss : 0.352628, Test loss : 0.280079, Validation loss : 0.321139\n",
            "\n",
            "======== Epoch 138 =========\n",
            "Train loss : 0.351156, Test loss : 0.278852, Validation loss : 0.319576\n",
            "\n",
            "======== Epoch 139 =========\n",
            "Train loss : 0.349693, Test loss : 0.277603, Validation loss : 0.318049\n",
            "\n",
            "======== Epoch 140 =========\n",
            "Train loss : 0.348237, Test loss : 0.276415, Validation loss : 0.316481\n",
            "\n",
            "======== Epoch 141 =========\n",
            "Train loss : 0.346791, Test loss : 0.275215, Validation loss : 0.314942\n",
            "\n",
            "======== Epoch 142 =========\n",
            "Train loss : 0.345350, Test loss : 0.273980, Validation loss : 0.313452\n",
            "\n",
            "======== Epoch 143 =========\n",
            "Train loss : 0.343919, Test loss : 0.272800, Validation loss : 0.311920\n",
            "\n",
            "======== Epoch 144 =========\n",
            "Train loss : 0.342493, Test loss : 0.271640, Validation loss : 0.310390\n",
            "\n",
            "======== Epoch 145 =========\n",
            "Train loss : 0.341076, Test loss : 0.270440, Validation loss : 0.308923\n",
            "\n",
            "======== Epoch 146 =========\n",
            "Train loss : 0.339666, Test loss : 0.269265, Validation loss : 0.307429\n",
            "\n",
            "======== Epoch 147 =========\n",
            "Train loss : 0.338265, Test loss : 0.268099, Validation loss : 0.305959\n",
            "\n",
            "======== Epoch 148 =========\n",
            "Train loss : 0.336871, Test loss : 0.266977, Validation loss : 0.304455\n",
            "\n",
            "======== Epoch 149 =========\n",
            "Train loss : 0.335485, Test loss : 0.265801, Validation loss : 0.303020\n",
            "\n",
            "======== Epoch 150 =========\n",
            "Train loss : 0.334105, Test loss : 0.264662, Validation loss : 0.301560\n",
            "\n",
            "======== Epoch 151 =========\n",
            "Train loss : 0.332733, Test loss : 0.263536, Validation loss : 0.300103\n",
            "\n",
            "======== Epoch 152 =========\n",
            "Train loss : 0.331368, Test loss : 0.262430, Validation loss : 0.298647\n",
            "\n",
            "======== Epoch 153 =========\n",
            "Train loss : 0.330011, Test loss : 0.261306, Validation loss : 0.297217\n",
            "\n",
            "======== Epoch 154 =========\n",
            "Train loss : 0.328660, Test loss : 0.260171, Validation loss : 0.295821\n",
            "\n",
            "======== Epoch 155 =========\n",
            "Train loss : 0.327316, Test loss : 0.259096, Validation loss : 0.294378\n",
            "\n",
            "======== Epoch 156 =========\n",
            "Train loss : 0.325979, Test loss : 0.257970, Validation loss : 0.292993\n",
            "\n",
            "======== Epoch 157 =========\n",
            "Train loss : 0.324649, Test loss : 0.256909, Validation loss : 0.291567\n",
            "\n",
            "======== Epoch 158 =========\n",
            "Train loss : 0.323326, Test loss : 0.255837, Validation loss : 0.290166\n",
            "\n",
            "======== Epoch 159 =========\n",
            "Train loss : 0.322010, Test loss : 0.254744, Validation loss : 0.288790\n",
            "\n",
            "======== Epoch 160 =========\n",
            "Train loss : 0.320700, Test loss : 0.253684, Validation loss : 0.287408\n",
            "\n",
            "======== Epoch 161 =========\n",
            "Train loss : 0.319397, Test loss : 0.252607, Validation loss : 0.286054\n",
            "\n",
            "======== Epoch 162 =========\n",
            "Train loss : 0.318100, Test loss : 0.251561, Validation loss : 0.284679\n",
            "\n",
            "======== Epoch 163 =========\n",
            "Train loss : 0.316811, Test loss : 0.250512, Validation loss : 0.283320\n",
            "\n",
            "======== Epoch 164 =========\n",
            "Train loss : 0.315527, Test loss : 0.249454, Validation loss : 0.281996\n",
            "\n",
            "======== Epoch 165 =========\n",
            "Train loss : 0.314250, Test loss : 0.248430, Validation loss : 0.280632\n",
            "\n",
            "======== Epoch 166 =========\n",
            "Train loss : 0.312981, Test loss : 0.247449, Validation loss : 0.279247\n",
            "\n",
            "======== Epoch 167 =========\n",
            "Train loss : 0.311717, Test loss : 0.246361, Validation loss : 0.277990\n",
            "\n",
            "======== Epoch 168 =========\n",
            "Train loss : 0.310460, Test loss : 0.245374, Validation loss : 0.276634\n",
            "\n",
            "======== Epoch 169 =========\n",
            "Train loss : 0.309210, Test loss : 0.244362, Validation loss : 0.275321\n",
            "\n",
            "======== Epoch 170 =========\n",
            "Train loss : 0.307966, Test loss : 0.243351, Validation loss : 0.274027\n",
            "\n",
            "======== Epoch 171 =========\n",
            "Train loss : 0.306728, Test loss : 0.242363, Validation loss : 0.272713\n",
            "\n",
            "======== Epoch 172 =========\n",
            "Train loss : 0.305497, Test loss : 0.241361, Validation loss : 0.271431\n",
            "\n",
            "======== Epoch 173 =========\n",
            "Train loss : 0.304272, Test loss : 0.240376, Validation loss : 0.270150\n",
            "\n",
            "======== Epoch 174 =========\n",
            "Train loss : 0.303055, Test loss : 0.239379, Validation loss : 0.268882\n",
            "\n",
            "======== Epoch 175 =========\n",
            "Train loss : 0.301843, Test loss : 0.238417, Validation loss : 0.267605\n",
            "\n",
            "======== Epoch 176 =========\n",
            "Train loss : 0.300637, Test loss : 0.237441, Validation loss : 0.266351\n",
            "\n",
            "======== Epoch 177 =========\n",
            "Train loss : 0.299438, Test loss : 0.236489, Validation loss : 0.265082\n",
            "\n",
            "======== Epoch 178 =========\n",
            "Train loss : 0.298245, Test loss : 0.235515, Validation loss : 0.263851\n",
            "\n",
            "======== Epoch 179 =========\n",
            "Train loss : 0.297057, Test loss : 0.234619, Validation loss : 0.262555\n",
            "\n",
            "======== Epoch 180 =========\n",
            "Train loss : 0.295876, Test loss : 0.233592, Validation loss : 0.261402\n",
            "\n",
            "======== Epoch 181 =========\n",
            "Train loss : 0.294702, Test loss : 0.232730, Validation loss : 0.260096\n",
            "\n",
            "======== Epoch 182 =========\n",
            "Train loss : 0.293533, Test loss : 0.231742, Validation loss : 0.258937\n",
            "\n",
            "======== Epoch 183 =========\n",
            "Train loss : 0.292371, Test loss : 0.230854, Validation loss : 0.257689\n",
            "\n",
            "======== Epoch 184 =========\n",
            "Train loss : 0.291216, Test loss : 0.229919, Validation loss : 0.256490\n",
            "\n",
            "======== Epoch 185 =========\n",
            "Train loss : 0.290065, Test loss : 0.229024, Validation loss : 0.255271\n",
            "\n",
            "======== Epoch 186 =========\n",
            "Train loss : 0.288922, Test loss : 0.228125, Validation loss : 0.254065\n",
            "\n",
            "======== Epoch 187 =========\n",
            "Train loss : 0.287785, Test loss : 0.227181, Validation loss : 0.252921\n",
            "\n",
            "======== Epoch 188 =========\n",
            "Train loss : 0.286654, Test loss : 0.226325, Validation loss : 0.251697\n",
            "\n",
            "======== Epoch 189 =========\n",
            "Train loss : 0.285529, Test loss : 0.225438, Validation loss : 0.250517\n",
            "\n",
            "======== Epoch 190 =========\n",
            "Train loss : 0.284409, Test loss : 0.224535, Validation loss : 0.249368\n",
            "\n",
            "======== Epoch 191 =========\n",
            "Train loss : 0.283296, Test loss : 0.223660, Validation loss : 0.248199\n",
            "\n",
            "======== Epoch 192 =========\n",
            "Train loss : 0.282189, Test loss : 0.222762, Validation loss : 0.247070\n",
            "\n",
            "======== Epoch 193 =========\n",
            "Train loss : 0.281088, Test loss : 0.221965, Validation loss : 0.245845\n",
            "\n",
            "======== Epoch 194 =========\n",
            "Train loss : 0.279993, Test loss : 0.221016, Validation loss : 0.244794\n",
            "\n",
            "======== Epoch 195 =========\n",
            "Train loss : 0.278904, Test loss : 0.220223, Validation loss : 0.243588\n",
            "\n",
            "======== Epoch 196 =========\n",
            "Train loss : 0.277820, Test loss : 0.219338, Validation loss : 0.242493\n",
            "\n",
            "======== Epoch 197 =========\n",
            "Train loss : 0.276743, Test loss : 0.218483, Validation loss : 0.241383\n",
            "\n",
            "======== Epoch 198 =========\n",
            "Train loss : 0.275672, Test loss : 0.217681, Validation loss : 0.240222\n",
            "\n",
            "======== Epoch 199 =========\n",
            "Train loss : 0.274607, Test loss : 0.216814, Validation loss : 0.239148\n",
            "\n",
            "======== Epoch 200 =========\n",
            "Train loss : 0.273547, Test loss : 0.215976, Validation loss : 0.238046\n",
            "\n",
            "======== Epoch 201 =========\n",
            "Train loss : 0.272494, Test loss : 0.215200, Validation loss : 0.236901\n",
            "\n",
            "======== Epoch 202 =========\n",
            "Train loss : 0.271446, Test loss : 0.214315, Validation loss : 0.235880\n",
            "\n",
            "======== Epoch 203 =========\n",
            "Train loss : 0.270405, Test loss : 0.213559, Validation loss : 0.234735\n",
            "\n",
            "======== Epoch 204 =========\n",
            "Train loss : 0.269368, Test loss : 0.212697, Validation loss : 0.233714\n",
            "\n",
            "======== Epoch 205 =========\n",
            "Train loss : 0.268339, Test loss : 0.211953, Validation loss : 0.232576\n",
            "\n",
            "======== Epoch 206 =========\n",
            "Train loss : 0.267314, Test loss : 0.211111, Validation loss : 0.231556\n",
            "\n",
            "======== Epoch 207 =========\n",
            "Train loss : 0.266295, Test loss : 0.210314, Validation loss : 0.230495\n",
            "\n",
            "======== Epoch 208 =========\n",
            "Train loss : 0.265282, Test loss : 0.209524, Validation loss : 0.229447\n",
            "\n",
            "======== Epoch 209 =========\n",
            "Train loss : 0.264275, Test loss : 0.208764, Validation loss : 0.228376\n",
            "\n",
            "======== Epoch 210 =========\n",
            "Train loss : 0.263274, Test loss : 0.207961, Validation loss : 0.227363\n",
            "\n",
            "======== Epoch 211 =========\n",
            "Train loss : 0.262277, Test loss : 0.207192, Validation loss : 0.226328\n",
            "\n",
            "======== Epoch 212 =========\n",
            "Train loss : 0.261288, Test loss : 0.206433, Validation loss : 0.225286\n",
            "\n",
            "======== Epoch 213 =========\n",
            "Train loss : 0.260303, Test loss : 0.205677, Validation loss : 0.224258\n",
            "\n",
            "======== Epoch 214 =========\n",
            "Train loss : 0.259324, Test loss : 0.204888, Validation loss : 0.223273\n",
            "\n",
            "======== Epoch 215 =========\n",
            "Train loss : 0.258350, Test loss : 0.204161, Validation loss : 0.222239\n",
            "\n",
            "======== Epoch 216 =========\n",
            "Train loss : 0.257382, Test loss : 0.203398, Validation loss : 0.221252\n",
            "\n",
            "======== Epoch 217 =========\n",
            "Train loss : 0.256420, Test loss : 0.202665, Validation loss : 0.220242\n",
            "\n",
            "======== Epoch 218 =========\n",
            "Train loss : 0.255463, Test loss : 0.201946, Validation loss : 0.219231\n",
            "\n",
            "======== Epoch 219 =========\n",
            "Train loss : 0.254511, Test loss : 0.201150, Validation loss : 0.218304\n",
            "\n",
            "======== Epoch 220 =========\n",
            "Train loss : 0.253565, Test loss : 0.200498, Validation loss : 0.217248\n",
            "\n",
            "======== Epoch 221 =========\n",
            "Train loss : 0.252625, Test loss : 0.199672, Validation loss : 0.216374\n",
            "\n",
            "======== Epoch 222 =========\n",
            "Train loss : 0.251691, Test loss : 0.199027, Validation loss : 0.215333\n",
            "\n",
            "======== Epoch 223 =========\n",
            "Train loss : 0.250762, Test loss : 0.198229, Validation loss : 0.214455\n",
            "\n",
            "======== Epoch 224 =========\n",
            "Train loss : 0.249839, Test loss : 0.197614, Validation loss : 0.213410\n",
            "\n",
            "======== Epoch 225 =========\n",
            "Train loss : 0.248921, Test loss : 0.196825, Validation loss : 0.212537\n",
            "\n",
            "======== Epoch 226 =========\n",
            "Train loss : 0.248009, Test loss : 0.196188, Validation loss : 0.211535\n",
            "\n",
            "======== Epoch 227 =========\n",
            "Train loss : 0.247102, Test loss : 0.195416, Validation loss : 0.210672\n",
            "\n",
            "======== Epoch 228 =========\n",
            "Train loss : 0.246201, Test loss : 0.194812, Validation loss : 0.209656\n",
            "\n",
            "======== Epoch 229 =========\n",
            "Train loss : 0.245305, Test loss : 0.194053, Validation loss : 0.208797\n",
            "\n",
            "======== Epoch 230 =========\n",
            "Train loss : 0.244414, Test loss : 0.193415, Validation loss : 0.207836\n",
            "\n",
            "======== Epoch 231 =========\n",
            "Train loss : 0.243529, Test loss : 0.192686, Validation loss : 0.206970\n",
            "\n",
            "======== Epoch 232 =========\n",
            "Train loss : 0.242649, Test loss : 0.192073, Validation loss : 0.206006\n",
            "\n",
            "======== Epoch 233 =========\n",
            "Train loss : 0.241775, Test loss : 0.191321, Validation loss : 0.205185\n",
            "\n",
            "======== Epoch 234 =========\n",
            "Train loss : 0.240905, Test loss : 0.190743, Validation loss : 0.204206\n",
            "\n",
            "======== Epoch 235 =========\n",
            "Train loss : 0.240041, Test loss : 0.190030, Validation loss : 0.203366\n",
            "\n",
            "======== Epoch 236 =========\n",
            "Train loss : 0.239182, Test loss : 0.189389, Validation loss : 0.202471\n",
            "\n",
            "======== Epoch 237 =========\n",
            "Train loss : 0.238329, Test loss : 0.188734, Validation loss : 0.201594\n",
            "\n",
            "======== Epoch 238 =========\n",
            "Train loss : 0.237481, Test loss : 0.188101, Validation loss : 0.200710\n",
            "\n",
            "======== Epoch 239 =========\n",
            "Train loss : 0.236638, Test loss : 0.187428, Validation loss : 0.199872\n",
            "\n",
            "======== Epoch 240 =========\n",
            "Train loss : 0.235800, Test loss : 0.186833, Validation loss : 0.198971\n",
            "\n",
            "======== Epoch 241 =========\n",
            "Train loss : 0.234967, Test loss : 0.186180, Validation loss : 0.198127\n",
            "\n",
            "======== Epoch 242 =========\n",
            "Train loss : 0.234139, Test loss : 0.185521, Validation loss : 0.197305\n",
            "\n",
            "======== Epoch 243 =========\n",
            "Train loss : 0.233317, Test loss : 0.184939, Validation loss : 0.196421\n",
            "\n",
            "======== Epoch 244 =========\n",
            "Train loss : 0.232499, Test loss : 0.184292, Validation loss : 0.195603\n",
            "\n",
            "======== Epoch 245 =========\n",
            "Train loss : 0.231686, Test loss : 0.183663, Validation loss : 0.194781\n",
            "\n",
            "======== Epoch 246 =========\n",
            "Train loss : 0.230878, Test loss : 0.183063, Validation loss : 0.193942\n",
            "\n",
            "======== Epoch 247 =========\n",
            "Train loss : 0.230076, Test loss : 0.182467, Validation loss : 0.193108\n",
            "\n",
            "======== Epoch 248 =========\n",
            "Train loss : 0.229278, Test loss : 0.181865, Validation loss : 0.192285\n",
            "\n",
            "======== Epoch 249 =========\n",
            "Train loss : 0.228485, Test loss : 0.181238, Validation loss : 0.191496\n",
            "\n",
            "======== Epoch 250 =========\n",
            "Train loss : 0.227697, Test loss : 0.180657, Validation loss : 0.190677\n",
            "\n",
            "======== Epoch 251 =========\n",
            "Train loss : 0.226914, Test loss : 0.180067, Validation loss : 0.189871\n",
            "\n",
            "======== Epoch 252 =========\n",
            "Train loss : 0.226136, Test loss : 0.179504, Validation loss : 0.189052\n",
            "\n",
            "======== Epoch 253 =========\n",
            "Train loss : 0.225363, Test loss : 0.178869, Validation loss : 0.188301\n",
            "\n",
            "======== Epoch 254 =========\n",
            "Train loss : 0.224594, Test loss : 0.178319, Validation loss : 0.187490\n",
            "\n",
            "======== Epoch 255 =========\n",
            "Train loss : 0.223831, Test loss : 0.177724, Validation loss : 0.186725\n",
            "\n",
            "======== Epoch 256 =========\n",
            "Train loss : 0.223072, Test loss : 0.177174, Validation loss : 0.185931\n",
            "\n",
            "======== Epoch 257 =========\n",
            "Train loss : 0.222318, Test loss : 0.176591, Validation loss : 0.185170\n",
            "\n",
            "======== Epoch 258 =========\n",
            "Train loss : 0.221569, Test loss : 0.176062, Validation loss : 0.184374\n",
            "\n",
            "======== Epoch 259 =========\n",
            "Train loss : 0.220824, Test loss : 0.175452, Validation loss : 0.183655\n",
            "\n",
            "======== Epoch 260 =========\n",
            "Train loss : 0.220085, Test loss : 0.174941, Validation loss : 0.182860\n",
            "\n",
            "======== Epoch 261 =========\n",
            "Train loss : 0.219349, Test loss : 0.174354, Validation loss : 0.182137\n",
            "\n",
            "======== Epoch 262 =========\n",
            "Train loss : 0.218619, Test loss : 0.173837, Validation loss : 0.181361\n",
            "\n",
            "======== Epoch 263 =========\n",
            "Train loss : 0.217893, Test loss : 0.173257, Validation loss : 0.180648\n",
            "\n",
            "======== Epoch 264 =========\n",
            "Train loss : 0.217171, Test loss : 0.172739, Validation loss : 0.179892\n",
            "\n",
            "======== Epoch 265 =========\n",
            "Train loss : 0.216455, Test loss : 0.172184, Validation loss : 0.179175\n",
            "\n",
            "======== Epoch 266 =========\n",
            "Train loss : 0.215743, Test loss : 0.171675, Validation loss : 0.178427\n",
            "\n",
            "======== Epoch 267 =========\n",
            "Train loss : 0.215036, Test loss : 0.171123, Validation loss : 0.177724\n",
            "\n",
            "======== Epoch 268 =========\n",
            "Train loss : 0.214333, Test loss : 0.170619, Validation loss : 0.176988\n",
            "\n",
            "======== Epoch 269 =========\n",
            "Train loss : 0.213634, Test loss : 0.170075, Validation loss : 0.176293\n",
            "\n",
            "======== Epoch 270 =========\n",
            "Train loss : 0.212940, Test loss : 0.169572, Validation loss : 0.175572\n",
            "\n",
            "======== Epoch 271 =========\n",
            "Train loss : 0.212251, Test loss : 0.169045, Validation loss : 0.174877\n",
            "\n",
            "======== Epoch 272 =========\n",
            "Train loss : 0.211566, Test loss : 0.168534, Validation loss : 0.174179\n",
            "\n",
            "======== Epoch 273 =========\n",
            "Train loss : 0.210886, Test loss : 0.168031, Validation loss : 0.173482\n",
            "\n",
            "======== Epoch 274 =========\n",
            "Train loss : 0.210210, Test loss : 0.167527, Validation loss : 0.172793\n",
            "\n",
            "======== Epoch 275 =========\n",
            "Train loss : 0.209538, Test loss : 0.167016, Validation loss : 0.172116\n",
            "\n",
            "======== Epoch 276 =========\n",
            "Train loss : 0.208871, Test loss : 0.166526, Validation loss : 0.171431\n",
            "\n",
            "======== Epoch 277 =========\n",
            "Train loss : 0.208208, Test loss : 0.166045, Validation loss : 0.170744\n",
            "\n",
            "======== Epoch 278 =========\n",
            "Train loss : 0.207549, Test loss : 0.165526, Validation loss : 0.170093\n",
            "\n",
            "======== Epoch 279 =========\n",
            "Train loss : 0.206893, Test loss : 0.165069, Validation loss : 0.169402\n",
            "\n",
            "======== Epoch 280 =========\n",
            "Train loss : 0.206242, Test loss : 0.164553, Validation loss : 0.168764\n",
            "\n",
            "======== Epoch 281 =========\n",
            "Train loss : 0.205595, Test loss : 0.164100, Validation loss : 0.168084\n",
            "\n",
            "======== Epoch 282 =========\n",
            "Train loss : 0.204952, Test loss : 0.163596, Validation loss : 0.167451\n",
            "\n",
            "======== Epoch 283 =========\n",
            "Train loss : 0.204313, Test loss : 0.163151, Validation loss : 0.166779\n",
            "\n",
            "======== Epoch 284 =========\n",
            "Train loss : 0.203678, Test loss : 0.162652, Validation loss : 0.166156\n",
            "\n",
            "======== Epoch 285 =========\n",
            "Train loss : 0.203047, Test loss : 0.162216, Validation loss : 0.165491\n",
            "\n",
            "======== Epoch 286 =========\n",
            "Train loss : 0.202420, Test loss : 0.161723, Validation loss : 0.164875\n",
            "\n",
            "======== Epoch 287 =========\n",
            "Train loss : 0.201797, Test loss : 0.161290, Validation loss : 0.164222\n",
            "\n",
            "======== Epoch 288 =========\n",
            "Train loss : 0.201178, Test loss : 0.160813, Validation loss : 0.163607\n",
            "\n",
            "======== Epoch 289 =========\n",
            "Train loss : 0.200562, Test loss : 0.160374, Validation loss : 0.162970\n",
            "\n",
            "======== Epoch 290 =========\n",
            "Train loss : 0.199951, Test loss : 0.159916, Validation loss : 0.162353\n",
            "\n",
            "======== Epoch 291 =========\n",
            "Train loss : 0.199343, Test loss : 0.159460, Validation loss : 0.161743\n",
            "\n",
            "======== Epoch 292 =========\n",
            "Train loss : 0.198739, Test loss : 0.159030, Validation loss : 0.161118\n",
            "\n",
            "======== Epoch 293 =========\n",
            "Train loss : 0.198139, Test loss : 0.158571, Validation loss : 0.160520\n",
            "\n",
            "======== Epoch 294 =========\n",
            "Train loss : 0.197542, Test loss : 0.158167, Validation loss : 0.159886\n",
            "\n",
            "======== Epoch 295 =========\n",
            "Train loss : 0.196949, Test loss : 0.157685, Validation loss : 0.159318\n",
            "\n",
            "======== Epoch 296 =========\n",
            "Train loss : 0.196359, Test loss : 0.157299, Validation loss : 0.158682\n",
            "\n",
            "======== Epoch 297 =========\n",
            "Train loss : 0.195773, Test loss : 0.156826, Validation loss : 0.158117\n",
            "\n",
            "======== Epoch 298 =========\n",
            "Train loss : 0.195189, Test loss : 0.156429, Validation loss : 0.157503\n",
            "\n",
            "======== Epoch 299 =========\n",
            "Train loss : 0.194609, Test loss : 0.155991, Validation loss : 0.156921\n",
            "\n",
            "======== Epoch 300 =========\n",
            "Train loss : 0.194033, Test loss : 0.155569, Validation loss : 0.156337\n",
            "\n",
            "======== Epoch 301 =========\n",
            "Train loss : 0.193460, Test loss : 0.155140, Validation loss : 0.155763\n",
            "\n",
            "======== Epoch 302 =========\n",
            "Train loss : 0.192891, Test loss : 0.154728, Validation loss : 0.155183\n",
            "\n",
            "======== Epoch 303 =========\n",
            "Train loss : 0.192325, Test loss : 0.154311, Validation loss : 0.154613\n",
            "\n",
            "======== Epoch 304 =========\n",
            "Train loss : 0.191763, Test loss : 0.153916, Validation loss : 0.154029\n",
            "\n",
            "======== Epoch 305 =========\n",
            "Train loss : 0.191205, Test loss : 0.153480, Validation loss : 0.153483\n",
            "\n",
            "======== Epoch 306 =========\n",
            "Train loss : 0.190650, Test loss : 0.153093, Validation loss : 0.152909\n",
            "\n",
            "======== Epoch 307 =========\n",
            "Train loss : 0.190098, Test loss : 0.152668, Validation loss : 0.152365\n",
            "\n",
            "======== Epoch 308 =========\n",
            "Train loss : 0.189550, Test loss : 0.152283, Validation loss : 0.151800\n",
            "\n",
            "======== Epoch 309 =========\n",
            "Train loss : 0.189005, Test loss : 0.151873, Validation loss : 0.151255\n",
            "\n",
            "======== Epoch 310 =========\n",
            "Train loss : 0.188464, Test loss : 0.151503, Validation loss : 0.150688\n",
            "\n",
            "======== Epoch 311 =========\n",
            "Train loss : 0.187926, Test loss : 0.151084, Validation loss : 0.150160\n",
            "\n",
            "======== Epoch 312 =========\n",
            "Train loss : 0.187391, Test loss : 0.150701, Validation loss : 0.149614\n",
            "\n",
            "======== Epoch 313 =========\n",
            "Train loss : 0.186860, Test loss : 0.150292, Validation loss : 0.149091\n",
            "\n",
            "======== Epoch 314 =========\n",
            "Train loss : 0.186332, Test loss : 0.149924, Validation loss : 0.148545\n",
            "\n",
            "======== Epoch 315 =========\n",
            "Train loss : 0.185808, Test loss : 0.149552, Validation loss : 0.148006\n",
            "\n",
            "======== Epoch 316 =========\n",
            "Train loss : 0.185287, Test loss : 0.149150, Validation loss : 0.147493\n",
            "\n",
            "======== Epoch 317 =========\n",
            "Train loss : 0.184769, Test loss : 0.148786, Validation loss : 0.146961\n",
            "\n",
            "======== Epoch 318 =========\n",
            "Train loss : 0.184253, Test loss : 0.148391, Validation loss : 0.146453\n",
            "\n",
            "======== Epoch 319 =========\n",
            "Train loss : 0.183741, Test loss : 0.148036, Validation loss : 0.145924\n",
            "\n",
            "======== Epoch 320 =========\n",
            "Train loss : 0.183233, Test loss : 0.147666, Validation loss : 0.145408\n",
            "\n",
            "======== Epoch 321 =========\n",
            "Train loss : 0.182727, Test loss : 0.147281, Validation loss : 0.144910\n",
            "\n",
            "======== Epoch 322 =========\n",
            "Train loss : 0.182225, Test loss : 0.146928, Validation loss : 0.144396\n",
            "\n",
            "======== Epoch 323 =========\n",
            "Train loss : 0.181726, Test loss : 0.146555, Validation loss : 0.143899\n",
            "\n",
            "======== Epoch 324 =========\n",
            "Train loss : 0.181230, Test loss : 0.146196, Validation loss : 0.143399\n",
            "\n",
            "======== Epoch 325 =========\n",
            "Train loss : 0.180737, Test loss : 0.145853, Validation loss : 0.142892\n",
            "\n",
            "======== Epoch 326 =========\n",
            "Train loss : 0.180247, Test loss : 0.145503, Validation loss : 0.142394\n",
            "\n",
            "======== Epoch 327 =========\n",
            "Train loss : 0.179760, Test loss : 0.145124, Validation loss : 0.141920\n",
            "\n",
            "======== Epoch 328 =========\n",
            "Train loss : 0.179276, Test loss : 0.144792, Validation loss : 0.141421\n",
            "\n",
            "======== Epoch 329 =========\n",
            "Train loss : 0.178795, Test loss : 0.144425, Validation loss : 0.140949\n",
            "\n",
            "======== Epoch 330 =========\n",
            "Train loss : 0.178318, Test loss : 0.144105, Validation loss : 0.140454\n",
            "\n",
            "======== Epoch 331 =========\n",
            "Train loss : 0.177844, Test loss : 0.143753, Validation loss : 0.139980\n",
            "\n",
            "======== Epoch 332 =========\n",
            "Train loss : 0.177374, Test loss : 0.143411, Validation loss : 0.139507\n",
            "\n",
            "======== Epoch 333 =========\n",
            "Train loss : 0.176906, Test loss : 0.143059, Validation loss : 0.139044\n",
            "\n",
            "======== Epoch 334 =========\n",
            "Train loss : 0.176441, Test loss : 0.142742, Validation loss : 0.138563\n",
            "\n",
            "======== Epoch 335 =========\n",
            "Train loss : 0.175978, Test loss : 0.142393, Validation loss : 0.138108\n",
            "\n",
            "======== Epoch 336 =========\n",
            "Train loss : 0.175519, Test loss : 0.142092, Validation loss : 0.137627\n",
            "\n",
            "======== Epoch 337 =========\n",
            "Train loss : 0.175063, Test loss : 0.141718, Validation loss : 0.137196\n",
            "\n",
            "======== Epoch 338 =========\n",
            "Train loss : 0.174609, Test loss : 0.141436, Validation loss : 0.136713\n",
            "\n",
            "======== Epoch 339 =========\n",
            "Train loss : 0.174159, Test loss : 0.141077, Validation loss : 0.136282\n",
            "\n",
            "======== Epoch 340 =========\n",
            "Train loss : 0.173711, Test loss : 0.140787, Validation loss : 0.135813\n",
            "\n",
            "======== Epoch 341 =========\n",
            "Train loss : 0.173266, Test loss : 0.140435, Validation loss : 0.135385\n",
            "\n",
            "======== Epoch 342 =========\n",
            "Train loss : 0.172824, Test loss : 0.140166, Validation loss : 0.134910\n",
            "\n",
            "======== Epoch 343 =========\n",
            "Train loss : 0.172385, Test loss : 0.139794, Validation loss : 0.134503\n",
            "\n",
            "======== Epoch 344 =========\n",
            "Train loss : 0.171948, Test loss : 0.139512, Validation loss : 0.134046\n",
            "\n",
            "======== Epoch 345 =========\n",
            "Train loss : 0.171514, Test loss : 0.139195, Validation loss : 0.133614\n",
            "\n",
            "======== Epoch 346 =========\n",
            "Train loss : 0.171083, Test loss : 0.138885, Validation loss : 0.133183\n",
            "\n",
            "======== Epoch 347 =========\n",
            "Train loss : 0.170655, Test loss : 0.138586, Validation loss : 0.132748\n",
            "\n",
            "======== Epoch 348 =========\n",
            "Train loss : 0.170229, Test loss : 0.138268, Validation loss : 0.132330\n",
            "\n",
            "======== Epoch 349 =========\n",
            "Train loss : 0.169806, Test loss : 0.137985, Validation loss : 0.131895\n",
            "\n",
            "======== Epoch 350 =========\n",
            "Train loss : 0.169386, Test loss : 0.137655, Validation loss : 0.131492\n",
            "\n",
            "======== Epoch 351 =========\n",
            "Train loss : 0.168969, Test loss : 0.137387, Validation loss : 0.131057\n",
            "\n",
            "======== Epoch 352 =========\n",
            "Train loss : 0.168554, Test loss : 0.137083, Validation loss : 0.130645\n",
            "\n",
            "======== Epoch 353 =========\n",
            "Train loss : 0.168142, Test loss : 0.136785, Validation loss : 0.130235\n",
            "\n",
            "======== Epoch 354 =========\n",
            "Train loss : 0.167732, Test loss : 0.136496, Validation loss : 0.129824\n",
            "\n",
            "======== Epoch 355 =========\n",
            "Train loss : 0.167324, Test loss : 0.136199, Validation loss : 0.129422\n",
            "\n",
            "======== Epoch 356 =========\n",
            "Train loss : 0.166920, Test loss : 0.135918, Validation loss : 0.129014\n",
            "\n",
            "======== Epoch 357 =========\n",
            "Train loss : 0.166518, Test loss : 0.135633, Validation loss : 0.128612\n",
            "\n",
            "======== Epoch 358 =========\n",
            "Train loss : 0.166119, Test loss : 0.135372, Validation loss : 0.128198\n",
            "\n",
            "======== Epoch 359 =========\n",
            "Train loss : 0.165723, Test loss : 0.135052, Validation loss : 0.127822\n",
            "\n",
            "======== Epoch 360 =========\n",
            "Train loss : 0.165329, Test loss : 0.134795, Validation loss : 0.127415\n",
            "\n",
            "======== Epoch 361 =========\n",
            "Train loss : 0.164937, Test loss : 0.134505, Validation loss : 0.127031\n",
            "\n",
            "======== Epoch 362 =========\n",
            "Train loss : 0.164548, Test loss : 0.134235, Validation loss : 0.126637\n",
            "\n",
            "======== Epoch 363 =========\n",
            "Train loss : 0.164161, Test loss : 0.133976, Validation loss : 0.126241\n",
            "\n",
            "======== Epoch 364 =========\n",
            "Train loss : 0.163777, Test loss : 0.133663, Validation loss : 0.125879\n",
            "\n",
            "======== Epoch 365 =========\n",
            "Train loss : 0.163395, Test loss : 0.133412, Validation loss : 0.125486\n",
            "\n",
            "======== Epoch 366 =========\n",
            "Train loss : 0.163016, Test loss : 0.133144, Validation loss : 0.125106\n",
            "\n",
            "======== Epoch 367 =========\n",
            "Train loss : 0.162638, Test loss : 0.132870, Validation loss : 0.124732\n",
            "\n",
            "======== Epoch 368 =========\n",
            "Train loss : 0.162264, Test loss : 0.132624, Validation loss : 0.124346\n",
            "\n",
            "======== Epoch 369 =========\n",
            "Train loss : 0.161891, Test loss : 0.132331, Validation loss : 0.123988\n",
            "\n",
            "======== Epoch 370 =========\n",
            "Train loss : 0.161521, Test loss : 0.132090, Validation loss : 0.123608\n",
            "\n",
            "======== Epoch 371 =========\n",
            "Train loss : 0.161152, Test loss : 0.131820, Validation loss : 0.123245\n",
            "\n",
            "======== Epoch 372 =========\n",
            "Train loss : 0.160787, Test loss : 0.131563, Validation loss : 0.122879\n",
            "\n",
            "======== Epoch 373 =========\n",
            "Train loss : 0.160423, Test loss : 0.131327, Validation loss : 0.122504\n",
            "\n",
            "======== Epoch 374 =========\n",
            "Train loss : 0.160062, Test loss : 0.131027, Validation loss : 0.122166\n",
            "\n",
            "======== Epoch 375 =========\n",
            "Train loss : 0.159704, Test loss : 0.130813, Validation loss : 0.121787\n",
            "\n",
            "======== Epoch 376 =========\n",
            "Train loss : 0.159347, Test loss : 0.130526, Validation loss : 0.121450\n",
            "\n",
            "======== Epoch 377 =========\n",
            "Train loss : 0.158992, Test loss : 0.130298, Validation loss : 0.121084\n",
            "\n",
            "======== Epoch 378 =========\n",
            "Train loss : 0.158640, Test loss : 0.130055, Validation loss : 0.120728\n",
            "\n",
            "======== Epoch 379 =========\n",
            "Train loss : 0.158290, Test loss : 0.129791, Validation loss : 0.120388\n",
            "\n",
            "======== Epoch 380 =========\n",
            "Train loss : 0.157942, Test loss : 0.129553, Validation loss : 0.120037\n",
            "\n",
            "======== Epoch 381 =========\n",
            "Train loss : 0.157596, Test loss : 0.129299, Validation loss : 0.119695\n",
            "\n",
            "======== Epoch 382 =========\n",
            "Train loss : 0.157253, Test loss : 0.129082, Validation loss : 0.119339\n",
            "\n",
            "======== Epoch 383 =========\n",
            "Train loss : 0.156911, Test loss : 0.128812, Validation loss : 0.119013\n",
            "\n",
            "======== Epoch 384 =========\n",
            "Train loss : 0.156572, Test loss : 0.128611, Validation loss : 0.118654\n",
            "\n",
            "======== Epoch 385 =========\n",
            "Train loss : 0.156234, Test loss : 0.128334, Validation loss : 0.118336\n",
            "\n",
            "======== Epoch 386 =========\n",
            "Train loss : 0.155899, Test loss : 0.128116, Validation loss : 0.117992\n",
            "\n",
            "======== Epoch 387 =========\n",
            "Train loss : 0.155565, Test loss : 0.127877, Validation loss : 0.117662\n",
            "\n",
            "======== Epoch 388 =========\n",
            "Train loss : 0.155234, Test loss : 0.127652, Validation loss : 0.117327\n",
            "\n",
            "======== Epoch 389 =========\n",
            "Train loss : 0.154904, Test loss : 0.127424, Validation loss : 0.116994\n",
            "\n",
            "======== Epoch 390 =========\n",
            "Train loss : 0.154577, Test loss : 0.127182, Validation loss : 0.116674\n",
            "\n",
            "======== Epoch 391 =========\n",
            "Train loss : 0.154251, Test loss : 0.126960, Validation loss : 0.116346\n",
            "\n",
            "======== Epoch 392 =========\n",
            "Train loss : 0.153928, Test loss : 0.126728, Validation loss : 0.116026\n",
            "\n",
            "======== Epoch 393 =========\n",
            "Train loss : 0.153606, Test loss : 0.126508, Validation loss : 0.115702\n",
            "\n",
            "======== Epoch 394 =========\n",
            "Train loss : 0.153287, Test loss : 0.126295, Validation loss : 0.115376\n",
            "\n",
            "======== Epoch 395 =========\n",
            "Train loss : 0.152970, Test loss : 0.126050, Validation loss : 0.115070\n",
            "\n",
            "======== Epoch 396 =========\n",
            "Train loss : 0.152654, Test loss : 0.125841, Validation loss : 0.114748\n",
            "\n",
            "======== Epoch 397 =========\n",
            "Train loss : 0.152340, Test loss : 0.125620, Validation loss : 0.114436\n",
            "\n",
            "======== Epoch 398 =========\n",
            "Train loss : 0.152027, Test loss : 0.125400, Validation loss : 0.114125\n",
            "\n",
            "======== Epoch 399 =========\n",
            "Train loss : 0.151716, Test loss : 0.125195, Validation loss : 0.113808\n",
            "\n",
            "======== Epoch 400 =========\n",
            "Train loss : 0.151407, Test loss : 0.124962, Validation loss : 0.113508\n",
            "\n",
            "======== Epoch 401 =========\n",
            "Train loss : 0.151099, Test loss : 0.124755, Validation loss : 0.113199\n",
            "\n",
            "======== Epoch 402 =========\n",
            "Train loss : 0.150794, Test loss : 0.124533, Validation loss : 0.112898\n",
            "\n",
            "======== Epoch 403 =========\n",
            "Train loss : 0.150490, Test loss : 0.124336, Validation loss : 0.112589\n",
            "\n",
            "======== Epoch 404 =========\n",
            "Train loss : 0.150188, Test loss : 0.124120, Validation loss : 0.112290\n",
            "\n",
            "======== Epoch 405 =========\n",
            "Train loss : 0.149889, Test loss : 0.123893, Validation loss : 0.111999\n",
            "\n",
            "======== Epoch 406 =========\n",
            "Train loss : 0.149591, Test loss : 0.123705, Validation loss : 0.111694\n",
            "\n",
            "======== Epoch 407 =========\n",
            "Train loss : 0.149294, Test loss : 0.123473, Validation loss : 0.111409\n",
            "\n",
            "======== Epoch 408 =========\n",
            "Train loss : 0.149000, Test loss : 0.123288, Validation loss : 0.111107\n",
            "\n",
            "======== Epoch 409 =========\n",
            "Train loss : 0.148707, Test loss : 0.123083, Validation loss : 0.110814\n",
            "\n",
            "======== Epoch 410 =========\n",
            "Train loss : 0.148417, Test loss : 0.122866, Validation loss : 0.110531\n",
            "\n",
            "======== Epoch 411 =========\n",
            "Train loss : 0.148128, Test loss : 0.122679, Validation loss : 0.110237\n",
            "\n",
            "======== Epoch 412 =========\n",
            "Train loss : 0.147840, Test loss : 0.122457, Validation loss : 0.109959\n",
            "\n",
            "======== Epoch 413 =========\n",
            "Train loss : 0.147555, Test loss : 0.122273, Validation loss : 0.109668\n",
            "\n",
            "======== Epoch 414 =========\n",
            "Train loss : 0.147271, Test loss : 0.122081, Validation loss : 0.109381\n",
            "\n",
            "======== Epoch 415 =========\n",
            "Train loss : 0.146989, Test loss : 0.121868, Validation loss : 0.109108\n",
            "\n",
            "======== Epoch 416 =========\n",
            "Train loss : 0.146708, Test loss : 0.121674, Validation loss : 0.108827\n",
            "\n",
            "======== Epoch 417 =========\n",
            "Train loss : 0.146429, Test loss : 0.121481, Validation loss : 0.108548\n",
            "\n",
            "======== Epoch 418 =========\n",
            "Train loss : 0.146152, Test loss : 0.121280, Validation loss : 0.108275\n",
            "\n",
            "======== Epoch 419 =========\n",
            "Train loss : 0.145876, Test loss : 0.121095, Validation loss : 0.107998\n",
            "\n",
            "======== Epoch 420 =========\n",
            "Train loss : 0.145602, Test loss : 0.120905, Validation loss : 0.107723\n",
            "\n",
            "======== Epoch 421 =========\n",
            "Train loss : 0.145330, Test loss : 0.120707, Validation loss : 0.107456\n",
            "\n",
            "======== Epoch 422 =========\n",
            "Train loss : 0.145059, Test loss : 0.120518, Validation loss : 0.107186\n",
            "\n",
            "======== Epoch 423 =========\n",
            "Train loss : 0.144790, Test loss : 0.120325, Validation loss : 0.106920\n",
            "\n",
            "======== Epoch 424 =========\n",
            "Train loss : 0.144523, Test loss : 0.120141, Validation loss : 0.106652\n",
            "\n",
            "======== Epoch 425 =========\n",
            "Train loss : 0.144257, Test loss : 0.119971, Validation loss : 0.106379\n",
            "\n",
            "======== Epoch 426 =========\n",
            "Train loss : 0.143992, Test loss : 0.119755, Validation loss : 0.106128\n",
            "\n",
            "======== Epoch 427 =========\n",
            "Train loss : 0.143730, Test loss : 0.119597, Validation loss : 0.105855\n",
            "\n",
            "======== Epoch 428 =========\n",
            "Train loss : 0.143468, Test loss : 0.119398, Validation loss : 0.105601\n",
            "\n",
            "======== Epoch 429 =========\n",
            "Train loss : 0.143209, Test loss : 0.119225, Validation loss : 0.105339\n",
            "\n",
            "======== Epoch 430 =========\n",
            "Train loss : 0.142950, Test loss : 0.119050, Validation loss : 0.105077\n",
            "\n",
            "======== Epoch 431 =========\n",
            "Train loss : 0.142693, Test loss : 0.118845, Validation loss : 0.104832\n",
            "\n",
            "======== Epoch 432 =========\n",
            "Train loss : 0.142438, Test loss : 0.118678, Validation loss : 0.104573\n",
            "\n",
            "======== Epoch 433 =========\n",
            "Train loss : 0.142185, Test loss : 0.118496, Validation loss : 0.104322\n",
            "\n",
            "======== Epoch 434 =========\n",
            "Train loss : 0.141932, Test loss : 0.118331, Validation loss : 0.104064\n",
            "\n",
            "======== Epoch 435 =========\n",
            "Train loss : 0.141682, Test loss : 0.118136, Validation loss : 0.103823\n",
            "\n",
            "======== Epoch 436 =========\n",
            "Train loss : 0.141432, Test loss : 0.117970, Validation loss : 0.103571\n",
            "\n",
            "======== Epoch 437 =========\n",
            "Train loss : 0.141184, Test loss : 0.117809, Validation loss : 0.103317\n",
            "\n",
            "======== Epoch 438 =========\n",
            "Train loss : 0.140938, Test loss : 0.117617, Validation loss : 0.103080\n",
            "\n",
            "======== Epoch 439 =========\n",
            "Train loss : 0.140693, Test loss : 0.117452, Validation loss : 0.102833\n",
            "\n",
            "======== Epoch 440 =========\n",
            "Train loss : 0.140449, Test loss : 0.117296, Validation loss : 0.102584\n",
            "\n",
            "======== Epoch 441 =========\n",
            "Train loss : 0.140207, Test loss : 0.117096, Validation loss : 0.102354\n",
            "\n",
            "======== Epoch 442 =========\n",
            "Train loss : 0.139965, Test loss : 0.116952, Validation loss : 0.102105\n",
            "\n",
            "======== Epoch 443 =========\n",
            "Train loss : 0.139726, Test loss : 0.116763, Validation loss : 0.101873\n",
            "\n",
            "======== Epoch 444 =========\n",
            "Train loss : 0.139487, Test loss : 0.116633, Validation loss : 0.101621\n",
            "\n",
            "======== Epoch 445 =========\n",
            "Train loss : 0.139250, Test loss : 0.116427, Validation loss : 0.101401\n",
            "\n",
            "======== Epoch 446 =========\n",
            "Train loss : 0.139014, Test loss : 0.116284, Validation loss : 0.101157\n",
            "\n",
            "======== Epoch 447 =========\n",
            "Train loss : 0.138779, Test loss : 0.116124, Validation loss : 0.100922\n",
            "\n",
            "======== Epoch 448 =========\n",
            "Train loss : 0.138546, Test loss : 0.115941, Validation loss : 0.100697\n",
            "\n",
            "======== Epoch 449 =========\n",
            "Train loss : 0.138314, Test loss : 0.115810, Validation loss : 0.100453\n",
            "\n",
            "======== Epoch 450 =========\n",
            "Train loss : 0.138084, Test loss : 0.115614, Validation loss : 0.100237\n",
            "\n",
            "======== Epoch 451 =========\n",
            "Train loss : 0.137855, Test loss : 0.115472, Validation loss : 0.100002\n",
            "\n",
            "======== Epoch 452 =========\n",
            "Train loss : 0.137626, Test loss : 0.115319, Validation loss : 0.099771\n",
            "\n",
            "======== Epoch 453 =========\n",
            "Train loss : 0.137400, Test loss : 0.115143, Validation loss : 0.099553\n",
            "\n",
            "======== Epoch 454 =========\n",
            "Train loss : 0.137174, Test loss : 0.114995, Validation loss : 0.099324\n",
            "\n",
            "======== Epoch 455 =========\n",
            "Train loss : 0.136949, Test loss : 0.114845, Validation loss : 0.099098\n",
            "\n",
            "======== Epoch 456 =========\n",
            "Train loss : 0.136726, Test loss : 0.114676, Validation loss : 0.098881\n",
            "\n",
            "======== Epoch 457 =========\n",
            "Train loss : 0.136504, Test loss : 0.114540, Validation loss : 0.098652\n",
            "\n",
            "======== Epoch 458 =========\n",
            "Train loss : 0.136283, Test loss : 0.114358, Validation loss : 0.098443\n",
            "\n",
            "======== Epoch 459 =========\n",
            "Train loss : 0.136064, Test loss : 0.114217, Validation loss : 0.098221\n",
            "\n",
            "======== Epoch 460 =========\n",
            "Train loss : 0.135845, Test loss : 0.114069, Validation loss : 0.098001\n",
            "\n",
            "======== Epoch 461 =========\n",
            "Train loss : 0.135628, Test loss : 0.113903, Validation loss : 0.097791\n",
            "\n",
            "======== Epoch 462 =========\n",
            "Train loss : 0.135413, Test loss : 0.113759, Validation loss : 0.097574\n",
            "\n",
            "======== Epoch 463 =========\n",
            "Train loss : 0.135198, Test loss : 0.113622, Validation loss : 0.097355\n",
            "\n",
            "======== Epoch 464 =========\n",
            "Train loss : 0.134984, Test loss : 0.113448, Validation loss : 0.097152\n",
            "\n",
            "======== Epoch 465 =========\n",
            "Train loss : 0.134772, Test loss : 0.113332, Validation loss : 0.096929\n",
            "\n",
            "======== Epoch 466 =========\n",
            "Train loss : 0.134561, Test loss : 0.113136, Validation loss : 0.096737\n",
            "\n",
            "======== Epoch 467 =========\n",
            "Train loss : 0.134351, Test loss : 0.113025, Validation loss : 0.096516\n",
            "\n",
            "======== Epoch 468 =========\n",
            "Train loss : 0.134142, Test loss : 0.112869, Validation loss : 0.096312\n",
            "\n",
            "======== Epoch 469 =========\n",
            "Train loss : 0.133934, Test loss : 0.112712, Validation loss : 0.096111\n",
            "\n",
            "======== Epoch 470 =========\n",
            "Train loss : 0.133727, Test loss : 0.112597, Validation loss : 0.095895\n",
            "\n",
            "======== Epoch 471 =========\n",
            "Train loss : 0.133522, Test loss : 0.112408, Validation loss : 0.095707\n",
            "\n",
            "======== Epoch 472 =========\n",
            "Train loss : 0.133317, Test loss : 0.112299, Validation loss : 0.095494\n",
            "\n",
            "======== Epoch 473 =========\n",
            "Train loss : 0.133114, Test loss : 0.112148, Validation loss : 0.095295\n",
            "\n",
            "======== Epoch 474 =========\n",
            "Train loss : 0.132911, Test loss : 0.111999, Validation loss : 0.095098\n",
            "\n",
            "======== Epoch 475 =========\n",
            "Train loss : 0.132710, Test loss : 0.111878, Validation loss : 0.094892\n",
            "\n",
            "======== Epoch 476 =========\n",
            "Train loss : 0.132510, Test loss : 0.111707, Validation loss : 0.094705\n",
            "\n",
            "======== Epoch 477 =========\n",
            "Train loss : 0.132311, Test loss : 0.111605, Validation loss : 0.094495\n",
            "\n",
            "======== Epoch 478 =========\n",
            "Train loss : 0.132113, Test loss : 0.111429, Validation loss : 0.094312\n",
            "\n",
            "======== Epoch 479 =========\n",
            "Train loss : 0.131916, Test loss : 0.111329, Validation loss : 0.094105\n",
            "\n",
            "======== Epoch 480 =========\n",
            "Train loss : 0.131720, Test loss : 0.111152, Validation loss : 0.093925\n",
            "\n",
            "======== Epoch 481 =========\n",
            "Train loss : 0.131525, Test loss : 0.111041, Validation loss : 0.093724\n",
            "\n",
            "======== Epoch 482 =========\n",
            "Train loss : 0.131331, Test loss : 0.110907, Validation loss : 0.093531\n",
            "\n",
            "======== Epoch 483 =========\n",
            "Train loss : 0.131138, Test loss : 0.110757, Validation loss : 0.093346\n",
            "\n",
            "======== Epoch 484 =========\n",
            "Train loss : 0.130946, Test loss : 0.110643, Validation loss : 0.093150\n",
            "\n",
            "======== Epoch 485 =========\n",
            "Train loss : 0.130755, Test loss : 0.110484, Validation loss : 0.092970\n",
            "\n",
            "======== Epoch 486 =========\n",
            "Train loss : 0.130565, Test loss : 0.110380, Validation loss : 0.092772\n",
            "\n",
            "======== Epoch 487 =========\n",
            "Train loss : 0.130376, Test loss : 0.110217, Validation loss : 0.092596\n",
            "\n",
            "======== Epoch 488 =========\n",
            "Train loss : 0.130188, Test loss : 0.110123, Validation loss : 0.092398\n",
            "\n",
            "======== Epoch 489 =========\n",
            "Train loss : 0.130001, Test loss : 0.109947, Validation loss : 0.092229\n",
            "\n",
            "======== Epoch 490 =========\n",
            "Train loss : 0.129814, Test loss : 0.109861, Validation loss : 0.092030\n",
            "\n",
            "======== Epoch 491 =========\n",
            "Train loss : 0.129629, Test loss : 0.109694, Validation loss : 0.091860\n",
            "\n",
            "======== Epoch 492 =========\n",
            "Train loss : 0.129445, Test loss : 0.109589, Validation loss : 0.091670\n",
            "\n",
            "======== Epoch 493 =========\n",
            "Train loss : 0.129262, Test loss : 0.109434, Validation loss : 0.091499\n",
            "\n",
            "======== Epoch 494 =========\n",
            "Train loss : 0.129079, Test loss : 0.109333, Validation loss : 0.091311\n",
            "\n",
            "======== Epoch 495 =========\n",
            "Train loss : 0.128898, Test loss : 0.109175, Validation loss : 0.091142\n",
            "\n",
            "======== Epoch 496 =========\n",
            "Train loss : 0.128717, Test loss : 0.109085, Validation loss : 0.090952\n",
            "\n",
            "======== Epoch 497 =========\n",
            "Train loss : 0.128538, Test loss : 0.108925, Validation loss : 0.090787\n",
            "\n",
            "======== Epoch 498 =========\n",
            "Train loss : 0.128359, Test loss : 0.108835, Validation loss : 0.090599\n",
            "\n",
            "======== Epoch 499 =========\n",
            "Train loss : 0.128181, Test loss : 0.108675, Validation loss : 0.090436\n",
            "\n",
            "======== Epoch 500 =========\n",
            "Train loss : 0.128004, Test loss : 0.108573, Validation loss : 0.090255\n",
            "\n",
            "======== Epoch 501 =========\n",
            "Train loss : 0.127828, Test loss : 0.108445, Validation loss : 0.090083\n",
            "\n",
            "======== Epoch 502 =========\n",
            "Train loss : 0.127653, Test loss : 0.108317, Validation loss : 0.089913\n",
            "\n",
            "======== Epoch 503 =========\n",
            "Train loss : 0.127479, Test loss : 0.108214, Validation loss : 0.089735\n",
            "\n",
            "======== Epoch 504 =========\n",
            "Train loss : 0.127305, Test loss : 0.108068, Validation loss : 0.089572\n",
            "\n",
            "======== Epoch 505 =========\n",
            "Train loss : 0.127133, Test loss : 0.107977, Validation loss : 0.089393\n",
            "\n",
            "======== Epoch 506 =========\n",
            "Train loss : 0.126961, Test loss : 0.107816, Validation loss : 0.089237\n",
            "\n",
            "======== Epoch 507 =========\n",
            "Train loss : 0.126790, Test loss : 0.107744, Validation loss : 0.089054\n",
            "\n",
            "======== Epoch 508 =========\n",
            "Train loss : 0.126620, Test loss : 0.107579, Validation loss : 0.088902\n",
            "\n",
            "======== Epoch 509 =========\n",
            "Train loss : 0.126451, Test loss : 0.107504, Validation loss : 0.088722\n",
            "\n",
            "======== Epoch 510 =========\n",
            "Train loss : 0.126283, Test loss : 0.107341, Validation loss : 0.088570\n",
            "\n",
            "======== Epoch 511 =========\n",
            "Train loss : 0.126115, Test loss : 0.107273, Validation loss : 0.088391\n",
            "\n",
            "======== Epoch 512 =========\n",
            "Train loss : 0.125949, Test loss : 0.107109, Validation loss : 0.088242\n",
            "\n",
            "======== Epoch 513 =========\n",
            "Train loss : 0.125783, Test loss : 0.107032, Validation loss : 0.088067\n",
            "\n",
            "======== Epoch 514 =========\n",
            "Train loss : 0.125618, Test loss : 0.106879, Validation loss : 0.087916\n",
            "\n",
            "======== Epoch 515 =========\n",
            "Train loss : 0.125454, Test loss : 0.106790, Validation loss : 0.087748\n",
            "\n",
            "======== Epoch 516 =========\n",
            "Train loss : 0.125290, Test loss : 0.106671, Validation loss : 0.087589\n",
            "\n",
            "======== Epoch 517 =========\n",
            "Train loss : 0.125128, Test loss : 0.106550, Validation loss : 0.087431\n",
            "\n",
            "======== Epoch 518 =========\n",
            "Train loss : 0.124966, Test loss : 0.106452, Validation loss : 0.087268\n",
            "\n",
            "======== Epoch 519 =========\n",
            "Train loss : 0.124805, Test loss : 0.106312, Validation loss : 0.087118\n",
            "\n",
            "======== Epoch 520 =========\n",
            "Train loss : 0.124645, Test loss : 0.106239, Validation loss : 0.086949\n",
            "\n",
            "======== Epoch 521 =========\n",
            "Train loss : 0.124485, Test loss : 0.106085, Validation loss : 0.086805\n",
            "\n",
            "======== Epoch 522 =========\n",
            "Train loss : 0.124327, Test loss : 0.106013, Validation loss : 0.086638\n",
            "\n",
            "======== Epoch 523 =========\n",
            "Train loss : 0.124169, Test loss : 0.105867, Validation loss : 0.086494\n",
            "\n",
            "======== Epoch 524 =========\n",
            "Train loss : 0.124012, Test loss : 0.105792, Validation loss : 0.086329\n",
            "\n",
            "======== Epoch 525 =========\n",
            "Train loss : 0.123855, Test loss : 0.105642, Validation loss : 0.086187\n",
            "\n",
            "======== Epoch 526 =========\n",
            "Train loss : 0.123699, Test loss : 0.105571, Validation loss : 0.086023\n",
            "\n",
            "======== Epoch 527 =========\n",
            "Train loss : 0.123544, Test loss : 0.105426, Validation loss : 0.085882\n",
            "\n",
            "======== Epoch 528 =========\n",
            "Train loss : 0.123390, Test loss : 0.105355, Validation loss : 0.085720\n",
            "\n",
            "======== Epoch 529 =========\n",
            "Train loss : 0.123236, Test loss : 0.105205, Validation loss : 0.085582\n",
            "\n",
            "======== Epoch 530 =========\n",
            "Train loss : 0.123083, Test loss : 0.105144, Validation loss : 0.085419\n",
            "\n",
            "======== Epoch 531 =========\n",
            "Train loss : 0.122931, Test loss : 0.104993, Validation loss : 0.085283\n",
            "\n",
            "======== Epoch 532 =========\n",
            "Train loss : 0.122779, Test loss : 0.104929, Validation loss : 0.085123\n",
            "\n",
            "======== Epoch 533 =========\n",
            "Train loss : 0.122629, Test loss : 0.104791, Validation loss : 0.084984\n",
            "\n",
            "======== Epoch 534 =========\n",
            "Train loss : 0.122479, Test loss : 0.104695, Validation loss : 0.084835\n",
            "\n",
            "======== Epoch 535 =========\n",
            "Train loss : 0.122329, Test loss : 0.104599, Validation loss : 0.084687\n",
            "\n",
            "======== Epoch 536 =========\n",
            "Train loss : 0.122181, Test loss : 0.104470, Validation loss : 0.084548\n",
            "\n",
            "======== Epoch 537 =========\n",
            "Train loss : 0.122033, Test loss : 0.104402, Validation loss : 0.084394\n",
            "\n",
            "======== Epoch 538 =========\n",
            "Train loss : 0.121885, Test loss : 0.104272, Validation loss : 0.084257\n",
            "\n",
            "======== Epoch 539 =========\n",
            "Train loss : 0.121739, Test loss : 0.104172, Validation loss : 0.084114\n",
            "\n",
            "======== Epoch 540 =========\n",
            "Train loss : 0.121593, Test loss : 0.104080, Validation loss : 0.083968\n",
            "\n",
            "======== Epoch 541 =========\n",
            "Train loss : 0.121447, Test loss : 0.103972, Validation loss : 0.083828\n",
            "\n",
            "======== Epoch 542 =========\n",
            "Train loss : 0.121303, Test loss : 0.103860, Validation loss : 0.083690\n",
            "\n",
            "======== Epoch 543 =========\n",
            "Train loss : 0.121159, Test loss : 0.103778, Validation loss : 0.083544\n",
            "\n",
            "======== Epoch 544 =========\n",
            "Train loss : 0.121016, Test loss : 0.103670, Validation loss : 0.083406\n",
            "\n",
            "======== Epoch 545 =========\n",
            "Train loss : 0.120873, Test loss : 0.103544, Validation loss : 0.083274\n",
            "\n",
            "======== Epoch 546 =========\n",
            "Train loss : 0.120731, Test loss : 0.103481, Validation loss : 0.083126\n",
            "\n",
            "======== Epoch 547 =========\n",
            "Train loss : 0.120590, Test loss : 0.103357, Validation loss : 0.082995\n",
            "\n",
            "======== Epoch 548 =========\n",
            "Train loss : 0.120450, Test loss : 0.103255, Validation loss : 0.082859\n",
            "\n",
            "======== Epoch 549 =========\n",
            "Train loss : 0.120310, Test loss : 0.103176, Validation loss : 0.082718\n",
            "\n",
            "======== Epoch 550 =========\n",
            "Train loss : 0.120170, Test loss : 0.103068, Validation loss : 0.082585\n",
            "\n",
            "======== Epoch 551 =========\n",
            "Train loss : 0.120032, Test loss : 0.102958, Validation loss : 0.082453\n",
            "\n",
            "======== Epoch 552 =========\n",
            "Train loss : 0.119894, Test loss : 0.102882, Validation loss : 0.082314\n",
            "\n",
            "======== Epoch 553 =========\n",
            "Train loss : 0.119756, Test loss : 0.102770, Validation loss : 0.082184\n",
            "\n",
            "======== Epoch 554 =========\n",
            "Train loss : 0.119619, Test loss : 0.102674, Validation loss : 0.082051\n",
            "\n",
            "======== Epoch 555 =========\n",
            "Train loss : 0.119483, Test loss : 0.102586, Validation loss : 0.081917\n",
            "\n",
            "======== Epoch 556 =========\n",
            "Train loss : 0.119348, Test loss : 0.102477, Validation loss : 0.081789\n",
            "\n",
            "======== Epoch 557 =========\n",
            "Train loss : 0.119213, Test loss : 0.102401, Validation loss : 0.081653\n",
            "\n",
            "======== Epoch 558 =========\n",
            "Train loss : 0.119078, Test loss : 0.102295, Validation loss : 0.081525\n",
            "\n",
            "======== Epoch 559 =========\n",
            "Train loss : 0.118944, Test loss : 0.102195, Validation loss : 0.081397\n",
            "\n",
            "======== Epoch 560 =========\n",
            "Train loss : 0.118811, Test loss : 0.102117, Validation loss : 0.081264\n",
            "\n",
            "======== Epoch 561 =========\n",
            "Train loss : 0.118679, Test loss : 0.102014, Validation loss : 0.081138\n",
            "\n",
            "======== Epoch 562 =========\n",
            "Train loss : 0.118547, Test loss : 0.101912, Validation loss : 0.081012\n",
            "\n",
            "======== Epoch 563 =========\n",
            "Train loss : 0.118415, Test loss : 0.101832, Validation loss : 0.080882\n",
            "\n",
            "======== Epoch 564 =========\n",
            "Train loss : 0.118285, Test loss : 0.101736, Validation loss : 0.080756\n",
            "\n",
            "======== Epoch 565 =========\n",
            "Train loss : 0.118154, Test loss : 0.101629, Validation loss : 0.080633\n",
            "\n",
            "======== Epoch 566 =========\n",
            "Train loss : 0.118025, Test loss : 0.101563, Validation loss : 0.080501\n",
            "\n",
            "======== Epoch 567 =========\n",
            "Train loss : 0.117895, Test loss : 0.101452, Validation loss : 0.080381\n",
            "\n",
            "======== Epoch 568 =========\n",
            "Train loss : 0.117767, Test loss : 0.101365, Validation loss : 0.080256\n",
            "\n",
            "======== Epoch 569 =========\n",
            "Train loss : 0.117639, Test loss : 0.101280, Validation loss : 0.080131\n",
            "\n",
            "======== Epoch 570 =========\n",
            "Train loss : 0.117511, Test loss : 0.101190, Validation loss : 0.080007\n",
            "\n",
            "======== Epoch 571 =========\n",
            "Train loss : 0.117385, Test loss : 0.101084, Validation loss : 0.079889\n",
            "\n",
            "======== Epoch 572 =========\n",
            "Train loss : 0.117258, Test loss : 0.101021, Validation loss : 0.079760\n",
            "\n",
            "======== Epoch 573 =========\n",
            "Train loss : 0.117133, Test loss : 0.100913, Validation loss : 0.079643\n",
            "\n",
            "======== Epoch 574 =========\n",
            "Train loss : 0.117007, Test loss : 0.100826, Validation loss : 0.079522\n",
            "\n",
            "======== Epoch 575 =========\n",
            "Train loss : 0.116883, Test loss : 0.100749, Validation loss : 0.079399\n",
            "\n",
            "======== Epoch 576 =========\n",
            "Train loss : 0.116759, Test loss : 0.100652, Validation loss : 0.079281\n",
            "\n",
            "======== Epoch 577 =========\n",
            "Train loss : 0.116635, Test loss : 0.100556, Validation loss : 0.079164\n",
            "\n",
            "======== Epoch 578 =========\n",
            "Train loss : 0.116512, Test loss : 0.100488, Validation loss : 0.079040\n",
            "\n",
            "======== Epoch 579 =========\n",
            "Train loss : 0.116390, Test loss : 0.100390, Validation loss : 0.078925\n",
            "\n",
            "======== Epoch 580 =========\n",
            "Train loss : 0.116268, Test loss : 0.100297, Validation loss : 0.078809\n",
            "\n",
            "======== Epoch 581 =========\n",
            "Train loss : 0.116146, Test loss : 0.100226, Validation loss : 0.078688\n",
            "\n",
            "======== Epoch 582 =========\n",
            "Train loss : 0.116025, Test loss : 0.100136, Validation loss : 0.078572\n",
            "\n",
            "======== Epoch 583 =========\n",
            "Train loss : 0.115905, Test loss : 0.100027, Validation loss : 0.078462\n",
            "\n",
            "======== Epoch 584 =========\n",
            "Train loss : 0.115785, Test loss : 0.099978, Validation loss : 0.078338\n",
            "\n",
            "======== Epoch 585 =========\n",
            "Train loss : 0.115666, Test loss : 0.099862, Validation loss : 0.078230\n",
            "\n",
            "======== Epoch 586 =========\n",
            "Train loss : 0.115547, Test loss : 0.099799, Validation loss : 0.078110\n",
            "\n",
            "======== Epoch 587 =========\n",
            "Train loss : 0.115429, Test loss : 0.099687, Validation loss : 0.078003\n",
            "\n",
            "======== Epoch 588 =========\n",
            "Train loss : 0.115311, Test loss : 0.099642, Validation loss : 0.077880\n",
            "\n",
            "======== Epoch 589 =========\n",
            "Train loss : 0.115194, Test loss : 0.099528, Validation loss : 0.077774\n",
            "\n",
            "======== Epoch 590 =========\n",
            "Train loss : 0.115077, Test loss : 0.099451, Validation loss : 0.077661\n",
            "\n",
            "======== Epoch 591 =========\n",
            "Train loss : 0.114961, Test loss : 0.099378, Validation loss : 0.077546\n",
            "\n",
            "======== Epoch 592 =========\n",
            "Train loss : 0.114845, Test loss : 0.099286, Validation loss : 0.077437\n",
            "\n",
            "======== Epoch 593 =========\n",
            "Train loss : 0.114729, Test loss : 0.099214, Validation loss : 0.077323\n",
            "\n",
            "======== Epoch 594 =========\n",
            "Train loss : 0.114615, Test loss : 0.099111, Validation loss : 0.077218\n",
            "\n",
            "======== Epoch 595 =========\n",
            "Train loss : 0.114500, Test loss : 0.099057, Validation loss : 0.077102\n",
            "\n",
            "======== Epoch 596 =========\n",
            "Train loss : 0.114386, Test loss : 0.098955, Validation loss : 0.076997\n",
            "\n",
            "======== Epoch 597 =========\n",
            "Train loss : 0.114273, Test loss : 0.098891, Validation loss : 0.076884\n",
            "\n",
            "======== Epoch 598 =========\n",
            "Train loss : 0.114160, Test loss : 0.098786, Validation loss : 0.076781\n",
            "\n",
            "======== Epoch 599 =========\n",
            "Train loss : 0.114048, Test loss : 0.098732, Validation loss : 0.076668\n",
            "\n",
            "======== Epoch 600 =========\n",
            "Train loss : 0.113936, Test loss : 0.098638, Validation loss : 0.076563\n",
            "\n",
            "======== Epoch 601 =========\n",
            "Train loss : 0.113824, Test loss : 0.098566, Validation loss : 0.076455\n",
            "\n",
            "======== Epoch 602 =========\n",
            "Train loss : 0.113713, Test loss : 0.098471, Validation loss : 0.076352\n",
            "\n",
            "======== Epoch 603 =========\n",
            "Train loss : 0.113603, Test loss : 0.098411, Validation loss : 0.076242\n",
            "\n",
            "======== Epoch 604 =========\n",
            "Train loss : 0.113492, Test loss : 0.098322, Validation loss : 0.076138\n",
            "\n",
            "======== Epoch 605 =========\n",
            "Train loss : 0.113383, Test loss : 0.098255, Validation loss : 0.076031\n",
            "\n",
            "======== Epoch 606 =========\n",
            "Train loss : 0.113274, Test loss : 0.098150, Validation loss : 0.075932\n",
            "\n",
            "======== Epoch 607 =========\n",
            "Train loss : 0.113165, Test loss : 0.098104, Validation loss : 0.075821\n",
            "\n",
            "======== Epoch 608 =========\n",
            "Train loss : 0.113056, Test loss : 0.098008, Validation loss : 0.075721\n",
            "\n",
            "======== Epoch 609 =========\n",
            "Train loss : 0.112949, Test loss : 0.097938, Validation loss : 0.075616\n",
            "\n",
            "======== Epoch 610 =========\n",
            "Train loss : 0.112841, Test loss : 0.097851, Validation loss : 0.075516\n",
            "\n",
            "======== Epoch 611 =========\n",
            "Train loss : 0.112734, Test loss : 0.097789, Validation loss : 0.075411\n",
            "\n",
            "======== Epoch 612 =========\n",
            "Train loss : 0.112628, Test loss : 0.097701, Validation loss : 0.075311\n",
            "\n",
            "======== Epoch 613 =========\n",
            "Train loss : 0.112521, Test loss : 0.097633, Validation loss : 0.075208\n",
            "\n",
            "======== Epoch 614 =========\n",
            "Train loss : 0.112416, Test loss : 0.097533, Validation loss : 0.075112\n",
            "\n",
            "======== Epoch 615 =========\n",
            "Train loss : 0.112310, Test loss : 0.097489, Validation loss : 0.075005\n",
            "\n",
            "======== Epoch 616 =========\n",
            "Train loss : 0.112205, Test loss : 0.097390, Validation loss : 0.074910\n",
            "\n",
            "======== Epoch 617 =========\n",
            "Train loss : 0.112101, Test loss : 0.097318, Validation loss : 0.074810\n",
            "\n",
            "======== Epoch 618 =========\n",
            "Train loss : 0.111997, Test loss : 0.097255, Validation loss : 0.074708\n",
            "\n",
            "======== Epoch 619 =========\n",
            "Train loss : 0.111893, Test loss : 0.097173, Validation loss : 0.074611\n",
            "\n",
            "======== Epoch 620 =========\n",
            "Train loss : 0.111790, Test loss : 0.097102, Validation loss : 0.074512\n",
            "\n",
            "======== Epoch 621 =========\n",
            "Train loss : 0.111687, Test loss : 0.097020, Validation loss : 0.074417\n",
            "\n",
            "======== Epoch 622 =========\n",
            "Train loss : 0.111585, Test loss : 0.096959, Validation loss : 0.074317\n",
            "\n",
            "======== Epoch 623 =========\n",
            "Train loss : 0.111483, Test loss : 0.096880, Validation loss : 0.074221\n",
            "\n",
            "======== Epoch 624 =========\n",
            "Train loss : 0.111381, Test loss : 0.096812, Validation loss : 0.074124\n",
            "\n",
            "======== Epoch 625 =========\n",
            "Train loss : 0.111280, Test loss : 0.096721, Validation loss : 0.074032\n",
            "\n",
            "======== Epoch 626 =========\n",
            "Train loss : 0.111179, Test loss : 0.096669, Validation loss : 0.073932\n",
            "\n",
            "======== Epoch 627 =========\n",
            "Train loss : 0.111079, Test loss : 0.096591, Validation loss : 0.073838\n",
            "\n",
            "======== Epoch 628 =========\n",
            "Train loss : 0.110979, Test loss : 0.096520, Validation loss : 0.073743\n",
            "\n",
            "======== Epoch 629 =========\n",
            "Train loss : 0.110879, Test loss : 0.096433, Validation loss : 0.073653\n",
            "\n",
            "======== Epoch 630 =========\n",
            "Train loss : 0.110780, Test loss : 0.096390, Validation loss : 0.073553\n",
            "\n",
            "======== Epoch 631 =========\n",
            "Train loss : 0.110681, Test loss : 0.096294, Validation loss : 0.073464\n",
            "\n",
            "======== Epoch 632 =========\n",
            "Train loss : 0.110583, Test loss : 0.096240, Validation loss : 0.073368\n",
            "\n",
            "======== Epoch 633 =========\n",
            "Train loss : 0.110485, Test loss : 0.096148, Validation loss : 0.073280\n",
            "\n",
            "======== Epoch 634 =========\n",
            "Train loss : 0.110387, Test loss : 0.096102, Validation loss : 0.073182\n",
            "\n",
            "======== Epoch 635 =========\n",
            "Train loss : 0.110290, Test loss : 0.096016, Validation loss : 0.073094\n",
            "\n",
            "======== Epoch 636 =========\n",
            "Train loss : 0.110193, Test loss : 0.095942, Validation loss : 0.073003\n",
            "\n",
            "======== Epoch 637 =========\n",
            "Train loss : 0.110097, Test loss : 0.095889, Validation loss : 0.072909\n",
            "\n",
            "======== Epoch 638 =========\n",
            "Train loss : 0.110001, Test loss : 0.095807, Validation loss : 0.072821\n",
            "\n",
            "======== Epoch 639 =========\n",
            "Train loss : 0.109905, Test loss : 0.095751, Validation loss : 0.072727\n",
            "\n",
            "======== Epoch 640 =========\n",
            "Train loss : 0.109809, Test loss : 0.095656, Validation loss : 0.072643\n",
            "\n",
            "======== Epoch 641 =========\n",
            "Train loss : 0.109714, Test loss : 0.095615, Validation loss : 0.072548\n",
            "\n",
            "======== Epoch 642 =========\n",
            "Train loss : 0.109620, Test loss : 0.095530, Validation loss : 0.072462\n",
            "\n",
            "======== Epoch 643 =========\n",
            "Train loss : 0.109525, Test loss : 0.095463, Validation loss : 0.072373\n",
            "\n",
            "======== Epoch 644 =========\n",
            "Train loss : 0.109431, Test loss : 0.095403, Validation loss : 0.072283\n",
            "\n",
            "======== Epoch 645 =========\n",
            "Train loss : 0.109338, Test loss : 0.095328, Validation loss : 0.072196\n",
            "\n",
            "======== Epoch 646 =========\n",
            "Train loss : 0.109245, Test loss : 0.095267, Validation loss : 0.072107\n",
            "\n",
            "======== Epoch 647 =========\n",
            "Train loss : 0.109152, Test loss : 0.095183, Validation loss : 0.072023\n",
            "\n",
            "======== Epoch 648 =========\n",
            "Train loss : 0.109059, Test loss : 0.095137, Validation loss : 0.071932\n",
            "\n",
            "======== Epoch 649 =========\n",
            "Train loss : 0.108967, Test loss : 0.095056, Validation loss : 0.071849\n",
            "\n",
            "======== Epoch 650 =========\n",
            "Train loss : 0.108875, Test loss : 0.094998, Validation loss : 0.071761\n",
            "\n",
            "======== Epoch 651 =========\n",
            "Train loss : 0.108784, Test loss : 0.094917, Validation loss : 0.071678\n",
            "\n",
            "======== Epoch 652 =========\n",
            "Train loss : 0.108693, Test loss : 0.094871, Validation loss : 0.071588\n",
            "\n",
            "======== Epoch 653 =========\n",
            "Train loss : 0.108602, Test loss : 0.094790, Validation loss : 0.071506\n",
            "\n",
            "======== Epoch 654 =========\n",
            "Train loss : 0.108511, Test loss : 0.094718, Validation loss : 0.071423\n",
            "\n",
            "======== Epoch 655 =========\n",
            "Train loss : 0.108421, Test loss : 0.094671, Validation loss : 0.071335\n",
            "\n",
            "======== Epoch 656 =========\n",
            "Train loss : 0.108332, Test loss : 0.094592, Validation loss : 0.071253\n",
            "\n",
            "======== Epoch 657 =========\n",
            "Train loss : 0.108242, Test loss : 0.094542, Validation loss : 0.071167\n",
            "\n",
            "======== Epoch 658 =========\n",
            "Train loss : 0.108153, Test loss : 0.094453, Validation loss : 0.071088\n",
            "\n",
            "======== Epoch 659 =========\n",
            "Train loss : 0.108064, Test loss : 0.094409, Validation loss : 0.071001\n",
            "\n",
            "======== Epoch 660 =========\n",
            "Train loss : 0.107976, Test loss : 0.094334, Validation loss : 0.070921\n",
            "\n",
            "======== Epoch 661 =========\n",
            "Train loss : 0.107888, Test loss : 0.094269, Validation loss : 0.070839\n",
            "\n",
            "======== Epoch 662 =========\n",
            "Train loss : 0.107800, Test loss : 0.094209, Validation loss : 0.070756\n",
            "\n",
            "======== Epoch 663 =========\n",
            "Train loss : 0.107713, Test loss : 0.094146, Validation loss : 0.070674\n",
            "\n",
            "======== Epoch 664 =========\n",
            "Train loss : 0.107626, Test loss : 0.094082, Validation loss : 0.070593\n",
            "\n",
            "======== Epoch 665 =========\n",
            "Train loss : 0.107539, Test loss : 0.094009, Validation loss : 0.070514\n",
            "\n",
            "======== Epoch 666 =========\n",
            "Train loss : 0.107452, Test loss : 0.093962, Validation loss : 0.070430\n",
            "\n",
            "======== Epoch 667 =========\n",
            "Train loss : 0.107366, Test loss : 0.093887, Validation loss : 0.070352\n",
            "\n",
            "======== Epoch 668 =========\n",
            "Train loss : 0.107280, Test loss : 0.093818, Validation loss : 0.070274\n",
            "\n",
            "======== Epoch 669 =========\n",
            "Train loss : 0.107195, Test loss : 0.093770, Validation loss : 0.070192\n",
            "\n",
            "======== Epoch 670 =========\n",
            "Train loss : 0.107110, Test loss : 0.093698, Validation loss : 0.070114\n",
            "\n",
            "======== Epoch 671 =========\n",
            "Train loss : 0.107025, Test loss : 0.093651, Validation loss : 0.070032\n",
            "\n",
            "======== Epoch 672 =========\n",
            "Train loss : 0.106940, Test loss : 0.093559, Validation loss : 0.069959\n",
            "\n",
            "======== Epoch 673 =========\n",
            "Train loss : 0.106856, Test loss : 0.093532, Validation loss : 0.069875\n",
            "\n",
            "======== Epoch 674 =========\n",
            "Train loss : 0.106772, Test loss : 0.093443, Validation loss : 0.069802\n",
            "\n",
            "======== Epoch 675 =========\n",
            "Train loss : 0.106688, Test loss : 0.093387, Validation loss : 0.069723\n",
            "\n",
            "======== Epoch 676 =========\n",
            "Train loss : 0.106605, Test loss : 0.093332, Validation loss : 0.069645\n",
            "\n",
            "======== Epoch 677 =========\n",
            "Train loss : 0.106522, Test loss : 0.093274, Validation loss : 0.069567\n",
            "\n",
            "======== Epoch 678 =========\n",
            "Train loss : 0.106439, Test loss : 0.093198, Validation loss : 0.069493\n",
            "\n",
            "======== Epoch 679 =========\n",
            "Train loss : 0.106357, Test loss : 0.093153, Validation loss : 0.069414\n",
            "\n",
            "======== Epoch 680 =========\n",
            "Train loss : 0.106275, Test loss : 0.093084, Validation loss : 0.069340\n",
            "\n",
            "======== Epoch 681 =========\n",
            "Train loss : 0.106193, Test loss : 0.093029, Validation loss : 0.069263\n",
            "\n",
            "======== Epoch 682 =========\n",
            "Train loss : 0.106112, Test loss : 0.092949, Validation loss : 0.069191\n",
            "\n",
            "======== Epoch 683 =========\n",
            "Train loss : 0.106031, Test loss : 0.092907, Validation loss : 0.069113\n",
            "\n",
            "======== Epoch 684 =========\n",
            "Train loss : 0.105950, Test loss : 0.092847, Validation loss : 0.069038\n",
            "\n",
            "======== Epoch 685 =========\n",
            "Train loss : 0.105870, Test loss : 0.092762, Validation loss : 0.068968\n",
            "\n",
            "======== Epoch 686 =========\n",
            "Train loss : 0.105790, Test loss : 0.092730, Validation loss : 0.068889\n",
            "\n",
            "======== Epoch 687 =========\n",
            "Train loss : 0.105710, Test loss : 0.092652, Validation loss : 0.068819\n",
            "\n",
            "======== Epoch 688 =========\n",
            "Train loss : 0.105630, Test loss : 0.092602, Validation loss : 0.068744\n",
            "\n",
            "======== Epoch 689 =========\n",
            "Train loss : 0.105550, Test loss : 0.092537, Validation loss : 0.068671\n",
            "\n",
            "======== Epoch 690 =========\n",
            "Train loss : 0.105470, Test loss : 0.092486, Validation loss : 0.068597\n",
            "\n",
            "======== Epoch 691 =========\n",
            "Train loss : 0.105391, Test loss : 0.092431, Validation loss : 0.068524\n",
            "\n",
            "======== Epoch 692 =========\n",
            "Train loss : 0.105312, Test loss : 0.092347, Validation loss : 0.068456\n",
            "\n",
            "======== Epoch 693 =========\n",
            "Train loss : 0.105234, Test loss : 0.092314, Validation loss : 0.068380\n",
            "\n",
            "======== Epoch 694 =========\n",
            "Train loss : 0.105156, Test loss : 0.092240, Validation loss : 0.068310\n",
            "\n",
            "======== Epoch 695 =========\n",
            "Train loss : 0.105078, Test loss : 0.092193, Validation loss : 0.068237\n",
            "\n",
            "======== Epoch 696 =========\n",
            "Train loss : 0.105000, Test loss : 0.092127, Validation loss : 0.068167\n",
            "\n",
            "======== Epoch 697 =========\n",
            "Train loss : 0.104922, Test loss : 0.092070, Validation loss : 0.068096\n",
            "\n",
            "======== Epoch 698 =========\n",
            "Train loss : 0.104845, Test loss : 0.092008, Validation loss : 0.068027\n",
            "\n",
            "======== Epoch 699 =========\n",
            "Train loss : 0.104768, Test loss : 0.091966, Validation loss : 0.067954\n",
            "\n",
            "======== Epoch 700 =========\n",
            "Train loss : 0.104691, Test loss : 0.091889, Validation loss : 0.067887\n",
            "\n",
            "======== Epoch 701 =========\n",
            "Train loss : 0.104615, Test loss : 0.091840, Validation loss : 0.067816\n",
            "\n",
            "======== Epoch 702 =========\n",
            "Train loss : 0.104538, Test loss : 0.091782, Validation loss : 0.067747\n",
            "\n",
            "======== Epoch 703 =========\n",
            "Train loss : 0.104462, Test loss : 0.091732, Validation loss : 0.067676\n",
            "\n",
            "======== Epoch 704 =========\n",
            "Train loss : 0.104386, Test loss : 0.091664, Validation loss : 0.067609\n",
            "\n",
            "======== Epoch 705 =========\n",
            "Train loss : 0.104311, Test loss : 0.091604, Validation loss : 0.067541\n",
            "\n",
            "======== Epoch 706 =========\n",
            "Train loss : 0.104236, Test loss : 0.091556, Validation loss : 0.067472\n",
            "\n",
            "======== Epoch 707 =========\n",
            "Train loss : 0.104161, Test loss : 0.091508, Validation loss : 0.067402\n",
            "\n",
            "======== Epoch 708 =========\n",
            "Train loss : 0.104086, Test loss : 0.091426, Validation loss : 0.067339\n",
            "\n",
            "======== Epoch 709 =========\n",
            "Train loss : 0.104011, Test loss : 0.091391, Validation loss : 0.067268\n",
            "\n",
            "======== Epoch 710 =========\n",
            "Train loss : 0.103937, Test loss : 0.091323, Validation loss : 0.067203\n",
            "\n",
            "======== Epoch 711 =========\n",
            "Train loss : 0.103863, Test loss : 0.091269, Validation loss : 0.067136\n",
            "\n",
            "======== Epoch 712 =========\n",
            "Train loss : 0.103789, Test loss : 0.091225, Validation loss : 0.067067\n",
            "\n",
            "======== Epoch 713 =========\n",
            "Train loss : 0.103716, Test loss : 0.091156, Validation loss : 0.067003\n",
            "\n",
            "======== Epoch 714 =========\n",
            "Train loss : 0.103642, Test loss : 0.091097, Validation loss : 0.066937\n",
            "\n",
            "======== Epoch 715 =========\n",
            "Train loss : 0.103569, Test loss : 0.091051, Validation loss : 0.066870\n",
            "\n",
            "======== Epoch 716 =========\n",
            "Train loss : 0.103497, Test loss : 0.090997, Validation loss : 0.066804\n",
            "\n",
            "======== Epoch 717 =========\n",
            "Train loss : 0.103424, Test loss : 0.090935, Validation loss : 0.066740\n",
            "\n",
            "======== Epoch 718 =========\n",
            "Train loss : 0.103352, Test loss : 0.090888, Validation loss : 0.066674\n",
            "\n",
            "======== Epoch 719 =========\n",
            "Train loss : 0.103280, Test loss : 0.090825, Validation loss : 0.066610\n",
            "\n",
            "======== Epoch 720 =========\n",
            "Train loss : 0.103208, Test loss : 0.090767, Validation loss : 0.066546\n",
            "\n",
            "======== Epoch 721 =========\n",
            "Train loss : 0.103137, Test loss : 0.090713, Validation loss : 0.066482\n",
            "\n",
            "======== Epoch 722 =========\n",
            "Train loss : 0.103066, Test loss : 0.090667, Validation loss : 0.066417\n",
            "\n",
            "======== Epoch 723 =========\n",
            "Train loss : 0.102995, Test loss : 0.090600, Validation loss : 0.066355\n",
            "\n",
            "======== Epoch 724 =========\n",
            "Train loss : 0.102924, Test loss : 0.090562, Validation loss : 0.066289\n",
            "\n",
            "======== Epoch 725 =========\n",
            "Train loss : 0.102854, Test loss : 0.090497, Validation loss : 0.066227\n",
            "\n",
            "======== Epoch 726 =========\n",
            "Train loss : 0.102783, Test loss : 0.090444, Validation loss : 0.066164\n",
            "\n",
            "======== Epoch 727 =========\n",
            "Train loss : 0.102712, Test loss : 0.090383, Validation loss : 0.066101\n",
            "\n",
            "======== Epoch 728 =========\n",
            "Train loss : 0.102642, Test loss : 0.090344, Validation loss : 0.066036\n",
            "\n",
            "======== Epoch 729 =========\n",
            "Train loss : 0.102572, Test loss : 0.090274, Validation loss : 0.065975\n",
            "\n",
            "======== Epoch 730 =========\n",
            "Train loss : 0.102500, Test loss : 0.090224, Validation loss : 0.065911\n",
            "\n",
            "======== Epoch 731 =========\n",
            "Train loss : 0.102429, Test loss : 0.090176, Validation loss : 0.065848\n",
            "\n",
            "======== Epoch 732 =========\n",
            "Train loss : 0.102358, Test loss : 0.090119, Validation loss : 0.065785\n",
            "\n",
            "======== Epoch 733 =========\n",
            "Train loss : 0.102288, Test loss : 0.090061, Validation loss : 0.065724\n",
            "\n",
            "======== Epoch 734 =========\n",
            "Train loss : 0.102217, Test loss : 0.089996, Validation loss : 0.065663\n",
            "\n",
            "======== Epoch 735 =========\n",
            "Train loss : 0.102147, Test loss : 0.089962, Validation loss : 0.065599\n",
            "\n",
            "======== Epoch 736 =========\n",
            "Train loss : 0.102077, Test loss : 0.089890, Validation loss : 0.065540\n",
            "\n",
            "======== Epoch 737 =========\n",
            "Train loss : 0.102007, Test loss : 0.089843, Validation loss : 0.065477\n",
            "\n",
            "======== Epoch 738 =========\n",
            "Train loss : 0.101938, Test loss : 0.089797, Validation loss : 0.065415\n",
            "\n",
            "======== Epoch 739 =========\n",
            "Train loss : 0.101868, Test loss : 0.089724, Validation loss : 0.065357\n",
            "\n",
            "======== Epoch 740 =========\n",
            "Train loss : 0.101799, Test loss : 0.089691, Validation loss : 0.065293\n",
            "\n",
            "======== Epoch 741 =========\n",
            "Train loss : 0.101730, Test loss : 0.089614, Validation loss : 0.065236\n",
            "\n",
            "======== Epoch 742 =========\n",
            "Train loss : 0.101661, Test loss : 0.089582, Validation loss : 0.065173\n",
            "\n",
            "======== Epoch 743 =========\n",
            "Train loss : 0.101593, Test loss : 0.089518, Validation loss : 0.065115\n",
            "\n",
            "======== Epoch 744 =========\n",
            "Train loss : 0.101524, Test loss : 0.089457, Validation loss : 0.065056\n",
            "\n",
            "======== Epoch 745 =========\n",
            "Train loss : 0.101456, Test loss : 0.089416, Validation loss : 0.064995\n",
            "\n",
            "======== Epoch 746 =========\n",
            "Train loss : 0.101388, Test loss : 0.089364, Validation loss : 0.064936\n",
            "\n",
            "======== Epoch 747 =========\n",
            "Train loss : 0.101320, Test loss : 0.089301, Validation loss : 0.064879\n",
            "\n",
            "======== Epoch 748 =========\n",
            "Train loss : 0.101253, Test loss : 0.089268, Validation loss : 0.064817\n",
            "\n",
            "======== Epoch 749 =========\n",
            "Train loss : 0.101186, Test loss : 0.089197, Validation loss : 0.064762\n",
            "\n",
            "======== Epoch 750 =========\n",
            "Train loss : 0.101120, Test loss : 0.089162, Validation loss : 0.064702\n",
            "\n",
            "======== Epoch 751 =========\n",
            "Train loss : 0.101054, Test loss : 0.089098, Validation loss : 0.064646\n",
            "\n",
            "======== Epoch 752 =========\n",
            "Train loss : 0.100988, Test loss : 0.089068, Validation loss : 0.064585\n",
            "\n",
            "======== Epoch 753 =========\n",
            "Train loss : 0.100923, Test loss : 0.088993, Validation loss : 0.064531\n",
            "\n",
            "======== Epoch 754 =========\n",
            "Train loss : 0.100858, Test loss : 0.088966, Validation loss : 0.064471\n",
            "\n",
            "======== Epoch 755 =========\n",
            "Train loss : 0.100793, Test loss : 0.088913, Validation loss : 0.064414\n",
            "\n",
            "======== Epoch 756 =========\n",
            "Train loss : 0.100728, Test loss : 0.088854, Validation loss : 0.064359\n",
            "\n",
            "======== Epoch 757 =========\n",
            "Train loss : 0.100663, Test loss : 0.088809, Validation loss : 0.064302\n",
            "\n",
            "======== Epoch 758 =========\n",
            "Train loss : 0.100599, Test loss : 0.088761, Validation loss : 0.064245\n",
            "\n",
            "======== Epoch 759 =========\n",
            "Train loss : 0.100535, Test loss : 0.088719, Validation loss : 0.064188\n",
            "\n",
            "======== Epoch 760 =========\n",
            "Train loss : 0.100471, Test loss : 0.088653, Validation loss : 0.064134\n",
            "\n",
            "======== Epoch 761 =========\n",
            "Train loss : 0.100407, Test loss : 0.088628, Validation loss : 0.064075\n",
            "\n",
            "======== Epoch 762 =========\n",
            "Train loss : 0.100343, Test loss : 0.088563, Validation loss : 0.064022\n",
            "\n",
            "======== Epoch 763 =========\n",
            "Train loss : 0.100280, Test loss : 0.088516, Validation loss : 0.063967\n",
            "\n",
            "======== Epoch 764 =========\n",
            "Train loss : 0.100217, Test loss : 0.088473, Validation loss : 0.063911\n",
            "\n",
            "======== Epoch 765 =========\n",
            "Train loss : 0.100153, Test loss : 0.088427, Validation loss : 0.063856\n",
            "\n",
            "======== Epoch 766 =========\n",
            "Train loss : 0.100091, Test loss : 0.088369, Validation loss : 0.063802\n",
            "\n",
            "======== Epoch 767 =========\n",
            "Train loss : 0.100028, Test loss : 0.088341, Validation loss : 0.063745\n",
            "\n",
            "======== Epoch 768 =========\n",
            "Train loss : 0.099966, Test loss : 0.088275, Validation loss : 0.063693\n",
            "\n",
            "======== Epoch 769 =========\n",
            "Train loss : 0.099904, Test loss : 0.088236, Validation loss : 0.063638\n",
            "\n",
            "======== Epoch 770 =========\n",
            "Train loss : 0.099842, Test loss : 0.088184, Validation loss : 0.063585\n",
            "\n",
            "======== Epoch 771 =========\n",
            "Train loss : 0.099780, Test loss : 0.088143, Validation loss : 0.063530\n",
            "\n",
            "======== Epoch 772 =========\n",
            "Train loss : 0.099719, Test loss : 0.088086, Validation loss : 0.063478\n",
            "\n",
            "======== Epoch 773 =========\n",
            "Train loss : 0.099657, Test loss : 0.088053, Validation loss : 0.063423\n",
            "\n",
            "======== Epoch 774 =========\n",
            "Train loss : 0.099596, Test loss : 0.087997, Validation loss : 0.063371\n",
            "\n",
            "======== Epoch 775 =========\n",
            "Train loss : 0.099535, Test loss : 0.087942, Validation loss : 0.063319\n",
            "\n",
            "======== Epoch 776 =========\n",
            "Train loss : 0.099475, Test loss : 0.087913, Validation loss : 0.063264\n",
            "\n",
            "======== Epoch 777 =========\n",
            "Train loss : 0.099415, Test loss : 0.087850, Validation loss : 0.063214\n",
            "\n",
            "======== Epoch 778 =========\n",
            "Train loss : 0.099355, Test loss : 0.087813, Validation loss : 0.063161\n",
            "\n",
            "======== Epoch 779 =========\n",
            "Train loss : 0.099296, Test loss : 0.087760, Validation loss : 0.063110\n",
            "\n",
            "======== Epoch 780 =========\n",
            "Train loss : 0.099236, Test loss : 0.087720, Validation loss : 0.063057\n",
            "\n",
            "======== Epoch 781 =========\n",
            "Train loss : 0.099177, Test loss : 0.087665, Validation loss : 0.063007\n",
            "\n",
            "======== Epoch 782 =========\n",
            "Train loss : 0.099118, Test loss : 0.087632, Validation loss : 0.062954\n",
            "\n",
            "======== Epoch 783 =========\n",
            "Train loss : 0.099059, Test loss : 0.087581, Validation loss : 0.062903\n",
            "\n",
            "======== Epoch 784 =========\n",
            "Train loss : 0.099001, Test loss : 0.087526, Validation loss : 0.062853\n",
            "\n",
            "======== Epoch 785 =========\n",
            "Train loss : 0.098942, Test loss : 0.087498, Validation loss : 0.062800\n",
            "\n",
            "======== Epoch 786 =========\n",
            "Train loss : 0.098884, Test loss : 0.087441, Validation loss : 0.062751\n",
            "\n",
            "======== Epoch 787 =========\n",
            "Train loss : 0.098826, Test loss : 0.087388, Validation loss : 0.062701\n",
            "\n",
            "======== Epoch 788 =========\n",
            "Train loss : 0.098768, Test loss : 0.087364, Validation loss : 0.062648\n",
            "\n",
            "======== Epoch 789 =========\n",
            "Train loss : 0.098710, Test loss : 0.087301, Validation loss : 0.062600\n",
            "\n",
            "======== Epoch 790 =========\n",
            "Train loss : 0.098652, Test loss : 0.087264, Validation loss : 0.062549\n",
            "\n",
            "======== Epoch 791 =========\n",
            "Train loss : 0.098595, Test loss : 0.087217, Validation loss : 0.062499\n",
            "\n",
            "======== Epoch 792 =========\n",
            "Train loss : 0.098537, Test loss : 0.087180, Validation loss : 0.062449\n",
            "\n",
            "======== Epoch 793 =========\n",
            "Train loss : 0.098480, Test loss : 0.087116, Validation loss : 0.062402\n",
            "\n",
            "======== Epoch 794 =========\n",
            "Train loss : 0.098423, Test loss : 0.087088, Validation loss : 0.062350\n",
            "\n",
            "======== Epoch 795 =========\n",
            "Train loss : 0.098366, Test loss : 0.087043, Validation loss : 0.062301\n",
            "\n",
            "======== Epoch 796 =========\n",
            "Train loss : 0.098310, Test loss : 0.086981, Validation loss : 0.062254\n",
            "\n",
            "======== Epoch 797 =========\n",
            "Train loss : 0.098253, Test loss : 0.086959, Validation loss : 0.062202\n",
            "\n",
            "======== Epoch 798 =========\n",
            "Train loss : 0.098197, Test loss : 0.086905, Validation loss : 0.062155\n",
            "\n",
            "======== Epoch 799 =========\n",
            "Train loss : 0.098141, Test loss : 0.086855, Validation loss : 0.062107\n",
            "\n",
            "======== Epoch 800 =========\n",
            "Train loss : 0.098085, Test loss : 0.086828, Validation loss : 0.062056\n",
            "\n",
            "======== Epoch 801 =========\n",
            "Train loss : 0.098029, Test loss : 0.086766, Validation loss : 0.062010\n",
            "\n",
            "======== Epoch 802 =========\n",
            "Train loss : 0.097974, Test loss : 0.086725, Validation loss : 0.061962\n",
            "\n",
            "======== Epoch 803 =========\n",
            "Train loss : 0.097919, Test loss : 0.086695, Validation loss : 0.061912\n",
            "\n",
            "======== Epoch 804 =========\n",
            "Train loss : 0.097864, Test loss : 0.086626, Validation loss : 0.061868\n",
            "\n",
            "======== Epoch 805 =========\n",
            "Train loss : 0.097809, Test loss : 0.086614, Validation loss : 0.061817\n",
            "\n",
            "======== Epoch 806 =========\n",
            "Train loss : 0.097754, Test loss : 0.086547, Validation loss : 0.061772\n",
            "\n",
            "======== Epoch 807 =========\n",
            "Train loss : 0.097700, Test loss : 0.086509, Validation loss : 0.061724\n",
            "\n",
            "======== Epoch 808 =========\n",
            "Train loss : 0.097646, Test loss : 0.086474, Validation loss : 0.061676\n",
            "\n",
            "======== Epoch 809 =========\n",
            "Train loss : 0.097591, Test loss : 0.086426, Validation loss : 0.061630\n",
            "\n",
            "======== Epoch 810 =========\n",
            "Train loss : 0.097537, Test loss : 0.086374, Validation loss : 0.061584\n",
            "\n",
            "======== Epoch 811 =========\n",
            "Train loss : 0.097484, Test loss : 0.086348, Validation loss : 0.061536\n",
            "\n",
            "======== Epoch 812 =========\n",
            "Train loss : 0.097430, Test loss : 0.086295, Validation loss : 0.061490\n",
            "\n",
            "======== Epoch 813 =========\n",
            "Train loss : 0.097376, Test loss : 0.086243, Validation loss : 0.061445\n",
            "\n",
            "======== Epoch 814 =========\n",
            "Train loss : 0.097323, Test loss : 0.086224, Validation loss : 0.061397\n",
            "\n",
            "======== Epoch 815 =========\n",
            "Train loss : 0.097270, Test loss : 0.086160, Validation loss : 0.061353\n",
            "\n",
            "======== Epoch 816 =========\n",
            "Train loss : 0.097216, Test loss : 0.086123, Validation loss : 0.061307\n",
            "\n",
            "======== Epoch 817 =========\n",
            "Train loss : 0.097164, Test loss : 0.086093, Validation loss : 0.061260\n",
            "\n",
            "======== Epoch 818 =========\n",
            "Train loss : 0.097111, Test loss : 0.086027, Validation loss : 0.061217\n",
            "\n",
            "======== Epoch 819 =========\n",
            "Train loss : 0.097058, Test loss : 0.086007, Validation loss : 0.061169\n",
            "\n",
            "======== Epoch 820 =========\n",
            "Train loss : 0.097006, Test loss : 0.085958, Validation loss : 0.061125\n",
            "\n",
            "======== Epoch 821 =========\n",
            "Train loss : 0.096953, Test loss : 0.085909, Validation loss : 0.061081\n",
            "\n",
            "======== Epoch 822 =========\n",
            "Train loss : 0.096901, Test loss : 0.085879, Validation loss : 0.061035\n",
            "\n",
            "======== Epoch 823 =========\n",
            "Train loss : 0.096849, Test loss : 0.085836, Validation loss : 0.060991\n",
            "\n",
            "======== Epoch 824 =========\n",
            "Train loss : 0.096797, Test loss : 0.085783, Validation loss : 0.060948\n",
            "\n",
            "======== Epoch 825 =========\n",
            "Train loss : 0.096745, Test loss : 0.085758, Validation loss : 0.060902\n",
            "\n",
            "======== Epoch 826 =========\n",
            "Train loss : 0.096694, Test loss : 0.085711, Validation loss : 0.060858\n",
            "\n",
            "======== Epoch 827 =========\n",
            "Train loss : 0.096642, Test loss : 0.085664, Validation loss : 0.060815\n",
            "\n",
            "======== Epoch 828 =========\n",
            "Train loss : 0.096591, Test loss : 0.085632, Validation loss : 0.060770\n",
            "\n",
            "======== Epoch 829 =========\n",
            "Train loss : 0.096540, Test loss : 0.085581, Validation loss : 0.060728\n",
            "\n",
            "======== Epoch 830 =========\n",
            "Train loss : 0.096489, Test loss : 0.085550, Validation loss : 0.060683\n",
            "\n",
            "======== Epoch 831 =========\n",
            "Train loss : 0.096438, Test loss : 0.085505, Validation loss : 0.060640\n",
            "\n",
            "======== Epoch 832 =========\n",
            "Train loss : 0.096387, Test loss : 0.085454, Validation loss : 0.060598\n",
            "\n",
            "======== Epoch 833 =========\n",
            "Train loss : 0.096337, Test loss : 0.085436, Validation loss : 0.060553\n",
            "\n",
            "======== Epoch 834 =========\n",
            "Train loss : 0.096286, Test loss : 0.085376, Validation loss : 0.060512\n",
            "\n",
            "======== Epoch 835 =========\n",
            "Train loss : 0.096236, Test loss : 0.085336, Validation loss : 0.060469\n",
            "\n",
            "======== Epoch 836 =========\n",
            "Train loss : 0.096186, Test loss : 0.085300, Validation loss : 0.060427\n",
            "\n",
            "======== Epoch 837 =========\n",
            "Train loss : 0.096136, Test loss : 0.085264, Validation loss : 0.060384\n",
            "\n",
            "======== Epoch 838 =========\n",
            "Train loss : 0.096086, Test loss : 0.085213, Validation loss : 0.060343\n",
            "\n",
            "======== Epoch 839 =========\n",
            "Train loss : 0.096037, Test loss : 0.085187, Validation loss : 0.060300\n",
            "\n",
            "======== Epoch 840 =========\n",
            "Train loss : 0.095987, Test loss : 0.085134, Validation loss : 0.060260\n",
            "\n",
            "======== Epoch 841 =========\n",
            "Train loss : 0.095938, Test loss : 0.085105, Validation loss : 0.060217\n",
            "\n",
            "======== Epoch 842 =========\n",
            "Train loss : 0.095889, Test loss : 0.085062, Validation loss : 0.060176\n",
            "\n",
            "======== Epoch 843 =========\n",
            "Train loss : 0.095840, Test loss : 0.085019, Validation loss : 0.060135\n",
            "\n",
            "======== Epoch 844 =========\n",
            "Train loss : 0.095791, Test loss : 0.084985, Validation loss : 0.060093\n",
            "\n",
            "======== Epoch 845 =========\n",
            "Train loss : 0.095742, Test loss : 0.084945, Validation loss : 0.060053\n",
            "\n",
            "======== Epoch 846 =========\n",
            "Train loss : 0.095694, Test loss : 0.084906, Validation loss : 0.060012\n",
            "\n",
            "======== Epoch 847 =========\n",
            "Train loss : 0.095645, Test loss : 0.084867, Validation loss : 0.059971\n",
            "\n",
            "======== Epoch 848 =========\n",
            "Train loss : 0.095597, Test loss : 0.084828, Validation loss : 0.059931\n",
            "\n",
            "======== Epoch 849 =========\n",
            "Train loss : 0.095549, Test loss : 0.084785, Validation loss : 0.059891\n",
            "\n",
            "======== Epoch 850 =========\n",
            "Train loss : 0.095500, Test loss : 0.084753, Validation loss : 0.059850\n",
            "\n",
            "======== Epoch 851 =========\n",
            "Train loss : 0.095452, Test loss : 0.084708, Validation loss : 0.059810\n",
            "\n",
            "======== Epoch 852 =========\n",
            "Train loss : 0.095405, Test loss : 0.084680, Validation loss : 0.059769\n",
            "\n",
            "======== Epoch 853 =========\n",
            "Train loss : 0.095357, Test loss : 0.084633, Validation loss : 0.059730\n",
            "\n",
            "======== Epoch 854 =========\n",
            "Train loss : 0.095309, Test loss : 0.084594, Validation loss : 0.059691\n",
            "\n",
            "======== Epoch 855 =========\n",
            "Train loss : 0.095262, Test loss : 0.084560, Validation loss : 0.059651\n",
            "\n",
            "======== Epoch 856 =========\n",
            "Train loss : 0.095215, Test loss : 0.084525, Validation loss : 0.059611\n",
            "\n",
            "======== Epoch 857 =========\n",
            "Train loss : 0.095167, Test loss : 0.084477, Validation loss : 0.059573\n",
            "\n",
            "======== Epoch 858 =========\n",
            "Train loss : 0.095120, Test loss : 0.084447, Validation loss : 0.059533\n",
            "\n",
            "======== Epoch 859 =========\n",
            "Train loss : 0.095073, Test loss : 0.084398, Validation loss : 0.059495\n",
            "\n",
            "======== Epoch 860 =========\n",
            "Train loss : 0.095027, Test loss : 0.084377, Validation loss : 0.059454\n",
            "\n",
            "======== Epoch 861 =========\n",
            "Train loss : 0.094980, Test loss : 0.084330, Validation loss : 0.059416\n",
            "\n",
            "======== Epoch 862 =========\n",
            "Train loss : 0.094933, Test loss : 0.084287, Validation loss : 0.059378\n",
            "\n",
            "======== Epoch 863 =========\n",
            "Train loss : 0.094887, Test loss : 0.084261, Validation loss : 0.059339\n",
            "\n",
            "======== Epoch 864 =========\n",
            "Train loss : 0.094841, Test loss : 0.084216, Validation loss : 0.059301\n",
            "\n",
            "======== Epoch 865 =========\n",
            "Train loss : 0.094795, Test loss : 0.084170, Validation loss : 0.059264\n",
            "\n",
            "======== Epoch 866 =========\n",
            "Train loss : 0.094749, Test loss : 0.084153, Validation loss : 0.059224\n",
            "\n",
            "======== Epoch 867 =========\n",
            "Train loss : 0.094703, Test loss : 0.084086, Validation loss : 0.059189\n",
            "\n",
            "======== Epoch 868 =========\n",
            "Train loss : 0.094657, Test loss : 0.084079, Validation loss : 0.059148\n",
            "\n",
            "======== Epoch 869 =========\n",
            "Train loss : 0.094611, Test loss : 0.084024, Validation loss : 0.059112\n",
            "\n",
            "======== Epoch 870 =========\n",
            "Train loss : 0.094566, Test loss : 0.083990, Validation loss : 0.059074\n",
            "\n",
            "======== Epoch 871 =========\n",
            "Train loss : 0.094520, Test loss : 0.083961, Validation loss : 0.059036\n",
            "\n",
            "======== Epoch 872 =========\n",
            "Train loss : 0.094475, Test loss : 0.083924, Validation loss : 0.058998\n",
            "\n",
            "======== Epoch 873 =========\n",
            "Train loss : 0.094430, Test loss : 0.083868, Validation loss : 0.058963\n",
            "\n",
            "======== Epoch 874 =========\n",
            "Train loss : 0.094385, Test loss : 0.083859, Validation loss : 0.058924\n",
            "\n",
            "======== Epoch 875 =========\n",
            "Train loss : 0.094340, Test loss : 0.083797, Validation loss : 0.058889\n",
            "\n",
            "======== Epoch 876 =========\n",
            "Train loss : 0.094295, Test loss : 0.083776, Validation loss : 0.058851\n",
            "\n",
            "======== Epoch 877 =========\n",
            "Train loss : 0.094251, Test loss : 0.083735, Validation loss : 0.058814\n",
            "\n",
            "======== Epoch 878 =========\n",
            "Train loss : 0.094206, Test loss : 0.083690, Validation loss : 0.058779\n",
            "\n",
            "======== Epoch 879 =========\n",
            "Train loss : 0.094162, Test loss : 0.083673, Validation loss : 0.058740\n",
            "\n",
            "======== Epoch 880 =========\n",
            "Train loss : 0.094117, Test loss : 0.083612, Validation loss : 0.058706\n",
            "\n",
            "======== Epoch 881 =========\n",
            "Train loss : 0.094073, Test loss : 0.083595, Validation loss : 0.058669\n",
            "\n",
            "======== Epoch 882 =========\n",
            "Train loss : 0.094029, Test loss : 0.083553, Validation loss : 0.058633\n",
            "\n",
            "======== Epoch 883 =========\n",
            "Train loss : 0.093985, Test loss : 0.083510, Validation loss : 0.058597\n",
            "\n",
            "======== Epoch 884 =========\n",
            "Train loss : 0.093941, Test loss : 0.083491, Validation loss : 0.058560\n",
            "\n",
            "======== Epoch 885 =========\n",
            "Train loss : 0.093897, Test loss : 0.083441, Validation loss : 0.058526\n",
            "\n",
            "======== Epoch 886 =========\n",
            "Train loss : 0.093854, Test loss : 0.083406, Validation loss : 0.058490\n",
            "\n",
            "======== Epoch 887 =========\n",
            "Train loss : 0.093810, Test loss : 0.083375, Validation loss : 0.058454\n",
            "\n",
            "======== Epoch 888 =========\n",
            "Train loss : 0.093767, Test loss : 0.083327, Validation loss : 0.058420\n",
            "\n",
            "======== Epoch 889 =========\n",
            "Train loss : 0.093724, Test loss : 0.083309, Validation loss : 0.058383\n",
            "\n",
            "======== Epoch 890 =========\n",
            "Train loss : 0.093681, Test loss : 0.083260, Validation loss : 0.058349\n",
            "\n",
            "======== Epoch 891 =========\n",
            "Train loss : 0.093638, Test loss : 0.083227, Validation loss : 0.058314\n",
            "\n",
            "======== Epoch 892 =========\n",
            "Train loss : 0.093595, Test loss : 0.083198, Validation loss : 0.058279\n",
            "\n",
            "======== Epoch 893 =========\n",
            "Train loss : 0.093553, Test loss : 0.083146, Validation loss : 0.058246\n",
            "\n",
            "======== Epoch 894 =========\n",
            "Train loss : 0.093510, Test loss : 0.083131, Validation loss : 0.058209\n",
            "\n",
            "======== Epoch 895 =========\n",
            "Train loss : 0.093468, Test loss : 0.083079, Validation loss : 0.058176\n",
            "\n",
            "======== Epoch 896 =========\n",
            "Train loss : 0.093425, Test loss : 0.083049, Validation loss : 0.058142\n",
            "\n",
            "======== Epoch 897 =========\n",
            "Train loss : 0.093383, Test loss : 0.083019, Validation loss : 0.058107\n",
            "\n",
            "======== Epoch 898 =========\n",
            "Train loss : 0.093341, Test loss : 0.082974, Validation loss : 0.058073\n",
            "\n",
            "======== Epoch 899 =========\n",
            "Train loss : 0.093299, Test loss : 0.082950, Validation loss : 0.058038\n",
            "\n",
            "======== Epoch 900 =========\n",
            "Train loss : 0.093257, Test loss : 0.082908, Validation loss : 0.058005\n",
            "\n",
            "======== Epoch 901 =========\n",
            "Train loss : 0.093215, Test loss : 0.082871, Validation loss : 0.057972\n",
            "\n",
            "======== Epoch 902 =========\n",
            "Train loss : 0.093174, Test loss : 0.082846, Validation loss : 0.057937\n",
            "\n",
            "======== Epoch 903 =========\n",
            "Train loss : 0.093132, Test loss : 0.082798, Validation loss : 0.057905\n",
            "\n",
            "======== Epoch 904 =========\n",
            "Train loss : 0.093090, Test loss : 0.082774, Validation loss : 0.057870\n",
            "\n",
            "======== Epoch 905 =========\n",
            "Train loss : 0.093049, Test loss : 0.082734, Validation loss : 0.057837\n",
            "\n",
            "======== Epoch 906 =========\n",
            "Train loss : 0.093008, Test loss : 0.082694, Validation loss : 0.057805\n",
            "\n",
            "======== Epoch 907 =========\n",
            "Train loss : 0.092967, Test loss : 0.082673, Validation loss : 0.057771\n",
            "\n",
            "======== Epoch 908 =========\n",
            "Train loss : 0.092925, Test loss : 0.082628, Validation loss : 0.057738\n",
            "\n",
            "======== Epoch 909 =========\n",
            "Train loss : 0.092885, Test loss : 0.082593, Validation loss : 0.057706\n",
            "\n",
            "======== Epoch 910 =========\n",
            "Train loss : 0.092844, Test loss : 0.082564, Validation loss : 0.057672\n",
            "\n",
            "======== Epoch 911 =========\n",
            "Train loss : 0.092803, Test loss : 0.082521, Validation loss : 0.057640\n",
            "\n",
            "======== Epoch 912 =========\n",
            "Train loss : 0.092762, Test loss : 0.082497, Validation loss : 0.057607\n",
            "\n",
            "======== Epoch 913 =========\n",
            "Train loss : 0.092722, Test loss : 0.082464, Validation loss : 0.057574\n",
            "\n",
            "======== Epoch 914 =========\n",
            "Train loss : 0.092681, Test loss : 0.082414, Validation loss : 0.057543\n",
            "\n",
            "======== Epoch 915 =========\n",
            "Train loss : 0.092641, Test loss : 0.082396, Validation loss : 0.057510\n",
            "\n",
            "======== Epoch 916 =========\n",
            "Train loss : 0.092601, Test loss : 0.082346, Validation loss : 0.057479\n",
            "\n",
            "======== Epoch 917 =========\n",
            "Train loss : 0.092561, Test loss : 0.082334, Validation loss : 0.057445\n",
            "\n",
            "======== Epoch 918 =========\n",
            "Train loss : 0.092521, Test loss : 0.082281, Validation loss : 0.057415\n",
            "\n",
            "======== Epoch 919 =========\n",
            "Train loss : 0.092481, Test loss : 0.082249, Validation loss : 0.057383\n",
            "\n",
            "======== Epoch 920 =========\n",
            "Train loss : 0.092441, Test loss : 0.082229, Validation loss : 0.057350\n",
            "\n",
            "======== Epoch 921 =========\n",
            "Train loss : 0.092401, Test loss : 0.082174, Validation loss : 0.057320\n",
            "\n",
            "======== Epoch 922 =========\n",
            "Train loss : 0.092361, Test loss : 0.082158, Validation loss : 0.057287\n",
            "\n",
            "======== Epoch 923 =========\n",
            "Train loss : 0.092322, Test loss : 0.082119, Validation loss : 0.057257\n",
            "\n",
            "======== Epoch 924 =========\n",
            "Train loss : 0.092283, Test loss : 0.082084, Validation loss : 0.057226\n",
            "\n",
            "======== Epoch 925 =========\n",
            "Train loss : 0.092243, Test loss : 0.082058, Validation loss : 0.057195\n",
            "\n",
            "======== Epoch 926 =========\n",
            "Train loss : 0.092204, Test loss : 0.082006, Validation loss : 0.057165\n",
            "\n",
            "======== Epoch 927 =========\n",
            "Train loss : 0.092165, Test loss : 0.081993, Validation loss : 0.057133\n",
            "\n",
            "======== Epoch 928 =========\n",
            "Train loss : 0.092126, Test loss : 0.081954, Validation loss : 0.057103\n",
            "\n",
            "======== Epoch 929 =========\n",
            "Train loss : 0.092087, Test loss : 0.081911, Validation loss : 0.057073\n",
            "\n",
            "======== Epoch 930 =========\n",
            "Train loss : 0.092048, Test loss : 0.081898, Validation loss : 0.057041\n",
            "\n",
            "======== Epoch 931 =========\n",
            "Train loss : 0.092010, Test loss : 0.081839, Validation loss : 0.057012\n",
            "\n",
            "======== Epoch 932 =========\n",
            "Train loss : 0.091971, Test loss : 0.081835, Validation loss : 0.056981\n",
            "\n",
            "======== Epoch 933 =========\n",
            "Train loss : 0.091933, Test loss : 0.081781, Validation loss : 0.056952\n",
            "\n",
            "======== Epoch 934 =========\n",
            "Train loss : 0.091894, Test loss : 0.081755, Validation loss : 0.056921\n",
            "\n",
            "======== Epoch 935 =========\n",
            "Train loss : 0.091856, Test loss : 0.081730, Validation loss : 0.056891\n",
            "\n",
            "======== Epoch 936 =========\n",
            "Train loss : 0.091818, Test loss : 0.081679, Validation loss : 0.056862\n",
            "\n",
            "======== Epoch 937 =========\n",
            "Train loss : 0.091779, Test loss : 0.081668, Validation loss : 0.056831\n",
            "\n",
            "======== Epoch 938 =========\n",
            "Train loss : 0.091741, Test loss : 0.081621, Validation loss : 0.056802\n",
            "\n",
            "======== Epoch 939 =========\n",
            "Train loss : 0.091703, Test loss : 0.081594, Validation loss : 0.056773\n",
            "\n",
            "======== Epoch 940 =========\n",
            "Train loss : 0.091665, Test loss : 0.081559, Validation loss : 0.056743\n",
            "\n",
            "======== Epoch 941 =========\n",
            "Train loss : 0.091628, Test loss : 0.081524, Validation loss : 0.056714\n",
            "\n",
            "======== Epoch 942 =========\n",
            "Train loss : 0.091590, Test loss : 0.081500, Validation loss : 0.056684\n",
            "\n",
            "======== Epoch 943 =========\n",
            "Train loss : 0.091552, Test loss : 0.081464, Validation loss : 0.056655\n",
            "\n",
            "======== Epoch 944 =========\n",
            "Train loss : 0.091515, Test loss : 0.081424, Validation loss : 0.056627\n",
            "\n",
            "======== Epoch 945 =========\n",
            "Train loss : 0.091478, Test loss : 0.081404, Validation loss : 0.056597\n",
            "\n",
            "======== Epoch 946 =========\n",
            "Train loss : 0.091440, Test loss : 0.081360, Validation loss : 0.056570\n",
            "\n",
            "======== Epoch 947 =========\n",
            "Train loss : 0.091403, Test loss : 0.081340, Validation loss : 0.056540\n",
            "\n",
            "======== Epoch 948 =========\n",
            "Train loss : 0.091366, Test loss : 0.081292, Validation loss : 0.056513\n",
            "\n",
            "======== Epoch 949 =========\n",
            "Train loss : 0.091329, Test loss : 0.081278, Validation loss : 0.056483\n",
            "\n",
            "======== Epoch 950 =========\n",
            "Train loss : 0.091292, Test loss : 0.081239, Validation loss : 0.056455\n",
            "\n",
            "======== Epoch 951 =========\n",
            "Train loss : 0.091256, Test loss : 0.081202, Validation loss : 0.056427\n",
            "\n",
            "======== Epoch 952 =========\n",
            "Train loss : 0.091219, Test loss : 0.081185, Validation loss : 0.056398\n",
            "\n",
            "======== Epoch 953 =========\n",
            "Train loss : 0.091182, Test loss : 0.081131, Validation loss : 0.056371\n",
            "\n",
            "======== Epoch 954 =========\n",
            "Train loss : 0.091146, Test loss : 0.081126, Validation loss : 0.056342\n",
            "\n",
            "======== Epoch 955 =========\n",
            "Train loss : 0.091109, Test loss : 0.081075, Validation loss : 0.056315\n",
            "\n",
            "======== Epoch 956 =========\n",
            "Train loss : 0.091073, Test loss : 0.081050, Validation loss : 0.056287\n",
            "\n",
            "======== Epoch 957 =========\n",
            "Train loss : 0.091037, Test loss : 0.081018, Validation loss : 0.056259\n",
            "\n",
            "======== Epoch 958 =========\n",
            "Train loss : 0.091001, Test loss : 0.080987, Validation loss : 0.056232\n",
            "\n",
            "======== Epoch 959 =========\n",
            "Train loss : 0.090965, Test loss : 0.080956, Validation loss : 0.056204\n",
            "\n",
            "======== Epoch 960 =========\n",
            "Train loss : 0.090929, Test loss : 0.080929, Validation loss : 0.056177\n",
            "\n",
            "======== Epoch 961 =========\n",
            "Train loss : 0.090893, Test loss : 0.080884, Validation loss : 0.056150\n",
            "\n",
            "======== Epoch 962 =========\n",
            "Train loss : 0.090857, Test loss : 0.080876, Validation loss : 0.056122\n",
            "\n",
            "======== Epoch 963 =========\n",
            "Train loss : 0.090821, Test loss : 0.080817, Validation loss : 0.056096\n",
            "\n",
            "======== Epoch 964 =========\n",
            "Train loss : 0.090786, Test loss : 0.080818, Validation loss : 0.056067\n",
            "\n",
            "======== Epoch 965 =========\n",
            "Train loss : 0.090750, Test loss : 0.080757, Validation loss : 0.056041\n",
            "\n",
            "======== Epoch 966 =========\n",
            "Train loss : 0.090715, Test loss : 0.080752, Validation loss : 0.056013\n",
            "\n",
            "======== Epoch 967 =========\n",
            "Train loss : 0.090679, Test loss : 0.080711, Validation loss : 0.055987\n",
            "\n",
            "======== Epoch 968 =========\n",
            "Train loss : 0.090644, Test loss : 0.080671, Validation loss : 0.055961\n",
            "\n",
            "======== Epoch 969 =========\n",
            "Train loss : 0.090609, Test loss : 0.080660, Validation loss : 0.055933\n",
            "\n",
            "======== Epoch 970 =========\n",
            "Train loss : 0.090574, Test loss : 0.080613, Validation loss : 0.055908\n",
            "\n",
            "======== Epoch 971 =========\n",
            "Train loss : 0.090538, Test loss : 0.080589, Validation loss : 0.055881\n",
            "\n",
            "======== Epoch 972 =========\n",
            "Train loss : 0.090503, Test loss : 0.080559, Validation loss : 0.055854\n",
            "\n",
            "======== Epoch 973 =========\n",
            "Train loss : 0.090469, Test loss : 0.080532, Validation loss : 0.055828\n",
            "\n",
            "======== Epoch 974 =========\n",
            "Train loss : 0.090434, Test loss : 0.080490, Validation loss : 0.055803\n",
            "\n",
            "======== Epoch 975 =========\n",
            "Train loss : 0.090399, Test loss : 0.080475, Validation loss : 0.055776\n",
            "\n",
            "======== Epoch 976 =========\n",
            "Train loss : 0.090364, Test loss : 0.080438, Validation loss : 0.055751\n",
            "\n",
            "======== Epoch 977 =========\n",
            "Train loss : 0.090330, Test loss : 0.080399, Validation loss : 0.055725\n",
            "\n",
            "======== Epoch 978 =========\n",
            "Train loss : 0.090295, Test loss : 0.080388, Validation loss : 0.055698\n",
            "\n",
            "======== Epoch 979 =========\n",
            "Train loss : 0.090261, Test loss : 0.080339, Validation loss : 0.055673\n",
            "\n",
            "======== Epoch 980 =========\n",
            "Train loss : 0.090227, Test loss : 0.080323, Validation loss : 0.055647\n",
            "\n",
            "======== Epoch 981 =========\n",
            "Train loss : 0.090192, Test loss : 0.080281, Validation loss : 0.055622\n",
            "\n",
            "======== Epoch 982 =========\n",
            "Train loss : 0.090158, Test loss : 0.080258, Validation loss : 0.055596\n",
            "\n",
            "======== Epoch 983 =========\n",
            "Train loss : 0.090124, Test loss : 0.080230, Validation loss : 0.055571\n",
            "\n",
            "======== Epoch 984 =========\n",
            "Train loss : 0.090090, Test loss : 0.080194, Validation loss : 0.055546\n",
            "\n",
            "======== Epoch 985 =========\n",
            "Train loss : 0.090056, Test loss : 0.080164, Validation loss : 0.055521\n",
            "\n",
            "======== Epoch 986 =========\n",
            "Train loss : 0.090022, Test loss : 0.080141, Validation loss : 0.055496\n",
            "\n",
            "======== Epoch 987 =========\n",
            "Train loss : 0.089988, Test loss : 0.080103, Validation loss : 0.055471\n",
            "\n",
            "======== Epoch 988 =========\n",
            "Train loss : 0.089955, Test loss : 0.080085, Validation loss : 0.055445\n",
            "\n",
            "======== Epoch 989 =========\n",
            "Train loss : 0.089921, Test loss : 0.080046, Validation loss : 0.055421\n",
            "\n",
            "======== Epoch 990 =========\n",
            "Train loss : 0.089887, Test loss : 0.080011, Validation loss : 0.055396\n",
            "\n",
            "======== Epoch 991 =========\n",
            "Train loss : 0.089854, Test loss : 0.079997, Validation loss : 0.055371\n",
            "\n",
            "======== Epoch 992 =========\n",
            "Train loss : 0.089821, Test loss : 0.079953, Validation loss : 0.055347\n",
            "\n",
            "======== Epoch 993 =========\n",
            "Train loss : 0.089787, Test loss : 0.079936, Validation loss : 0.055322\n",
            "\n",
            "======== Epoch 994 =========\n",
            "Train loss : 0.089754, Test loss : 0.079890, Validation loss : 0.055298\n",
            "\n",
            "======== Epoch 995 =========\n",
            "Train loss : 0.089721, Test loss : 0.079874, Validation loss : 0.055273\n",
            "\n",
            "======== Epoch 996 =========\n",
            "Train loss : 0.089688, Test loss : 0.079843, Validation loss : 0.055249\n",
            "\n",
            "======== Epoch 997 =========\n",
            "Train loss : 0.089655, Test loss : 0.079812, Validation loss : 0.055225\n",
            "\n",
            "======== Epoch 998 =========\n",
            "Train loss : 0.089622, Test loss : 0.079775, Validation loss : 0.055201\n",
            "\n",
            "======== Epoch 999 =========\n",
            "Train loss : 0.089589, Test loss : 0.079758, Validation loss : 0.055177\n",
            "\n",
            "======== Epoch 1000 =========\n",
            "Train loss : 0.089556, Test loss : 0.079722, Validation loss : 0.055153\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Scoring\n",
        "분류에 대한 평가 지표로는 아래와 같은 지표들이 사용 가능하다.  \n",
        "\n",
        "- Accuracy : 정확히 예측한 Example 수 / 전체 Example 수\n",
        "- Precision : \n",
        "- Recall : \n",
        "- F-1 Score : Precision과 Recall의 조화평균\n",
        "- Confusion matrix를 통해 한 눈에 확인이 가능하다."
      ],
      "metadata": {
        "id": "o2GmWRSpbHVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy 측정\n",
        "def get_result_class(pred):\n",
        "  result = [] # 예측된 Class를 저장할 배열\n",
        "  pred = pred.numpy()\n",
        "  \n",
        "  for example in range(len(pred)):\n",
        "    result.append(np.argmax(pred[example]))\n",
        "    # 가장 큰 값이 나온 index가, 즉 예측된 class가 된다.\n",
        "\n",
        "  return result\n",
        "  # 몇 개나 맞췄는지 정확도를 반환한다.\n",
        "\n",
        "def print_score(org_set, pred_set):\n",
        "  print(\"Accuracy of train set : \", round(met.accuracy_score(org_set, pred_set) * 100, 3))\n",
        "  print(\"Precision of train set : \", round(met.precision_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print(\"Recall of train set : \", round(met.recall_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print(\"F-1 Score of train set : \", round(met.f1_score(org_set, pred_set, average = 'weighted') * 100, 3))\n",
        "  print()\n",
        "  print(met.confusion_matrix(org_set, pred_set))\n",
        "  print(\"=================================\")\n",
        "\n",
        "with torch.no_grad():\n",
        "# torch.no_grad() 함수를 통해, weight 업데이트 없이 테스트가 가능하다.\n",
        "  train_pred = model(x_train)\n",
        "  test_pred = model(x_test)\n",
        "  valid_pred = model(x_valid)\n",
        "\n",
        "train_result = get_result_class(train_pred)\n",
        "test_result = get_result_class(test_pred)\n",
        "valid_result = get_result_class(valid_pred)\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "print_score(y_train, train_result)\n",
        "print_score(y_test, test_result)\n",
        "print_score(y_valid, valid_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeGizBI0hBlJ",
        "outputId": "83e9fe95-2e7a-4f4b-ad7a-4eb1aea4d9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "\n",
            "Accuracy of train set :  97.778\n",
            "Precision of train set :  97.908\n",
            "Recall of train set :  97.778\n",
            "F-1 Score of train set :  97.774\n",
            "\n",
            "[[27  0  0]\n",
            " [ 0 29  2]\n",
            " [ 0  0 32]]\n",
            "=================================\n",
            "Accuracy of train set :  100.0\n",
            "Precision of train set :  100.0\n",
            "Recall of train set :  100.0\n",
            "F-1 Score of train set :  100.0\n",
            "\n",
            "[[12  0  0]\n",
            " [ 0  6  0]\n",
            " [ 0  0 12]]\n",
            "=================================\n",
            "Accuracy of train set :  100.0\n",
            "Precision of train set :  100.0\n",
            "Recall of train set :  100.0\n",
            "F-1 Score of train set :  100.0\n",
            "\n",
            "[[11  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0  6]]\n",
            "=================================\n"
          ]
        }
      ]
    }
  ]
}